{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed12364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa1fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from attrs import define, field\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9111b1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from octopus import OctoStudy\n",
    "from octopus.modules import Octo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a14512",
   "metadata": {},
   "outputs": [],
   "source": [
    "@define\n",
    "class DataFrameGenerator:\n",
    "    \"\"\"A class to generate an example DataFrame.\"\"\"\n",
    "\n",
    "    n_samples: int = 1000\n",
    "    n_features: int = 20\n",
    "    n_informative: int = 10\n",
    "    n_redundant: int = 10\n",
    "    n_classes: int = 3\n",
    "    random_state: int = None\n",
    "\n",
    "    df: pd.DataFrame = field(init=False)\n",
    "\n",
    "    def __attrs_post_init__(self):\n",
    "        self._generate_data()\n",
    "\n",
    "    def _generate_data(self):\n",
    "        \"\"\"Generate the classification dataset and initialize the DataFrame.\"\"\"\n",
    "        X, y = make_classification(\n",
    "            n_samples=self.n_samples,\n",
    "            n_features=self.n_features,\n",
    "            n_informative=self.n_informative,\n",
    "            n_redundant=self.n_redundant,\n",
    "            n_classes=self.n_classes,\n",
    "            n_clusters_per_class=2,\n",
    "            class_sep=5.0,\n",
    "            random_state=self.random_state,\n",
    "        )\n",
    "\n",
    "        # Create DataFrame from features\n",
    "        feature_names = [f\"feature_{i + 1}\" for i in range(self.n_features)]\n",
    "        self.df = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "        # Add the target column\n",
    "        self.df[\"target\"] = y\n",
    "\n",
    "    def add_nan_to_features(self, min_frac=0.02, max_frac=0.8):\n",
    "        \"\"\"Add a random proportion of NaNs to the first half of the feature columns.\"\"\"\n",
    "        half_features = self.df.columns[: self.n_features // 2]\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        num_rows = len(self.df)\n",
    "\n",
    "        for feature in half_features:\n",
    "            # Determine the number of NaNs to introduce based on the random fraction\n",
    "            nan_fraction = rng.uniform(min_frac, max_frac)\n",
    "            num_nan = int(nan_fraction * num_rows)\n",
    "\n",
    "            # Select random indices to set as NaN\n",
    "            nan_indices = rng.choice(self.df.index, size=num_nan, replace=False)\n",
    "            self.df.loc[nan_indices, feature] = np.nan\n",
    "\n",
    "    def add_nan_to_target(self, num_nan=10):\n",
    "        \"\"\"Add NaN values to the target column.\"\"\"\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        nan_indices = rng.choice(self.df.index, size=num_nan, replace=False)\n",
    "        self.df.loc[nan_indices, \"target\"] = np.nan\n",
    "\n",
    "    def add_id_column(\n",
    "        self,\n",
    "        column_name=\"id\",\n",
    "        prefix=\"ID_\",\n",
    "        unique=True,\n",
    "        duplicate_factor=2,\n",
    "        include_nans=False,\n",
    "        nan_ratio=0.1,\n",
    "    ):\n",
    "        \"\"\"Add an ID column with unique or non-unique identifiers.\"\"\"\n",
    "        if prefix is None:\n",
    "            # Use integers for IDs\n",
    "            ids = np.arange(len(self.df), dtype=\"uint\" if unique else \"int\")\n",
    "            if not unique:\n",
    "                ids = np.repeat(ids, duplicate_factor)[: len(self.df)]\n",
    "        elif unique:\n",
    "            # Create unique IDs with prefix\n",
    "            ids = [prefix + str(i) for i in self.df.index]\n",
    "        else:\n",
    "            # Create non-unique IDs with prefix\n",
    "            ids = [prefix + str(i) for i in range(len(self.df) // duplicate_factor)]\n",
    "            non_unique_ids = ids * duplicate_factor\n",
    "            ids = non_unique_ids[: len(self.df)]\n",
    "\n",
    "        if include_nans:\n",
    "            # Determine number of NaNs to include\n",
    "            num_nans = int(len(self.df) * nan_ratio)\n",
    "            nan_indices = np.random.choice(len(self.df), num_nans, replace=False)\n",
    "            ids = np.array(ids, dtype=object)  # Convert to a mutable array\n",
    "            ids[nan_indices] = np.nan\n",
    "\n",
    "        self.df[column_name] = ids\n",
    "\n",
    "    def add_constant_column(self, column_name=\"one\", value=1):\n",
    "        \"\"\"Add a constant column to the DataFrame.\"\"\"\n",
    "        self.df[column_name] = value\n",
    "\n",
    "    def add_decimal_columns(self, column_names: list[str] | None = None, precision=8):\n",
    "        \"\"\"Add columns with Decimal data type.\"\"\"\n",
    "        if column_names is None:\n",
    "            column_names = [\"decimal_1\", \"decimal_2\"]\n",
    "\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        for col_name in column_names:\n",
    "            random_numbers = rng.random(size=len(self.df))\n",
    "            formatted_numbers = [Decimal(f\"{num:.{precision}f}\") for num in random_numbers]\n",
    "            self.df[col_name] = formatted_numbers\n",
    "\n",
    "    def add_inf_columns(self, column_names: list[str] | None = None, num_inf=10):\n",
    "        \"\"\"Add columns with infinite values.\"\"\"\n",
    "        if column_names is None:\n",
    "            column_names = [\"inf_col\"]\n",
    "\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        for col_name in column_names:\n",
    "            # Initialize the column with random float values\n",
    "            self.df[col_name] = rng.standard_normal(size=len(self.df))\n",
    "            # Introduce inf values\n",
    "            inf_indices = rng.choice(self.df.index, size=num_inf, replace=False)\n",
    "            self.df.loc[inf_indices, col_name] = np.inf\n",
    "\n",
    "    def add_fixed_unique_values_column(self, column_name=\"few_unique\", num_unique=3):\n",
    "        \"\"\"Add a column with a specified number of unique values.\"\"\"\n",
    "        # Create a list of unique values\n",
    "        unique_values = list(range(num_unique))\n",
    "        # Repeat these values to fill the column\n",
    "        repeated_values = unique_values * (len(self.df) // num_unique + 1)\n",
    "        # Assign to the DataFrame, trimming to the correct length\n",
    "        self.df[column_name] = repeated_values[: len(self.df)]\n",
    "\n",
    "    def add_string_mismatch_column(self, column_name=\"mismatch_col\", base_string=\"sample\", error_rate=0.1):\n",
    "        \"\"\"Add a column with strings that contain random typos or mismatches, and convert it to categorical.\"\"\"\n",
    "\n",
    "        def introduce_typo(s):\n",
    "            if random.random() < error_rate:\n",
    "                # Introduce a typo by swapping two adjacent characters\n",
    "                idx = random.randint(0, len(s) - 2)\n",
    "                return s[:idx] + s[idx + 1] + s[idx] + s[idx + 2 :]\n",
    "            return s\n",
    "\n",
    "        # Generate the column with potential typos\n",
    "        self.df[column_name] = [introduce_typo(base_string) for _ in range(len(self.df))]\n",
    "\n",
    "        # Convert the column to categorical type\n",
    "        self.df[column_name] = self.df[column_name].astype(\"category\")\n",
    "\n",
    "    def get_dataframe(self):\n",
    "        \"\"\"Return the generated DataFrame.\n",
    "\n",
    "        Returns:\n",
    "        - pd.DataFrame: The generated DataFrame.\n",
    "        \"\"\"\n",
    "        return self.df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8636abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error example\n",
    "generator_errors = DataFrameGenerator(random_state=42)\n",
    "generator_errors.add_nan_to_features()\n",
    "generator_errors.add_nan_to_target(num_nan=10)\n",
    "generator_errors.add_id_column(unique=True, include_nans=True)\n",
    "generator_errors.add_id_column(column_name=\"sample_id\", prefix=\"Sample\", unique=True, include_nans=True)\n",
    "generator_errors.add_id_column(\n",
    "    column_name=\"stratification\",\n",
    "    prefix=\"Strat_\",\n",
    "    unique=True,\n",
    "    include_nans=False,\n",
    ")\n",
    "generator_errors.add_constant_column()\n",
    "# generator_errors.add_decimal_columns()\n",
    "generator_errors.add_inf_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60441c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error = generator_errors.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1169b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning example\n",
    "generator_warnings = DataFrameGenerator(random_state=42, n_classes=2)\n",
    "generator_warnings.add_fixed_unique_values_column()\n",
    "generator_warnings.add_id_column(unique=True, include_nans=False)\n",
    "generator_warnings.add_id_column(column_name=\"sample_id\", prefix=\"Sample\", unique=True, include_nans=False)\n",
    "generator_warnings.add_id_column(\n",
    "    column_name=\"stratification\",\n",
    "    prefix=None,\n",
    "    unique=True,\n",
    "    include_nans=False,\n",
    ")\n",
    "generator_warnings.add_string_mismatch_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_warnings = generator_warnings.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e04033",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_warnings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc2e71a",
   "metadata": {},
   "source": [
    "## Create and run OctoStudy with health check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1636515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = OctoStudy(\n",
    "    name=\"health_check\",\n",
    "    path=os.environ.get(\"STUDIES_PATH\", \"./studies\"),\n",
    "    ml_type=\"classification\",\n",
    "    target_metric=\"AUCROC\",\n",
    "    feature_columns=df_warnings.columns.drop(\"target\").drop(\"id\").drop(\"sample_id\").drop(\"stratification\").tolist(),\n",
    "    target_columns=[\"target\"],\n",
    "    sample_id=\"sample_id\",\n",
    "    datasplit_type=\"group_sample_and_features\",\n",
    "    stratification_column=\"target\",\n",
    "    ignore_data_health_warning=False,  # Will stop if health check finds issues\n",
    "    outer_parallelization=True,\n",
    "    workflow=[\n",
    "        Octo(\n",
    "            task_id=0,\n",
    "            depends_on_task=-1,\n",
    "            description=\"step_1_octo\",\n",
    "            models=[\"RandomForestClassifier\"],\n",
    "            n_trials=3,\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf3f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.fit(data=df_warnings)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
