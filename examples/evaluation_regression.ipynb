{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Regression\n",
    "\n",
    "This notebook provides tools for evaluating regression model results from Octopus studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import altair as alt\n",
    "import duckdb\n",
    "import polars as pl\n",
    "from IPython.display import display\n",
    "from ipywidgets import Dropdown, interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Study Directory\n",
    "\n",
    "Update the `study_path` variable below to point to your study directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this path to your study directory\n",
    "# In this example, we use a path relative to the current working directory\n",
    "studies_root = os.environ.get(\"STUDIES_PATH\", \"./studies\")\n",
    "study_path = os.path.join(studies_root, \"basic_regression\")  # Change this to your study path\n",
    "\n",
    "# Convert to absolute path to avoid path resolution issues\n",
    "study_path_abs = Path(study_path).resolve()\n",
    "print(f\"Using study path: {study_path_abs}\")\n",
    "\n",
    "# Check if path exists\n",
    "if not Path(study_path_abs).exists():\n",
    "    raise ValueError(f\"Path does not exist: {study_path_abs}. Please update the study_path variable above to point to your actual study directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Using DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DuckDB connection\n",
    "con = duckdb.connect()\n",
    "print(\"DuckDB connection established\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Optuna data\n",
    "df_optuna = con.execute(\n",
    "    f\"SELECT * FROM read_parquet('{study_path_abs}/*/*/optuna*.parquet', hive_partitioning=true)\"\n",
    ").pl()\n",
    "print(f\"Loaded {len(df_optuna)} optuna records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions data\n",
    "df_predictions = con.execute(\n",
    "    f\"SELECT * FROM read_parquet('{study_path_abs}/*/*/predictions*.parquet', hive_partitioning=true)\"\n",
    ").pl()\n",
    "\n",
    "df_predictions_pandas = df_predictions.to_pandas()\n",
    "print(f\"Loaded {len(df_predictions)} prediction records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature importances\n",
    "df_feature_importances = (\n",
    "    con.execute(\n",
    "        f\"SELECT * FROM read_parquet('{study_path_abs}/*/*/feature-importance*.parquet', hive_partitioning=true)\"\n",
    "    )\n",
    "    .pl()\n",
    "    .with_columns(pl.col(\"experiment_id\").cast(pl.Int64))\n",
    "    .with_columns(pl.col(\"task_id\").cast(pl.Int64))\n",
    ")\n",
    "print(f\"Loaded {len(df_feature_importances)} feature importance records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Interactive Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique values for dropdowns\n",
    "unique_id_values = {\n",
    "    k: sorted(v)\n",
    "    for k, v in df_predictions.select(pl.all().cast(pl.Utf8))\n",
    "    .select([\"experiment_id\", \"task_id\", \"training_id\"])\n",
    "    .unique()\n",
    "    .to_dict(as_series=False)\n",
    "    .items()\n",
    "}\n",
    "\n",
    "unique_id_values_feature_importance = {\n",
    "    k: sorted(v)\n",
    "    for k, v in df_feature_importances.select(pl.all().cast(pl.Utf8))\n",
    "    .select([\"fi_type\"])\n",
    "    .unique()\n",
    "    .to_dict(as_series=False)\n",
    "    .items()\n",
    "}\n",
    "\n",
    "unique_id_values_optuna = {\n",
    "    k: sorted(v)\n",
    "    for k, v in df_optuna.select(pl.all().cast(pl.Utf8))\n",
    "    .select([\"experiment_id\", \"task_id\", \"model_type\"])\n",
    "    .unique()\n",
    "    .to_dict(as_series=False)\n",
    "    .items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction vs Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(\n",
    "    experiment_id=Dropdown(options=unique_id_values[\"experiment_id\"], description=\"Experiment ID:\"),\n",
    "    task_id=Dropdown(options=unique_id_values[\"task_id\"], description=\"Task ID:\"),\n",
    "    training_id=Dropdown(options=unique_id_values[\"training_id\"], description=\"Split ID:\"),\n",
    ")\n",
    "def plot_predictions_vs_ground_truth(experiment_id, task_id, training_id):\n",
    "    filtered_df = df_predictions.filter(\n",
    "        (pl.col(\"experiment_id\") == int(experiment_id))\n",
    "        & (pl.col(\"task_id\") == int(task_id))\n",
    "        & (pl.col(\"training_id\") == training_id)\n",
    "    )\n",
    "\n",
    "    # Create line data for diagonal reference line\n",
    "    line_data = pl.DataFrame(\n",
    "        {\n",
    "            \"x\": [\n",
    "                df_predictions[\"target\"].min(),\n",
    "                df_predictions[\"target\"].max(),\n",
    "            ],\n",
    "            \"y\": [\n",
    "                df_predictions[\"target\"].min(),\n",
    "                df_predictions[\"target\"].max(),\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Create the main chart\n",
    "    main_chart = (\n",
    "        alt.Chart(filtered_df)\n",
    "        .mark_point()\n",
    "        .encode(\n",
    "            x=alt.X(\"target\", title=\"Ground truth\"),\n",
    "            y=alt.Y(\"prediction\", title=\"Prediction\"),\n",
    "            color=\"split\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create the diagonal line layer\n",
    "    line_layer = alt.Chart(line_data).mark_line(strokeDash=[6, 4], color=\"black\").encode(x=\"x\", y=\"y\")\n",
    "\n",
    "    # Combine the main chart with the line layer\n",
    "    final_chart = main_chart + line_layer\n",
    "\n",
    "    # Apply configurations\n",
    "    final_chart = final_chart.properties(width=600, height=400).configure_axis(titleFontSize=14, labelFontSize=12)\n",
    "\n",
    "    display(final_chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(\n",
    "    experiment_id=Dropdown(options=unique_id_values[\"experiment_id\"], description=\"Experiment ID:\"),\n",
    "    task_id=Dropdown(options=unique_id_values[\"task_id\"], description=\"Task ID:\"),\n",
    "    training_id=Dropdown(options=unique_id_values[\"training_id\"], description=\"Split ID:\"),\n",
    "    fi_type=Dropdown(options=unique_id_values_feature_importance[\"fi_type\"], description=\"FI Type:\"),\n",
    ")\n",
    "def plot_feature_importance(experiment_id, task_id, training_id, fi_type):\n",
    "    df_fi_plot = df_feature_importances.filter(\n",
    "        (pl.col(\"experiment_id\") == int(experiment_id))\n",
    "        & (pl.col(\"task_id\") == int(task_id))\n",
    "        & (pl.col(\"training_id\") == training_id)\n",
    "        & (pl.col(\"fi_type\") == fi_type)\n",
    "    )\n",
    "\n",
    "    chart_fi = (\n",
    "        alt.Chart(df_fi_plot)\n",
    "        .mark_bar()\n",
    "        .encode(\n",
    "            x=alt.X(\n",
    "                \"feature\",\n",
    "                title=\"Feature\",\n",
    "                sort=alt.SortField(\"importance\", order=\"descending\"),\n",
    "            ),\n",
    "            y=alt.Y(\"importance\", title=\"Importance\"),\n",
    "            tooltip=[\"feature\", \"importance\"],\n",
    "        )\n",
    "        .properties(title=\"Feature Importance\", width=600, height=400)\n",
    "    )\n",
    "\n",
    "    display(chart_fi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna Insights\n",
    "\n",
    "### Number of Unique Trials by Model Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by experiment_id, task_id, and model_type\n",
    "df_chart_optuna_count = (\n",
    "    df_optuna.group_by([\"experiment_id\", \"task_id\", \"model_type\"])\n",
    "    .agg(pl.col(\"trial\").n_unique().alias(\"trial_count\"))\n",
    "    .sort([\"task_id\", \"experiment_id\"])\n",
    ")\n",
    "\n",
    "# Create the base chart\n",
    "base = (\n",
    "    alt.Chart(df_chart_optuna_count)\n",
    "    .mark_bar()\n",
    "    .encode(\n",
    "        x=alt.X(\"model_type:N\", title=\"Model Type\", axis=alt.Axis(labelAngle=-45)),\n",
    "        y=alt.Y(\"trial_count:Q\", title=\"Number of Unique Trials\"),\n",
    "        color=alt.Color(\"model_type:N\", legend=None),\n",
    "    )\n",
    "    .properties(width=180, height=120)\n",
    ")\n",
    "\n",
    "# Create the faceted chart\n",
    "chart_optuna_count = base.facet(row=\"task_id:N\", column=\"experiment_id:N\").properties(\n",
    "    title=\"Number of Unique Trials by Model Type, Task ID, and Experiment ID\"\n",
    ")\n",
    "\n",
    "# Adjust the spacing of the facets\n",
    "chart_optuna_count = chart_optuna_count.configure_facet(spacing=10)\n",
    "display(chart_optuna_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna Trials: Object Value and Best Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_optuna_trials(df, direction=\"maximize\"):\n",
    "    if direction == \"maximize\":\n",
    "        df_optuna_trials_best = (\n",
    "            df.with_columns(pl.col(\"value\").cum_max().alias(\"cummax\"))\n",
    "            .filter(pl.col(\"value\") == pl.col(\"cummax\"))\n",
    "            .drop(\"cummax\")\n",
    "        )\n",
    "    else:\n",
    "        df_optuna_trials_best = (\n",
    "            df.with_columns(pl.col(\"value\").cum_min().alias(\"cummin\"))\n",
    "            .filter(pl.col(\"value\") == pl.col(\"cummin\"))\n",
    "            .drop(\"cummin\")\n",
    "        )\n",
    "\n",
    "    return df_optuna_trials_best\n",
    "\n",
    "\n",
    "@interact(\n",
    "    experiment_id=Dropdown(options=unique_id_values[\"experiment_id\"], description=\"Experiment ID:\"),\n",
    "    task_id=Dropdown(options=unique_id_values[\"task_id\"], description=\"Task ID:\"),\n",
    ")\n",
    "def plot_optuna_trials(experiment_id, task_id):\n",
    "    df_optuna_filtered = df_optuna.filter(\n",
    "        (pl.col(\"experiment_id\") == int(experiment_id)) & (pl.col(\"task_id\") == int(task_id))\n",
    "    )\n",
    "\n",
    "    df_best_optuna_trails = get_best_optuna_trials(df_optuna_filtered, \"minimize\")\n",
    "\n",
    "    # Create the scatter plot for object values\n",
    "    scatter = (\n",
    "        alt.Chart(df_optuna_filtered)\n",
    "        .mark_point(size=60)\n",
    "        .encode(\n",
    "            x=\"trial:Q\",\n",
    "            y=alt.Y(\"value:Q\", scale=alt.Scale(type=\"log\")),\n",
    "            color=alt.Color(\"model_type:N\", legend=alt.Legend(title=\"Model Type\")),\n",
    "            tooltip=[\"trial\", \"value\", \"model_type\"],\n",
    "        )\n",
    "        .properties(width=600, height=400)\n",
    "    )\n",
    "\n",
    "    # Create the line plot for best values\n",
    "    line = (\n",
    "        alt.Chart(df_best_optuna_trails)\n",
    "        .mark_line(color=\"green\")\n",
    "        .encode(x=\"trial:Q\", y=alt.Y(\"value:Q\", scale=alt.Scale(type=\"log\")))\n",
    "    )\n",
    "\n",
    "    # Combine the scatter and line plots\n",
    "    chart_optuna_best_value = (scatter + line).properties(title=\"Optuna Trials: Object Value and Best Value\")\n",
    "\n",
    "    display(chart_optuna_best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(\n",
    "    experiment_id=Dropdown(options=unique_id_values[\"experiment_id\"], description=\"Experiment ID:\"),\n",
    "    task_id=Dropdown(options=unique_id_values[\"task_id\"], description=\"Task ID:\"),\n",
    "    model_type=Dropdown(options=unique_id_values_optuna[\"model_type\"], description=\"Model:\"),\n",
    ")\n",
    "def plot_optuna_hyperparameters(experiment_id, task_id, model_type):\n",
    "    df_optuna_hp = df_optuna.filter(\n",
    "        (pl.col(\"experiment_id\") == int(experiment_id))\n",
    "        & (pl.col(\"task_id\") == int(task_id))\n",
    "        & (pl.col(\"model_type\") == model_type)\n",
    "    )\n",
    "\n",
    "    param_list = df_optuna_hp.select(pl.col(\"hyper_param\")).unique().to_series().to_list()\n",
    "    param_list = sorted(param_list)\n",
    "    num_groups = len(param_list)\n",
    "    plots_per_row = 2\n",
    "    num_rows = (num_groups // plots_per_row) + (num_groups % plots_per_row > 0)\n",
    "\n",
    "    base_optuna_hp = (\n",
    "        alt.Chart(df_optuna_hp.to_pandas())  # convert to pandas for Altair\n",
    "        .mark_point()\n",
    "        .encode(\n",
    "            x=alt.X(\"param_value:Q\", title=\"Parameter Value\"),\n",
    "            y=alt.Y(\"value:Q\", title=\"Target Metric\"),\n",
    "            color=alt.Color(\n",
    "                \"trial:Q\",\n",
    "                scale=alt.Scale(scheme=\"blues\"),\n",
    "                legend=alt.Legend(title=\"Trial\"),\n",
    "            ),\n",
    "            tooltip=[\"hyper_param\", \"param_value\", \"value\", \"trial\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    charts_optuna_hp = alt.vconcat()\n",
    "    for row in range(num_rows):\n",
    "        row_charts = alt.hconcat()\n",
    "        for col in range(plots_per_row):\n",
    "            idx = row * plots_per_row + col\n",
    "            if idx < num_groups:\n",
    "                param = param_list[idx]\n",
    "                chart_optuna_hp = base_optuna_hp.transform_filter(alt.datum.hyper_param == param).properties(\n",
    "                    title=param, width=300, height=200\n",
    "                )\n",
    "                row_charts |= chart_optuna_hp\n",
    "        charts_optuna_hp &= row_charts\n",
    "\n",
    "    final_chart_optuna_hp = charts_optuna_hp.resolve_scale(color=\"independent\")\n",
    "\n",
    "    display(final_chart_optuna_hp)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
