{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Octopus","text":"Homepage \u00a0\u2022\u00a0 User Guide \u00a0\u2022\u00a0 Documentation \u00a0\u2022\u00a0 Contribute"},{"location":"#octopus","title":"Octopus","text":"<p>Octopus is a lightweight AutoML framework specifically designed for small datasets (&lt;1k samples) and with high dimensionality (number of features). The goal of Octopus is to speed up machine learning projects and to increase the reliability of results in the context of small datasets.</p> <p>What distinguishes Octopus from others</p> <ul> <li>Nested cross-validation (CV)</li> <li>Performance on small datasets</li> <li>No information leakage</li> <li>No data split mistakes</li> <li>Constrained regularization</li> <li>Ensembling, optimized for (nested) CV</li> <li>Simplicity</li> <li>Time to event</li> <li>Testing system (branching workflows)</li> <li>Reporting based on nested CV</li> <li>Test predictions over all samples</li> </ul>"},{"location":"#hardware","title":"Hardware","text":"<p>For maximum speed it is recommended to run Octopus on a compute node with $n\\times m$ CPUS for a $n \\times m$ nested cross validation. Octopus development is done, for example, on a c5.9xlarge EC2 instance.</p>"},{"location":"#installation","title":"Installation","text":"<p>Package Installation works via <code>pip</code> or any other standard Python package manager:</p> <pre><code>    pip install octopus-automl\n\n    # Install with extras\n    pip install \"octopus-automl[autogluon]\"     # AutoGluon reference\n    pip install \"octopus-automl[boruta]\"        # Boruta feature selection\n    pip install \"octopus-automl[sfs]\"           # SequentialFeatureSelector feature selection\n    pip install \"octopus-automl[survival]\"      # Support time-to-event / survival analysis\n    pip install \"octopus-automl[examples]\"      # Dependencies for running examples\n\n    # Install with more than one extras, e.g.\n    pip install \"octopus-automl[autogluon,examples]\"\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"[Unreleased]","text":"<ul> <li>refactor: rename sequence to workflow</li> <li>changed name of output directory</li> </ul>"},{"location":"changelog/#010-","title":"[0.1.0] -","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Added <code>num_features</code>, <code>cat_nominal_features</code>, and <code>cat_ordinal_features</code> properties to OctoData class to retrieve feature columns by type</li> </ul>"},{"location":"contributing/","title":"Contributing to Octopus","text":"<p>All contributions to Octopus are welcome! Bug fixes, new features, docs improvements, typo corrections - everything helps.</p>"},{"location":"contributing/#quick-start","title":"Quick Start","text":"<ol> <li> <p>Fork and clone the repository</p> </li> <li> <p>Set up your development environment (Python 3.12 only):</p> </li> </ol> <pre><code>conda create -n octopus-dev python=3.12\nconda activate octopus-dev\nuv sync --extra dev\n</code></pre> <p>Note: We use uv for fast and reliable dependency management.</p> <ol> <li>Install pre-commit hooks:</li> </ol> <pre><code>pre-commit install\npre-commit install --hook-type commit-msg\n</code></pre> <ol> <li>Create a feature branch:</li> </ol> <pre><code>git checkout -b &lt;type&gt;/&lt;issue&gt;_&lt;description&gt;\n# Example: git checkout -b feat/123_add-ensemble-selection\n</code></pre>"},{"location":"contributing/#development-workflow","title":"Development Workflow","text":"<ul> <li>Make your changes</li> <li>Run tests and quality checks (see below)</li> <li>Update CHANGELOG.md</li> <li>Commit with semantic message</li> <li>Push and create PR</li> </ul>"},{"location":"contributing/#package-management","title":"Package Management","text":"<p>We use uv for dependency management. All dependencies are defined in <code>pyproject.toml</code> and locked in <code>uv.lock</code>.</p>"},{"location":"contributing/#adding-a-new-package","title":"Adding a New Package","text":"<pre><code>uv add &lt;package-name&gt;\n# Example: uv add pandas\n</code></pre>"},{"location":"contributing/#updating-the-lock-file","title":"Updating the Lock File","text":"<p>After manually editing <code>pyproject.toml</code>, update the lock file:</p> <pre><code>uv lock\n</code></pre>"},{"location":"contributing/#syncing-your-environment","title":"Syncing Your Environment","text":"<p>After pulling changes from the repository:</p> <pre><code>uv sync --extra dev\n</code></pre> <p>This installs all dependencies according to the lock file, ensuring everyone has the same versions.</p>"},{"location":"contributing/#testing-and-quality","title":"Testing and Quality","text":"<ul> <li>Run tests:</li> </ul> <pre><code>pytest\n</code></pre> <ul> <li>Run specific test module:</li> </ul> <pre><code>pytest tests/data/test_validator.py -v\n</code></pre> <ul> <li>Run with coverage:</li> </ul> <pre><code>pytest --cov=octopus --cov-report=html\n</code></pre> <ul> <li>Run all quality checks:</li> </ul> <pre><code>pre-commit run --all-files\n</code></pre> <ul> <li>Individual tools:</li> </ul> <pre><code>ruff check .      # Linting\nruff format .     # Formatting\ntypos             # Spell checking\n</code></pre>"},{"location":"contributing/#branch-naming","title":"Branch Naming","text":"<p>Format: <code>&lt;type&gt;/&lt;issue&gt;_&lt;slug&gt;</code></p> <p>Valid types:</p> <ul> <li><code>feat</code> - New features</li> <li><code>fix</code> - Bug fixes</li> <li><code>docs</code> - Documentation changes</li> <li><code>style</code> - Formatting, missing semicolons, etc. (no code change)</li> <li><code>refactor</code> - Code restructuring without changing behavior</li> <li><code>test</code> - Adding or updating tests</li> <li><code>chore</code> - Maintenance tasks, dependency updates</li> <li><code>perf</code> - Performance improvements</li> <li><code>ci</code> - CI/CD configuration changes</li> <li><code>build</code> - Build system or external dependency changes</li> <li><code>revert</code> - Reverting previous commits</li> </ul> <p>Examples:</p> <ul> <li>\u2713 <code>feat/90_add-ensemble-selection</code></li> <li>\u2713 <code>fix/124_memory-leak</code></li> <li>\u2713 <code>docs/update-readme</code></li> <li>\u2713 <code>ci/138_add-pre-commit-hooks</code></li> <li>\u2717 <code>Add-New-Feature</code> (wrong format)</li> </ul>"},{"location":"contributing/#commit-messages","title":"Commit Messages","text":"<p>Format: <code>&lt;type&gt;: &lt;description&gt;</code></p> <p>Valid types: See Branch Naming section for complete list of types and their descriptions.</p> <p>Examples:</p> <ul> <li>\u2713 <code>feat: add ensemble selection method</code></li> <li>\u2713 <code>fix: resolve memory leak in data loader</code></li> <li>\u2713 <code>docs: update installation guide</code></li> <li>\u2713 <code>ci: add pre-commit validation hooks</code></li> </ul> <p>Auto-close issues:</p> <ul> <li><code>fixes #123</code> \u2192 for bugs</li> <li><code>resolves #123</code> \u2192 for features</li> <li><code>closes #123</code> \u2192 for tasks/docs</li> </ul> <p>Full example:</p> <pre><code>git commit -m \"feat: add ensemble selection resolves #90\"\n</code></pre>"},{"location":"contributing/#changelogmd","title":"CHANGELOG.md","text":"<p>Required: Each PR must update CHANGELOG.md</p> <ol> <li> <p>Add entry under <code>## [Unreleased]</code></p> </li> <li> <p>Use appropriate section:</p> </li> <li> <p>Added - New features</p> </li> <li>Changed - Changes to existing functionality</li> <li>Deprecated - Soon-to-be removed features</li> <li>Removed - Removed features</li> <li>Fixed - Bug fixes</li> <li> <p>Security - Vulnerability fixes</p> </li> <li> <p>Format:</p> </li> </ol> <pre><code>## [Unreleased]\n\n### Added\n\n- New ensemble selection method for improved performance (#123)\n\n### Fixed\n\n- Memory leak in data loader (#124)\n</code></pre> <p>Tips:</p> <ul> <li>Write from user perspective</li> <li>Reference issue/PR number</li> <li>Be concise but clear</li> </ul>"},{"location":"contributing/#code-style","title":"Code Style","text":""},{"location":"contributing/#docstrings","title":"Docstrings","text":"<p>Follow Google Style Guide:</p> <pre><code>def example_function(arg1: str, arg2: int) -&gt; bool:\n    \"\"\"Short one-line summary.\n\n    Optional longer description if needed.\n\n    Args:\n        arg1: Description of arg1.\n        arg2: Description of arg2.\n\n    Returns:\n        Description of return value.\n\n    Raises:\n        ValueError: When something goes wrong.\n    \"\"\"\n    ...\n</code></pre> <p>Notes:</p> <ul> <li>Use type hints (don't repeat them in docstrings)</li> <li>One-line summary first</li> <li>Use double backticks for literals: <code></code>MyString<code></code></li> </ul>"},{"location":"contributing/#attrs-classes","title":"attrs Classes","text":"<pre><code>from attrs import define\n\n@define\nclass DataConfig:\n    \"\"\"Configuration for data processing.\"\"\"\n\n    n_samples: int\n    \"\"\"Number of samples in the dataset.\"\"\"\n\n    n_features: int\n    \"\"\"Number of features in the dataset.\"\"\"\n\n    @n_samples.validator\n    def _validate_n_samples(self, attribute, value):\n        \"\"\"Validate n_samples is positive.\"\"\"\n        if value &lt;= 0:\n            raise ValueError(\"n_samples must be positive\")\n</code></pre> <p>Conventions:</p> <ul> <li>Attribute docstrings below the declaration</li> <li>Blank line between attributes</li> <li>Name validators: <code>_validate_&lt;attribute_name&gt;</code></li> <li>Name defaults: <code>_default_&lt;attribute_name&gt;</code></li> </ul>"},{"location":"contributing/#package-structure","title":"Package Structure","text":"<pre><code>octopus/\n\u251c\u2500\u2500 data/       # Data handling and validation\n\u251c\u2500\u2500 models/     # Model definitions and wrappers\n\u251c\u2500\u2500 modules/    # Feature selection and optimization\n\u251c\u2500\u2500 metrics/    # Performance metrics\n\u2514\u2500\u2500 config/     # Configuration management\n</code></pre> <p>When adding new functionality:</p> <ul> <li>Follow existing package structure</li> <li>Import public APIs into high-level namespaces</li> <li>Consider small dataset optimization (&lt;1k samples)</li> </ul>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Main branch stability: - All commits on the <code>main</code> branch should be stable - PRs are squash-merged or rebased to maintain clean history</p> <p>Commit organization: - Multiple commits in a PR are allowed - Should be consolidated into a reasonable contribution - Each commit should be logical and buildable - Avoid WIP commits, fixups, or \"oops\" commits</p> <p>Good PR structure: <pre><code>\u2713 feat/123_add-feature\n  - Add core functionality\n  - Add tests\n  - Update documentation\n\n\u2717 feat/123_add-feature\n  - WIP initial try\n  - fix typo\n  - oops forgot file\n  - actually fix it\n  - revert previous\n</code></pre></p> <p>Tips: - Squash small fixups before submitting - Use interactive rebase to clean up history: <code>git rebase -i main</code> - Each commit should pass tests - Maintainers may squash-merge if needed</p>"},{"location":"contributing/#syncing-your-pr","title":"Syncing Your PR","text":"<p>If the main branch has moved ahead:</p> <pre><code># Fetch latest changes\ngit fetch upstream\n\n# Rebase (recommended for clean history)\ngit rebase upstream/main\n\n# Or merge (if rebase is too complex)\ngit merge upstream/main\n</code></pre> <p>Note: We prefer rebase for linear history, but may squash-merge your PR if needed.</p>"},{"location":"contributing/#developer-tools","title":"Developer Tools","text":"Tool Purpose uv Dependency management ruff Linting and formatting pydoclint Docstring checking pyupgrade Python syntax upgrading typos Spell checking pytest Testing pytest-cov Test coverage pre-commit Git hooks orchestration <p>All tools run automatically via pre-commit hooks and CI/CD.</p>"},{"location":"contributing/#questions","title":"Questions?","text":"<ul> <li>Open an issue: GitHub Issues</li> <li>Contact maintainers: CONTRIBUTORS.md</li> </ul> <p>Thank you for contributing to Octopus!</p>"},{"location":"contributors/","title":"Contributors","text":""},{"location":"contributors/#authors","title":"Authors","text":"<ul> <li>Andreas Wurl (Merck Healthcare KGaA, Darmstadt, Germany),  Github</li> <li>Nils Haase (Merck KGaA, Darmstadt, Germany),  Github</li> </ul>"},{"location":"contributors/#contributors_1","title":"Contributors","text":"<ul> <li>Kathrin Skubch (Merck KGaA, Darmstadt, Germany)  Github</li> <li>Mathias Winkel (Merck KGaA, Darmstadt, Germany)  Github</li> <li>Alexander V. Hopp (Merck KGaA, Darmstadt, Germany)  Github</li> <li>Abhijna Shridhara Hebbar (Merck Healthcare KGaA, Darmstadt, Germany)  Github</li> </ul>"},{"location":"faq/","title":"FAQ","text":""},{"location":"license/","title":"Octopus License Terms","text":"<pre><code>                             Apache License\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\n</code></pre> <p>TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION</p> <ol> <li> <p>Definitions.</p> <p>\"License\" shall mean the terms and conditions for use, reproduction,   and distribution as defined by Sections 1 through 9 of this document.</p> <p>\"Licensor\" shall mean the copyright owner or entity authorized by   the copyright owner that is granting the License.</p> <p>\"Legal Entity\" shall mean the union of the acting entity and all   other entities that control, are controlled by, or are under common   control with that entity. For the purposes of this definition,   \"control\" means (i) the power, direct or indirect, to cause the   direction or management of such entity, whether by contract or   otherwise, or (ii) ownership of fifty percent (50%) or more of the   outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\"You\" (or \"Your\") shall mean an individual or Legal Entity   exercising permissions granted by this License.</p> <p>\"Source\" form shall mean the preferred form for making modifications,   including but not limited to software source code, documentation   source, and configuration files.</p> <p>\"Object\" form shall mean any form resulting from mechanical   transformation or translation of a Source form, including but   not limited to compiled object code, generated documentation,   and conversions to other media types.</p> <p>\"Work\" shall mean the work of authorship, whether in Source or   Object form, made available under the License, as indicated by a   copyright notice that is included in or attached to the work   (an example is provided in the Appendix below).</p> <p>\"Derivative Works\" shall mean any work, whether in Source or Object   form, that is based on (or derived from) the Work and for which the   editorial revisions, annotations, elaborations, or other modifications   represent, as a whole, an original work of authorship. For the purposes   of this License, Derivative Works shall not include works that remain   separable from, or merely link (or bind by name) to the interfaces of,   the Work and Derivative Works thereof.</p> <p>\"Contribution\" shall mean any work of authorship, including   the original version of the Work and any modifications or additions   to that Work or Derivative Works thereof, that is intentionally   submitted to Licensor for inclusion in the Work by the copyright owner   or by an individual or Legal Entity authorized to submit on behalf of   the copyright owner. For the purposes of this definition, \"submitted\"   means any form of electronic, verbal, or written communication sent   to the Licensor or its representatives, including but not limited to   communication on electronic mailing lists, source code control systems,   and issue tracking systems that are managed by, or on behalf of, the   Licensor for the purpose of discussing and improving the Work, but   excluding communication that is conspicuously marked or otherwise   designated in writing by the copyright owner as \"Not a Contribution.\"</p> <p>\"Contributor\" shall mean Licensor and any individual or Legal Entity   on behalf of whom a Contribution has been received by Licensor and   subsequently incorporated within the Work.</p> </li> <li> <p>Grant of Copyright License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       copyright license to reproduce, prepare Derivative Works of,       publicly display, publicly perform, sublicense, and distribute the       Work and such Derivative Works in Source or Object form.</p> </li> <li> <p>Grant of Patent License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       (except as stated in this section) patent license to make, have made,       use, offer to sell, sell, import, and otherwise transfer the Work,       where such license applies only to those patent claims licensable       by such Contributor that are necessarily infringed by their       Contribution(s) alone or by combination of their Contribution(s)       with the Work to which such Contribution(s) was submitted. If You       institute patent litigation against any entity (including a       cross-claim or counterclaim in a lawsuit) alleging that the Work       or a Contribution incorporated within the Work constitutes direct       or contributory patent infringement, then any patent licenses       granted to You under this License for that Work shall terminate       as of the date such litigation is filed.</p> </li> <li> <p>Redistribution. You may reproduce and distribute copies of the       Work or Derivative Works thereof in any medium, with or without       modifications, and in Source or Object form, provided that You       meet the following conditions:</p> <p>(a) You must give any other recipients of the Work or       Derivative Works a copy of this License; and</p> <p>(b) You must cause any modified files to carry prominent notices       stating that You changed the files; and</p> <p>(c) You must retain, in the Source form of any Derivative Works       that You distribute, all copyright, patent, trademark, and       attribution notices from the Source form of the Work,       excluding those notices that do not pertain to any part of       the Derivative Works; and</p> <p>(d) If the Work includes a \"NOTICE\" text file as part of its       distribution, then any Derivative Works that You distribute must       include a readable copy of the attribution notices contained       within such NOTICE file, excluding those notices that do not       pertain to any part of the Derivative Works, in at least one       of the following places: within a NOTICE text file distributed       as part of the Derivative Works; within the Source form or       documentation, if provided along with the Derivative Works; or,       within a display generated by the Derivative Works, if and       wherever such third-party notices normally appear. The contents       of the NOTICE file are for informational purposes only and       do not modify the License. You may add Your own attribution       notices within Derivative Works that You distribute, alongside       or as an addendum to the NOTICE text from the Work, provided       that such additional attribution notices cannot be construed       as modifying the License.</p> <p>You may add Your own copyright statement to Your modifications and   may provide additional or different license terms and conditions   for use, reproduction, or distribution of Your modifications, or   for any such Derivative Works as a whole, provided Your use,   reproduction, and distribution of the Work otherwise complies with   the conditions stated in this License.</p> </li> <li> <p>Submission of Contributions. Unless You explicitly state otherwise,       any Contribution intentionally submitted for inclusion in the Work       by You to the Licensor shall be under the terms and conditions of       this License, without any additional terms or conditions.       Notwithstanding the above, nothing herein shall supersede or modify       the terms of any separate license agreement you may have executed       with Licensor regarding such Contributions.</p> </li> <li> <p>Trademarks. This License does not grant permission to use the trade       names, trademarks, service marks, or product names of the Licensor,       except as required for reasonable and customary use in describing the       origin of the Work and reproducing the content of the NOTICE file.</p> </li> <li> <p>Disclaimer of Warranty. Unless required by applicable law or       agreed to in writing, Licensor provides the Work (and each       Contributor provides its Contributions) on an \"AS IS\" BASIS,       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or       implied, including, without limitation, any warranties or conditions       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A       PARTICULAR PURPOSE. You are solely responsible for determining the       appropriateness of using or redistributing the Work and assume any       risks associated with Your exercise of permissions under this License.</p> </li> <li> <p>Limitation of Liability. In no event and under no legal theory,       whether in tort (including negligence), contract, or otherwise,       unless required by applicable law (such as deliberate and grossly       negligent acts) or agreed to in writing, shall any Contributor be       liable to You for damages, including any direct, indirect, special,       incidental, or consequential damages of any character arising as a       result of this License or out of the use or inability to use the       Work (including but not limited to damages for loss of goodwill,       work stoppage, computer failure or malfunction, or any and all       other commercial damages or losses), even if such Contributor       has been advised of the possibility of such damages.</p> </li> <li> <p>Accepting Warranty or Additional Liability. While redistributing       the Work or Derivative Works thereof, You may choose to offer,       and charge a fee for, acceptance of support, warranty, indemnity,       or other liability obligations and/or rights consistent with this       License. However, in accepting such obligations, You may act only       on Your own behalf and on Your sole responsibility, not on behalf       of any other Contributor, and only if You agree to indemnify,       defend, and hold each Contributor harmless for any liability       incurred by, or claims asserted against, such Contributor by reason       of your accepting any such warranty or additional liability.</p> </li> </ol> <p>END OF TERMS AND CONDITIONS</p>"},{"location":"concepts/concepts/","title":"Concepts","text":"<p>This section explains the core concepts and methodologies used in Octopus to help you better understand how the tool works and how to use it effectively.</p>"},{"location":"concepts/concepts/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Nested Cross-Validation - Understand the nested CV approach that makes Octopus suitable for small datasets</li> <li>Core Concepts - Key terms, architecture, and how Octopus works internally</li> <li>Understanding Results - How to interpret and use the predictions and metrics from Octopus</li> </ul>"},{"location":"concepts/concepts/#quick-navigation","title":"Quick Navigation","text":"<ul> <li>Nested Cross-Validation - Learn about the unique CV strategy that prevents overfitting</li> <li>Understanding Results - How to read and use Octopus outputs</li> </ul> <p>If you're new to Octopus, we recommend starting with \"Nested Cross-Validation\" to understand why this tool is different.</p>"},{"location":"concepts/nested_cv/","title":"Nested Cross-Validation","text":"<p>To be added.</p>"},{"location":"concepts/understanding_results/","title":"Understanding the Results","text":"<p>To be added.</p>"},{"location":"examples/analyse_study_classification/","title":"Analyze Study (Binary Classification)","text":"<ul> <li>version 0.1</li> <li>3.2.2026</li> </ul>"},{"location":"examples/analyse_study_classification/#todo","title":"ToDo","text":"<ul> <li>[done] Study details </li> <li>[done] Target metric performance on all tasks </li> <li>[done] Selected features summary</li> <li>[done] Model performance on test dataset for a given task</li> <li>[done] AUCROC plots</li> <li>[done] Confusion matrix</li> <li>Individual test feature importances (table + plot)</li> <li>[done] Merged test feature importances (table + plot)</li> <li>Summary confusion matrix</li> <li>creat tests for notebook utils</li> <li>beeswarm plot (individual + merged!)</li> </ul>"},{"location":"examples/analyse_study_classification/#imports","title":"Imports","text":"<pre><code>from octopus.predict import OctoPredict\nfrom octopus.predict.notebook_utils import (\n    show_selected_features,\n    show_study_details,\n    show_target_metric_performance,\n    testset_performance_overview,\n    plot_aucroc,\n    show_confusionmatrix,\n    show_overall_fi_table,\n    show_overall_fi_plot,\n)\n</code></pre>"},{"location":"examples/analyse_study_classification/#input","title":"Input","text":"<pre><code># INPUT: Select study\nstudy_directory = \"../studies/wf_octo_mrmr_octo/\"\n</code></pre>"},{"location":"examples/analyse_study_classification/#study-details","title":"Study Details","text":"<pre><code># Call the utility function to display and validate study details\nstudy_info = show_study_details(study_directory)\n\n# Extract key variables for use in subsequent cells\n# path_study = study_info[\"path\"]\n# config = study_info[\"config\"]\n# ml_type = study_info[\"ml_type\"]\n# n_folds_outer = study_info[\"n_folds_outer\"]\n# workflow_tasks = study_info[\"workflow_tasks\"]\n# outersplit = study_info[\"outersplit_dirs\"]\n# expected_task_ids = study_info[\"expected_task_ids\"]\n# octo_workflow_lst = study_info[\"octo_workflow_tasks\"]\n</code></pre>"},{"location":"examples/analyse_study_classification/#target-metric-performance-for-all-tasks","title":"Target Metric Performance for all  Tasks","text":"<pre><code># Display performance (target metric) for all workflow tasks\nperformance_tables = show_target_metric_performance(study_info, details=False)\n</code></pre>"},{"location":"examples/analyse_study_classification/#selected-features-summary","title":"Selected Features Summary","text":"<pre><code># Display the number of selected features across outer splits and tasks\n# Returns three tables: feature count table, feature frequency table, and raw performance dataframe\n# sort_task and sort_key parameters sort the frequency table by the specified task-key combination\nsort_by_task = None\nsort_by_key = None\nfeature_table, feature_frequency_table, raw_feature_table = show_selected_features(study_info, sort_task=sort_by_task, sort_key=sort_by_key)\n</code></pre>"},{"location":"examples/analyse_study_classification/#model-performance-on-test-dataset-for-a-given-task","title":"Model Performance on Test Dataset for a given Task","text":"<pre><code># Input: selected metrics for performance overview\nmetrics = [\"AUCROC\", \"ACCBAL\", \"ACC\", \"F1\", \"AUCPR\", \"NEGBRIERSCORE\"]\nprint(\"Selected metrics: \", metrics)\n</code></pre>"},{"location":"examples/analyse_study_classification/#test-performance-for-given-task-and-selected-metrics","title":"Test performance for given task and selected metrics","text":"<pre><code># load predictor object\ntask_predictor = OctoPredict(study_path=study_info[\"path\"], task_id=0, results_key=\"best\")\ntestset_performance = testset_performance_overview(predictor=task_predictor, metrics=metrics)\n</code></pre>"},{"location":"examples/analyse_study_classification/#aucroc-plots","title":"AUCROC Plots","text":"<pre><code>plot_aucroc(task_predictor, show_individual=True)\n</code></pre>"},{"location":"examples/analyse_study_classification/#confusion-matrix","title":"Confusion Matrix","text":"<pre><code>show_confusionmatrix(task_predictor, threshold=0.5, metrics=metrics)\n</code></pre>"},{"location":"examples/analyse_study_classification/#test-feature-importances","title":"Test Feature Importances","text":""},{"location":"examples/analyse_study_classification/#calculate-permutation-feature-importances","title":"Calculate Permutation Feature Importances","text":"<pre><code># (A) Permutation feature importances on test data using final models\n# - fi tables are saved in the  study.results dictionary\n# - pdf plots are saved in the results directory of the sequence item\n#\n# calculate pfi for only one experiment\n# task_predictor.calculate_fi_test(fi_type=\"group_permutation\", n_repeat=5, experiment_id=4)\n#\n# calculate pfi for all available experiments\n# - n_repeats has major impact on p-values\n# - high n_repeats lead to long compute times\nprint(\"PFI calculation running.....\")\ntask_predictor.calculate_fi_test(fi_type=\"group_permutation\", n_repeat=3)\n</code></pre> <pre><code>fi_table_overall = show_overall_fi_table(task_predictor, fi_type=\"group_permutation\")\nfi_table_overall.head(10)\n</code></pre> <pre><code>show_overall_fi_plot(task_predictor, fi_type=\"group_permutation\")\n</code></pre>"},{"location":"examples/analyse_study_classification/#calculate-shap-feature-importances","title":"Calculate Shap Feature Importances","text":"<pre><code># (D) Shap feature importances on test data using final models\n# \n# - for highest quality use \"exact\" or \"kernel\"\n# - shap_type could be [\"kernel\", \"permutation\", \"exact\"]\n# - shap_type \"exact\" does not scale well with number of features\n# - shap_type \"permutation\" scales better than \"exact\" but\n#   takes longer for a small number of features\n# - shap_type \"kernel\" does scales better than \"exact\" but is slower than \"permutation\"\n# - fi tables are saved in the  study.results dictionary\n# - pdf plots are saved in the results directory\ntask_predictor.calculate_fi_test(fi_type=\"shap\", shap_type=\"kernel\")\n</code></pre> <pre><code>fi_table_overall = show_overall_fi_table(task_predictor, fi_type=\"shap\")\nfi_table_overall.head(10)\n</code></pre> <pre><code>show_overall_fi_plot(task_predictor, fi_type=\"shap\")\n</code></pre>"},{"location":"examples/basic_classification/","title":"Basic classification","text":"<p>This example demonstrates how to use Octopus to create a machine learning classification model. We will use the breast cancer dataset for this purpose. Please ensure your dataset is clean, with no missing values (<code>NaN</code>), and that all features are numeric.</p> <pre><code>### Necessary imports for this example\nimport os\n</code></pre> <pre><code>from sklearn.datasets import load_breast_cancer\n</code></pre> <pre><code>from octopus import OctoStudy\n</code></pre> <pre><code>### Load and Preprocess Data\nbreast_cancer = load_breast_cancer(as_frame=True)\n</code></pre> <pre><code>df = breast_cancer[\"frame\"].reset_index()\ndf.columns = df.columns.str.replace(\" \", \"_\")\nfeatures = list(breast_cancer[\"feature_names\"])\nfeatures = [feature.replace(\" \", \"_\") for feature in features]\n</code></pre> <pre><code>### Create and run OctoStudy\nstudy = OctoStudy(\n    name=\"basic_classification\",\n    path=os.environ.get(\"STUDIES_PATH\", \"./studies\"),\n    ml_type=\"classification\",\n    target_metric=\"AUCROC\",\n    feature_columns=features,\n    target_columns=[\"target\"],\n    sample_id=\"index\",\n    stratification_column=\"target\",\n)\n</code></pre> <pre><code>study.fit(data=df)\n</code></pre> <pre><code>print(\"Workflow completed\")\n</code></pre>"},{"location":"examples/basic_regression/","title":"Basic regression","text":"<p>This example demonstrates how to use Octopus to create a machine learning regression model. We will use the famous diabetes dataset for this purpose. Please ensure your dataset is clean, with no missing values (<code>NaN</code>), and that all features are numeric.</p> <pre><code>### Necessary imports for this example\nimport os\n</code></pre> <pre><code>from sklearn.datasets import load_diabetes\n</code></pre> <pre><code>from octopus import OctoStudy\n</code></pre> <pre><code>### Load the diabetes dataset\ndiabetes = load_diabetes(as_frame=True)\n</code></pre> <pre><code>### Create and run OctoStudy\nstudy = OctoStudy(\n    name=\"basic_regression\",\n    path=os.environ.get(\"STUDIES_PATH\", \"./studies\"),\n    ml_type=\"regression\",\n    target_metric=\"MAE\",\n    feature_columns=diabetes[\"feature_names\"],\n    target_columns=[\"target\"],\n    sample_id=\"index\",\n)\n</code></pre> <pre><code>study.fit(data=diabetes[\"frame\"].reset_index())\n</code></pre> <pre><code>print(\"Workflow completed\")\n</code></pre>"},{"location":"examples/data_health_check/","title":"Data health check","text":"<pre><code>import os\nimport random\nfrom decimal import Decimal\n</code></pre> <pre><code>import numpy as np\nimport pandas as pd\nfrom attrs import define, field\nfrom sklearn.datasets import make_classification\n</code></pre> <pre><code>from octopus import OctoStudy\nfrom octopus.modules import Octo\n</code></pre> <pre><code>@define\nclass DataFrameGenerator:\n    \"\"\"A class to generate an example DataFrame.\"\"\"\n\n    n_samples: int = 1000\n    n_features: int = 20\n    n_informative: int = 10\n    n_redundant: int = 10\n    n_classes: int = 3\n    random_state: int = None\n\n    df: pd.DataFrame = field(init=False)\n\n    def __attrs_post_init__(self):\n        self._generate_data()\n\n    def _generate_data(self):\n        \"\"\"Generate the classification dataset and initialize the DataFrame.\"\"\"\n        X, y = make_classification(\n            n_samples=self.n_samples,\n            n_features=self.n_features,\n            n_informative=self.n_informative,\n            n_redundant=self.n_redundant,\n            n_classes=self.n_classes,\n            n_clusters_per_class=2,\n            class_sep=5.0,\n            random_state=self.random_state,\n        )\n\n        # Create DataFrame from features\n        feature_names = [f\"feature_{i + 1}\" for i in range(self.n_features)]\n        self.df = pd.DataFrame(X, columns=feature_names)\n\n        # Add the target column\n        self.df[\"target\"] = y\n\n    def add_nan_to_features(self, min_frac=0.02, max_frac=0.8):\n        \"\"\"Add a random proportion of NaNs to the first half of the feature columns.\"\"\"\n        half_features = self.df.columns[: self.n_features // 2]\n        rng = np.random.default_rng(self.random_state)\n        num_rows = len(self.df)\n\n        for feature in half_features:\n            # Determine the number of NaNs to introduce based on the random fraction\n            nan_fraction = rng.uniform(min_frac, max_frac)\n            num_nan = int(nan_fraction * num_rows)\n\n            # Select random indices to set as NaN\n            nan_indices = rng.choice(self.df.index, size=num_nan, replace=False)\n            self.df.loc[nan_indices, feature] = np.nan\n\n    def add_nan_to_target(self, num_nan=10):\n        \"\"\"Add NaN values to the target column.\"\"\"\n        rng = np.random.default_rng(self.random_state)\n        nan_indices = rng.choice(self.df.index, size=num_nan, replace=False)\n        self.df.loc[nan_indices, \"target\"] = np.nan\n\n    def add_id_column(\n        self,\n        column_name=\"id\",\n        prefix=\"ID_\",\n        unique=True,\n        duplicate_factor=2,\n        include_nans=False,\n        nan_ratio=0.1,\n    ):\n        \"\"\"Add an ID column with unique or non-unique identifiers.\"\"\"\n        if prefix is None:\n            # Use integers for IDs\n            ids = np.arange(len(self.df), dtype=\"uint\" if unique else \"int\")\n            if not unique:\n                ids = np.repeat(ids, duplicate_factor)[: len(self.df)]\n        elif unique:\n            # Create unique IDs with prefix\n            ids = [prefix + str(i) for i in self.df.index]\n        else:\n            # Create non-unique IDs with prefix\n            ids = [prefix + str(i) for i in range(len(self.df) // duplicate_factor)]\n            non_unique_ids = ids * duplicate_factor\n            ids = non_unique_ids[: len(self.df)]\n\n        if include_nans:\n            # Determine number of NaNs to include\n            num_nans = int(len(self.df) * nan_ratio)\n            nan_indices = np.random.choice(len(self.df), num_nans, replace=False)\n            ids = np.array(ids, dtype=object)  # Convert to a mutable array\n            ids[nan_indices] = np.nan\n\n        self.df[column_name] = ids\n\n    def add_constant_column(self, column_name=\"one\", value=1):\n        \"\"\"Add a constant column to the DataFrame.\"\"\"\n        self.df[column_name] = value\n\n    def add_decimal_columns(self, column_names: list[str] | None = None, precision=8):\n        \"\"\"Add columns with Decimal data type.\"\"\"\n        if column_names is None:\n            column_names = [\"decimal_1\", \"decimal_2\"]\n\n        rng = np.random.default_rng(self.random_state)\n        for col_name in column_names:\n            random_numbers = rng.random(size=len(self.df))\n            formatted_numbers = [Decimal(f\"{num:.{precision}f}\") for num in random_numbers]\n            self.df[col_name] = formatted_numbers\n\n    def add_inf_columns(self, column_names: list[str] | None = None, num_inf=10):\n        \"\"\"Add columns with infinite values.\"\"\"\n        if column_names is None:\n            column_names = [\"inf_col\"]\n\n        rng = np.random.default_rng(self.random_state)\n        for col_name in column_names:\n            # Initialize the column with random float values\n            self.df[col_name] = rng.standard_normal(size=len(self.df))\n            # Introduce inf values\n            inf_indices = rng.choice(self.df.index, size=num_inf, replace=False)\n            self.df.loc[inf_indices, col_name] = np.inf\n\n    def add_fixed_unique_values_column(self, column_name=\"few_unique\", num_unique=3):\n        \"\"\"Add a column with a specified number of unique values.\"\"\"\n        # Create a list of unique values\n        unique_values = list(range(num_unique))\n        # Repeat these values to fill the column\n        repeated_values = unique_values * (len(self.df) // num_unique + 1)\n        # Assign to the DataFrame, trimming to the correct length\n        self.df[column_name] = repeated_values[: len(self.df)]\n\n    def add_string_mismatch_column(self, column_name=\"mismatch_col\", base_string=\"sample\", error_rate=0.1):\n        \"\"\"Add a column with strings that contain random typos or mismatches, and convert it to categorical.\"\"\"\n\n        def introduce_typo(s):\n            if random.random() &lt; error_rate:\n                # Introduce a typo by swapping two adjacent characters\n                idx = random.randint(0, len(s) - 2)\n                return s[:idx] + s[idx + 1] + s[idx] + s[idx + 2 :]\n            return s\n\n        # Generate the column with potential typos\n        self.df[column_name] = [introduce_typo(base_string) for _ in range(len(self.df))]\n\n        # Convert the column to categorical type\n        self.df[column_name] = self.df[column_name].astype(\"category\")\n\n    def get_dataframe(self):\n        \"\"\"Return the generated DataFrame.\n\n        Returns:\n        - pd.DataFrame: The generated DataFrame.\n        \"\"\"\n        return self.df.copy()\n</code></pre> <pre><code># Error example\ngenerator_errors = DataFrameGenerator(random_state=42)\ngenerator_errors.add_nan_to_features()\ngenerator_errors.add_nan_to_target(num_nan=10)\ngenerator_errors.add_id_column(unique=True, include_nans=True)\ngenerator_errors.add_id_column(column_name=\"sample_id\", prefix=\"Sample\", unique=True, include_nans=True)\ngenerator_errors.add_id_column(\n    column_name=\"stratification\",\n    prefix=\"Strat_\",\n    unique=True,\n    include_nans=False,\n)\ngenerator_errors.add_constant_column()\n# generator_errors.add_decimal_columns()\ngenerator_errors.add_inf_columns()\n</code></pre> <pre><code>df_error = generator_errors.get_dataframe()\n</code></pre> <pre><code># warning example\ngenerator_warnings = DataFrameGenerator(random_state=42, n_classes=2)\ngenerator_warnings.add_fixed_unique_values_column()\ngenerator_warnings.add_id_column(unique=True, include_nans=False)\ngenerator_warnings.add_id_column(column_name=\"sample_id\", prefix=\"Sample\", unique=True, include_nans=False)\ngenerator_warnings.add_id_column(\n    column_name=\"stratification\",\n    prefix=None,\n    unique=True,\n    include_nans=False,\n)\ngenerator_warnings.add_string_mismatch_column()\n</code></pre> <pre><code>df_warnings = generator_warnings.get_dataframe()\n</code></pre> <pre><code>print(df_warnings)\n</code></pre>"},{"location":"examples/data_health_check/#create-and-run-octostudy-with-health-check","title":"Create and run OctoStudy with health check","text":"<pre><code>study = OctoStudy(\n    name=\"health_check\",\n    path=os.environ.get(\"STUDIES_PATH\", \"./studies\"),\n    ml_type=\"classification\",\n    target_metric=\"AUCROC\",\n    feature_columns=df_warnings.columns.drop(\"target\").drop(\"id\").drop(\"sample_id\").drop(\"stratification\").tolist(),\n    target_columns=[\"target\"],\n    sample_id=\"sample_id\",\n    datasplit_type=\"group_sample_and_features\",\n    stratification_column=\"target\",\n    ignore_data_health_warning=False,  # Will stop if health check finds issues\n    outer_parallelization=True,\n    workflow=[\n        Octo(\n            task_id=0,\n            depends_on_task=-1,\n            description=\"step_1_octo\",\n            models=[\"RandomForestClassifier\"],\n            n_trials=3,\n        )\n    ],\n)\n</code></pre> <pre><code>study.fit(data=df_warnings)\n</code></pre>"},{"location":"examples/evaluation_classification/","title":"Evaluation Classification","text":"<p>This notebook provides tools for evaluating classification model results from Octopus studies.</p> <pre><code>import os\nfrom pathlib import Path\n\nimport altair as alt\nimport duckdb\nimport numpy as np\nimport polars as pl\nfrom IPython.display import display\nfrom ipywidgets import Dropdown, interact\nfrom sklearn.metrics import confusion_matrix\n</code></pre>"},{"location":"examples/evaluation_classification/#select-study-directory","title":"Select Study Directory","text":"<p>Update the <code>study_path</code> variable below to point to your study directory:</p> <pre><code># Update this path to your study directory\n# In this example, we use a path relative to the current working directory\nstudies_root = os.environ.get(\"STUDIES_PATH\", \"./studies\")\nstudy_path = os.path.join(studies_root, \"basic_classification\")  # Change this to your study path\n\n# Convert to absolute path to avoid path resolution issues\nstudy_path_abs = Path(study_path).resolve()\nprint(f\"Using study path: {study_path_abs}\")\n\n# Check if path exists\nif not Path(study_path_abs).exists():\n    raise ValueError(f\"Path does not exist: {study_path_abs}. Please update the study_path variable above to point to your actual study directory.\")\n</code></pre>"},{"location":"examples/evaluation_classification/#load-data-using-duckdb","title":"Load Data Using DuckDB","text":"<pre><code># Create DuckDB connection\ncon = duckdb.connect()\nprint(\"DuckDB connection established\")\n</code></pre> <pre><code># Load Optuna data\ndf_optuna = con.execute(\n    f\"SELECT * FROM read_parquet('{study_path_abs}/*/*/optuna*.parquet', hive_partitioning=true)\"\n).pl()\nprint(f\"Loaded {len(df_optuna)} optuna records\")\n</code></pre> <pre><code># Load predictions data\ndf_predictions = con.execute(\n    f\"SELECT * FROM read_parquet('{study_path_abs}/*/*/predictions*.parquet', hive_partitioning=true)\"\n).pl().with_columns(pl.col(\"prediction\").cast(pl.Int64))\n\ndf_predictions_pandas = df_predictions.to_pandas()\nprint(f\"Loaded {len(df_predictions)} prediction records\")\n</code></pre> <pre><code># Load feature importances\ndf_feature_importances = (\n    con.execute(\n        f\"SELECT * FROM read_parquet('{study_path_abs}/*/*/feature-importance*.parquet', hive_partitioning=true)\"\n    )\n    .pl()\n    .with_columns(pl.col(\"experiment_id\").cast(pl.Int64))\n    .with_columns(pl.col(\"task_id\").cast(pl.Int64))\n)\nprint(f\"Loaded {len(df_feature_importances)} feature importance records\")\n</code></pre>"},{"location":"examples/evaluation_classification/#setup-interactive-controls","title":"Setup Interactive Controls","text":"<pre><code># Extract unique values for dropdowns\nunique_id_values = {\n    k: sorted(v)\n    for k, v in df_predictions.select(pl.all().cast(pl.Utf8))\n    .select([\"experiment_id\", \"task_id\", \"training_id\"])\n    .unique()\n    .to_dict(as_series=False)\n    .items()\n}\n\nunique_id_values_feature_importance = {\n    k: sorted(v)\n    for k, v in df_feature_importances.select(pl.all().cast(pl.Utf8))\n    .select([\"fi_type\"])\n    .unique()\n    .to_dict(as_series=False)\n    .items()\n}\n\nunique_id_values_optuna = {\n    k: sorted(v)\n    for k, v in df_optuna.select(pl.all().cast(pl.Utf8))\n    .select([\"experiment_id\", \"task_id\", \"model_type\"])\n    .unique()\n    .to_dict(as_series=False)\n    .items()\n}\n</code></pre>"},{"location":"examples/evaluation_classification/#feature-importance","title":"Feature Importance","text":"<pre><code>@interact(\n    experiment_id=Dropdown(options=unique_id_values[\"experiment_id\"], description=\"Experiment ID:\"),\n    task_id=Dropdown(options=unique_id_values[\"task_id\"], description=\"Task ID:\"),\n    training_id=Dropdown(options=unique_id_values[\"training_id\"], description=\"Training ID:\"),\n    fi_type=Dropdown(options=unique_id_values_feature_importance[\"fi_type\"], description=\"FI Type:\"),\n)\ndef plot_feature_importance(experiment_id, task_id, training_id, fi_type):\n    df_fi_plot = df_feature_importances.filter(\n        (pl.col(\"experiment_id\") == int(experiment_id))\n        &amp; (pl.col(\"task_id\") == int(task_id))\n        &amp; (pl.col(\"training_id\") == training_id)\n        &amp; (pl.col(\"fi_type\") == fi_type)\n    )\n\n    chart_fi = (\n        alt.Chart(df_fi_plot)\n        .mark_bar()\n        .encode(\n            x=alt.X(\n                \"feature\",\n                title=\"Feature\",\n                sort=alt.SortField(\"importance\", order=\"descending\"),\n            ),\n            y=alt.Y(\"importance\", title=\"Importance\"),\n            tooltip=[\"feature\", \"importance\"],\n        )\n        .properties(title=\"Feature Importance\", width=600, height=400)\n    )\n\n    display(chart_fi)\n</code></pre>"},{"location":"examples/evaluation_classification/#confusion-matrix-for-test-split","title":"Confusion Matrix for Test Split","text":"<pre><code>@interact(\n    experiment_id=Dropdown(options=unique_id_values[\"experiment_id\"], description=\"Experiment ID:\"),\n    task_id=Dropdown(options=unique_id_values[\"task_id\"], description=\"Task ID:\"),\n    training_id=Dropdown(options=unique_id_values[\"training_id\"], description=\"Training ID:\"),\n)\ndef plot_confusion_matrix(experiment_id, task_id, training_id):\n    df_confusion_matrix = df_predictions.filter(\n        (pl.col(\"experiment_id\") == int(experiment_id))\n        &amp; (pl.col(\"task_id\") == int(task_id))\n        &amp; (pl.col(\"training_id\") == training_id)\n        &amp; (pl.col(\"split\") == \"test\")\n    )\n\n    y_true = df_confusion_matrix[\"target\"].to_numpy()\n    y_pred = df_confusion_matrix[\"prediction\"].to_numpy()\n\n    class_labels = sorted(set(y_true) | set(y_pred))\n\n    cm = confusion_matrix(y_true, y_pred)\n\n    # Convert confusion matrix to a Polars DataFrame\n    cm_df = pl.DataFrame(\n        {\n            \"true_label\": np.repeat(class_labels, len(class_labels)),\n            \"predicted_label\": np.tile(class_labels, len(class_labels)),\n            \"value\": cm.flatten(),\n        }\n    )\n\n    # Create the Altair chart\n    cm_chart = (\n        alt.Chart(cm_df.to_pandas())\n        .mark_rect()\n        .encode(\n            x=alt.X(\"predicted_label:N\", title=\"Predicted label\"),\n            y=alt.Y(\n                \"true_label:N\",\n                title=\"True label\",\n                sort=alt.EncodingSortField(field=\"true_label\", order=\"descending\"),\n            ),\n            color=alt.Color(\"value:Q\", scale=alt.Scale(scheme=\"blues\")),\n            tooltip=[\"true_label\", \"predicted_label\", \"value\"],\n        )\n        .properties(title=\"Confusion Matrix\", width=400, height=400)\n    )\n\n    # Add text labels\n    cm_text = (\n        alt.Chart(cm_df.to_pandas())\n        .mark_text(baseline=\"middle\")\n        .encode(\n            x=\"predicted_label:N\",\n            y=\"true_label:N\",\n            text=\"value:Q\",\n            color=alt.condition(\n                alt.datum.value &gt; cm_df[\"value\"].max() / 2,\n                alt.value(\"white\"),\n                alt.value(\"black\"),\n            ),\n        )\n    )\n\n    # Combine the heatmap and text layers\n    cm_final_chart = cm_chart + cm_text\n\n    display(cm_final_chart)\n</code></pre>"},{"location":"examples/evaluation_classification/#optuna-insights","title":"Optuna Insights","text":""},{"location":"examples/evaluation_classification/#number-of-unique-trials-by-model-type","title":"Number of Unique Trials by Model Type","text":"<pre><code># Group by experiment_id, task_id, and model_type\ndf_chart_optuna_count = (\n    df_optuna.group_by([\"experiment_id\", \"task_id\", \"model_type\"])\n    .agg(pl.col(\"trial\").n_unique().alias(\"trial_count\"))\n    .sort([\"task_id\", \"experiment_id\"])\n)\n\n# Create the base chart\nbase = (\n    alt.Chart(df_chart_optuna_count)\n    .mark_bar()\n    .encode(\n        x=alt.X(\"model_type:N\", title=\"Model Type\", axis=alt.Axis(labelAngle=-45)),\n        y=alt.Y(\"trial_count:Q\", title=\"Number of Unique Trials\"),\n        color=alt.Color(\"model_type:N\", legend=None),\n    )\n    .properties(width=180, height=120)\n)\n\n# Create the faceted chart\nchart_optuna_count = base.facet(row=\"task_id:N\", column=\"experiment_id:N\").properties(\n    title=\"Number of Unique Trials by Model Type, Task ID, and Experiment ID\"\n)\n\n# Adjust the spacing of the facets\nchart_optuna_count = chart_optuna_count.configure_facet(spacing=10)\ndisplay(chart_optuna_count)\n</code></pre>"},{"location":"examples/evaluation_classification/#optuna-trials-object-value-and-best-value","title":"Optuna Trials: Object Value and Best Value","text":"<pre><code>def get_best_optuna_trials(df, direction=\"maximize\"):\n    if direction == \"maximize\":\n        df_optuna_trials_best = (\n            df.with_columns(pl.col(\"value\").cum_max().alias(\"cummax\"))\n            .filter(pl.col(\"value\") == pl.col(\"cummax\"))\n            .drop(\"cummax\")\n        )\n    else:\n        df_optuna_trials_best = (\n            df.with_columns(pl.col(\"value\").cum_min().alias(\"cummin\"))\n            .filter(pl.col(\"value\") == pl.col(\"cummin\"))\n            .drop(\"cummin\")\n        )\n\n    return df_optuna_trials_best\n\n\n@interact(\n    experiment_id=Dropdown(options=unique_id_values[\"experiment_id\"], description=\"Experiment ID:\"),\n    task_id=Dropdown(options=unique_id_values[\"task_id\"], description=\"Task ID:\"),\n)\ndef plot_optuna_trials(experiment_id, task_id):\n    df_optuna_filtered = df_optuna.filter(\n        (pl.col(\"experiment_id\") == int(experiment_id)) &amp; (pl.col(\"task_id\") == int(task_id))\n    )\n\n    df_best_optuna_trails = get_best_optuna_trials(df_optuna_filtered, \"minimize\")\n\n    # Create the scatter plot for object values\n    scatter = (\n        alt.Chart(df_optuna_filtered)\n        .mark_point(size=60)\n        .encode(\n            x=\"trial:Q\",\n            y=alt.Y(\"value:Q\", scale=alt.Scale(type=\"log\")),\n            color=alt.Color(\"model_type:N\", legend=alt.Legend(title=\"Model Type\")),\n            tooltip=[\"trial\", \"value\", \"model_type\"],\n        )\n        .properties(width=600, height=400)\n    )\n\n    # Create the line plot for best values\n    line = (\n        alt.Chart(df_best_optuna_trails)\n        .mark_line(color=\"green\")\n        .encode(x=\"trial:Q\", y=alt.Y(\"value:Q\", scale=alt.Scale(type=\"log\")))\n    )\n\n    # Combine the scatter and line plots\n    chart_optuna_best_value = (scatter + line).properties(title=\"Optuna Trials: Object Value and Best Value\")\n\n    display(chart_optuna_best_value)\n</code></pre>"},{"location":"examples/evaluation_classification/#optuna-hyperparameters","title":"Optuna Hyperparameters","text":"<pre><code>@interact(\n    experiment_id=Dropdown(options=unique_id_values[\"experiment_id\"], description=\"Experiment ID:\"),\n    task_id=Dropdown(options=unique_id_values[\"task_id\"], description=\"Task ID:\"),\n    model_type=Dropdown(options=unique_id_values_optuna[\"model_type\"], description=\"Model:\"),\n)\ndef plot_optuna_hyperparameters(experiment_id, task_id, model_type):\n    df_optuna_hp = df_optuna.filter(\n        (pl.col(\"experiment_id\") == int(experiment_id))\n        &amp; (pl.col(\"task_id\") == int(task_id))\n        &amp; (pl.col(\"model_type\") == model_type)\n    )\n\n    param_list = df_optuna_hp.select(pl.col(\"hyper_param\")).unique().to_series().to_list()\n    param_list = sorted(param_list)\n    num_groups = len(param_list)\n    plots_per_row = 2\n    num_rows = (num_groups // plots_per_row) + (num_groups % plots_per_row &gt; 0)\n\n    base_optuna_hp = (\n        alt.Chart(df_optuna_hp.to_pandas())  # convert to pandas for Altair\n        .mark_point()\n        .encode(\n            x=alt.X(\"param_value:Q\", title=\"Parameter Value\"),\n            y=alt.Y(\"value:Q\", title=\"Target Metric\"),\n            color=alt.Color(\n                \"trial:Q\",\n                scale=alt.Scale(scheme=\"blues\"),\n                legend=alt.Legend(title=\"Trial\"),\n            ),\n            tooltip=[\"hyper_param\", \"param_value\", \"value\", \"trial\"],\n        )\n    )\n\n    charts_optuna_hp = alt.vconcat()\n    for row in range(num_rows):\n        row_charts = alt.hconcat()\n        for col in range(plots_per_row):\n            idx = row * plots_per_row + col\n            if idx &lt; num_groups:\n                param = param_list[idx]\n                chart_optuna_hp = base_optuna_hp.transform_filter(alt.datum.hyper_param == param).properties(\n                    title=param, width=300, height=200\n                )\n                row_charts |= chart_optuna_hp\n        charts_optuna_hp &amp;= row_charts\n\n    final_chart_optuna_hp = charts_optuna_hp.resolve_scale(color=\"independent\")\n\n    display(final_chart_optuna_hp)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"examples/evaluation_regression/","title":"Evaluation Regression","text":"<p>This notebook provides tools for evaluating regression model results from Octopus studies.</p> <pre><code>import os\nfrom pathlib import Path\n\nimport altair as alt\nimport duckdb\nimport polars as pl\nfrom IPython.display import display\nfrom ipywidgets import Dropdown, interact\n</code></pre>"},{"location":"examples/evaluation_regression/#select-study-directory","title":"Select Study Directory","text":"<p>Update the <code>study_path</code> variable below to point to your study directory:</p> <pre><code># Update this path to your study directory\n# In this example, we use a path relative to the current working directory\nstudies_root = os.environ.get(\"STUDIES_PATH\", \"./studies\")\nstudy_path = os.path.join(studies_root, \"basic_regression\")  # Change this to your study path\n\n# Convert to absolute path to avoid path resolution issues\nstudy_path_abs = Path(study_path).resolve()\nprint(f\"Using study path: {study_path_abs}\")\n\n# Check if path exists\nif not Path(study_path_abs).exists():\n    raise ValueError(f\"Path does not exist: {study_path_abs}. Please update the study_path variable above to point to your actual study directory.\")\n</code></pre>"},{"location":"examples/evaluation_regression/#load-data-using-duckdb","title":"Load Data Using DuckDB","text":"<pre><code># Create DuckDB connection\ncon = duckdb.connect()\nprint(\"DuckDB connection established\")\n</code></pre> <pre><code># Load Optuna data\ndf_optuna = con.execute(\n    f\"SELECT * FROM read_parquet('{study_path_abs}/*/*/optuna*.parquet', hive_partitioning=true)\"\n).pl()\nprint(f\"Loaded {len(df_optuna)} optuna records\")\n</code></pre> <pre><code># Load predictions data\ndf_predictions = con.execute(\n    f\"SELECT * FROM read_parquet('{study_path_abs}/*/*/predictions*.parquet', hive_partitioning=true)\"\n).pl()\n\ndf_predictions_pandas = df_predictions.to_pandas()\nprint(f\"Loaded {len(df_predictions)} prediction records\")\n</code></pre> <pre><code># Load feature importances\ndf_feature_importances = (\n    con.execute(\n        f\"SELECT * FROM read_parquet('{study_path_abs}/*/*/feature-importance*.parquet', hive_partitioning=true)\"\n    )\n    .pl()\n    .with_columns(pl.col(\"experiment_id\").cast(pl.Int64))\n    .with_columns(pl.col(\"task_id\").cast(pl.Int64))\n)\nprint(f\"Loaded {len(df_feature_importances)} feature importance records\")\n</code></pre>"},{"location":"examples/evaluation_regression/#setup-interactive-controls","title":"Setup Interactive Controls","text":"<pre><code># Extract unique values for dropdowns\nunique_id_values = {\n    k: sorted(v)\n    for k, v in df_predictions.select(pl.all().cast(pl.Utf8))\n    .select([\"experiment_id\", \"task_id\", \"training_id\"])\n    .unique()\n    .to_dict(as_series=False)\n    .items()\n}\n\nunique_id_values_feature_importance = {\n    k: sorted(v)\n    for k, v in df_feature_importances.select(pl.all().cast(pl.Utf8))\n    .select([\"fi_type\"])\n    .unique()\n    .to_dict(as_series=False)\n    .items()\n}\n\nunique_id_values_optuna = {\n    k: sorted(v)\n    for k, v in df_optuna.select(pl.all().cast(pl.Utf8))\n    .select([\"experiment_id\", \"task_id\", \"model_type\"])\n    .unique()\n    .to_dict(as_series=False)\n    .items()\n}\n</code></pre>"},{"location":"examples/evaluation_regression/#prediction-vs-ground-truth","title":"Prediction vs Ground Truth","text":"<pre><code>@interact(\n    experiment_id=Dropdown(options=unique_id_values[\"experiment_id\"], description=\"Experiment ID:\"),\n    task_id=Dropdown(options=unique_id_values[\"task_id\"], description=\"Task ID:\"),\n    training_id=Dropdown(options=unique_id_values[\"training_id\"], description=\"Split ID:\"),\n)\ndef plot_predictions_vs_ground_truth(experiment_id, task_id, training_id):\n    filtered_df = df_predictions.filter(\n        (pl.col(\"experiment_id\") == int(experiment_id))\n        &amp; (pl.col(\"task_id\") == int(task_id))\n        &amp; (pl.col(\"training_id\") == training_id)\n    )\n\n    # Create line data for diagonal reference line\n    line_data = pl.DataFrame(\n        {\n            \"x\": [\n                df_predictions[\"target\"].min(),\n                df_predictions[\"target\"].max(),\n            ],\n            \"y\": [\n                df_predictions[\"target\"].min(),\n                df_predictions[\"target\"].max(),\n            ],\n        }\n    )\n\n    # Create the main chart\n    main_chart = (\n        alt.Chart(filtered_df)\n        .mark_point()\n        .encode(\n            x=alt.X(\"target\", title=\"Ground truth\"),\n            y=alt.Y(\"prediction\", title=\"Prediction\"),\n            color=\"split\",\n        )\n    )\n\n    # Create the diagonal line layer\n    line_layer = alt.Chart(line_data).mark_line(strokeDash=[6, 4], color=\"black\").encode(x=\"x\", y=\"y\")\n\n    # Combine the main chart with the line layer\n    final_chart = main_chart + line_layer\n\n    # Apply configurations\n    final_chart = final_chart.properties(width=600, height=400).configure_axis(titleFontSize=14, labelFontSize=12)\n\n    display(final_chart)\n</code></pre>"},{"location":"examples/evaluation_regression/#feature-importance","title":"Feature Importance","text":"<pre><code>@interact(\n    experiment_id=Dropdown(options=unique_id_values[\"experiment_id\"], description=\"Experiment ID:\"),\n    task_id=Dropdown(options=unique_id_values[\"task_id\"], description=\"Task ID:\"),\n    training_id=Dropdown(options=unique_id_values[\"training_id\"], description=\"Split ID:\"),\n    fi_type=Dropdown(options=unique_id_values_feature_importance[\"fi_type\"], description=\"FI Type:\"),\n)\ndef plot_feature_importance(experiment_id, task_id, training_id, fi_type):\n    df_fi_plot = df_feature_importances.filter(\n        (pl.col(\"experiment_id\") == int(experiment_id))\n        &amp; (pl.col(\"task_id\") == int(task_id))\n        &amp; (pl.col(\"training_id\") == training_id)\n        &amp; (pl.col(\"fi_type\") == fi_type)\n    )\n\n    chart_fi = (\n        alt.Chart(df_fi_plot)\n        .mark_bar()\n        .encode(\n            x=alt.X(\n                \"feature\",\n                title=\"Feature\",\n                sort=alt.SortField(\"importance\", order=\"descending\"),\n            ),\n            y=alt.Y(\"importance\", title=\"Importance\"),\n            tooltip=[\"feature\", \"importance\"],\n        )\n        .properties(title=\"Feature Importance\", width=600, height=400)\n    )\n\n    display(chart_fi)\n</code></pre>"},{"location":"examples/evaluation_regression/#optuna-insights","title":"Optuna Insights","text":""},{"location":"examples/evaluation_regression/#number-of-unique-trials-by-model-type","title":"Number of Unique Trials by Model Type","text":"<pre><code># Group by experiment_id, task_id, and model_type\ndf_chart_optuna_count = (\n    df_optuna.group_by([\"experiment_id\", \"task_id\", \"model_type\"])\n    .agg(pl.col(\"trial\").n_unique().alias(\"trial_count\"))\n    .sort([\"task_id\", \"experiment_id\"])\n)\n\n# Create the base chart\nbase = (\n    alt.Chart(df_chart_optuna_count)\n    .mark_bar()\n    .encode(\n        x=alt.X(\"model_type:N\", title=\"Model Type\", axis=alt.Axis(labelAngle=-45)),\n        y=alt.Y(\"trial_count:Q\", title=\"Number of Unique Trials\"),\n        color=alt.Color(\"model_type:N\", legend=None),\n    )\n    .properties(width=180, height=120)\n)\n\n# Create the faceted chart\nchart_optuna_count = base.facet(row=\"task_id:N\", column=\"experiment_id:N\").properties(\n    title=\"Number of Unique Trials by Model Type, Task ID, and Experiment ID\"\n)\n\n# Adjust the spacing of the facets\nchart_optuna_count = chart_optuna_count.configure_facet(spacing=10)\ndisplay(chart_optuna_count)\n</code></pre>"},{"location":"examples/evaluation_regression/#optuna-trials-object-value-and-best-value","title":"Optuna Trials: Object Value and Best Value","text":"<pre><code>def get_best_optuna_trials(df, direction=\"maximize\"):\n    if direction == \"maximize\":\n        df_optuna_trials_best = (\n            df.with_columns(pl.col(\"value\").cum_max().alias(\"cummax\"))\n            .filter(pl.col(\"value\") == pl.col(\"cummax\"))\n            .drop(\"cummax\")\n        )\n    else:\n        df_optuna_trials_best = (\n            df.with_columns(pl.col(\"value\").cum_min().alias(\"cummin\"))\n            .filter(pl.col(\"value\") == pl.col(\"cummin\"))\n            .drop(\"cummin\")\n        )\n\n    return df_optuna_trials_best\n\n\n@interact(\n    experiment_id=Dropdown(options=unique_id_values[\"experiment_id\"], description=\"Experiment ID:\"),\n    task_id=Dropdown(options=unique_id_values[\"task_id\"], description=\"Task ID:\"),\n)\ndef plot_optuna_trials(experiment_id, task_id):\n    df_optuna_filtered = df_optuna.filter(\n        (pl.col(\"experiment_id\") == int(experiment_id)) &amp; (pl.col(\"task_id\") == int(task_id))\n    )\n\n    df_best_optuna_trails = get_best_optuna_trials(df_optuna_filtered, \"minimize\")\n\n    # Create the scatter plot for object values\n    scatter = (\n        alt.Chart(df_optuna_filtered)\n        .mark_point(size=60)\n        .encode(\n            x=\"trial:Q\",\n            y=alt.Y(\"value:Q\", scale=alt.Scale(type=\"log\")),\n            color=alt.Color(\"model_type:N\", legend=alt.Legend(title=\"Model Type\")),\n            tooltip=[\"trial\", \"value\", \"model_type\"],\n        )\n        .properties(width=600, height=400)\n    )\n\n    # Create the line plot for best values\n    line = (\n        alt.Chart(df_best_optuna_trails)\n        .mark_line(color=\"green\")\n        .encode(x=\"trial:Q\", y=alt.Y(\"value:Q\", scale=alt.Scale(type=\"log\")))\n    )\n\n    # Combine the scatter and line plots\n    chart_optuna_best_value = (scatter + line).properties(title=\"Optuna Trials: Object Value and Best Value\")\n\n    display(chart_optuna_best_value)\n</code></pre>"},{"location":"examples/evaluation_regression/#optuna-hyperparameters","title":"Optuna Hyperparameters","text":"<pre><code>@interact(\n    experiment_id=Dropdown(options=unique_id_values[\"experiment_id\"], description=\"Experiment ID:\"),\n    task_id=Dropdown(options=unique_id_values[\"task_id\"], description=\"Task ID:\"),\n    model_type=Dropdown(options=unique_id_values_optuna[\"model_type\"], description=\"Model:\"),\n)\ndef plot_optuna_hyperparameters(experiment_id, task_id, model_type):\n    df_optuna_hp = df_optuna.filter(\n        (pl.col(\"experiment_id\") == int(experiment_id))\n        &amp; (pl.col(\"task_id\") == int(task_id))\n        &amp; (pl.col(\"model_type\") == model_type)\n    )\n\n    param_list = df_optuna_hp.select(pl.col(\"hyper_param\")).unique().to_series().to_list()\n    param_list = sorted(param_list)\n    num_groups = len(param_list)\n    plots_per_row = 2\n    num_rows = (num_groups // plots_per_row) + (num_groups % plots_per_row &gt; 0)\n\n    base_optuna_hp = (\n        alt.Chart(df_optuna_hp.to_pandas())  # convert to pandas for Altair\n        .mark_point()\n        .encode(\n            x=alt.X(\"param_value:Q\", title=\"Parameter Value\"),\n            y=alt.Y(\"value:Q\", title=\"Target Metric\"),\n            color=alt.Color(\n                \"trial:Q\",\n                scale=alt.Scale(scheme=\"blues\"),\n                legend=alt.Legend(title=\"Trial\"),\n            ),\n            tooltip=[\"hyper_param\", \"param_value\", \"value\", \"trial\"],\n        )\n    )\n\n    charts_optuna_hp = alt.vconcat()\n    for row in range(num_rows):\n        row_charts = alt.hconcat()\n        for col in range(plots_per_row):\n            idx = row * plots_per_row + col\n            if idx &lt; num_groups:\n                param = param_list[idx]\n                chart_optuna_hp = base_optuna_hp.transform_filter(alt.datum.hyper_param == param).properties(\n                    title=param, width=300, height=200\n                )\n                row_charts |= chart_optuna_hp\n        charts_optuna_hp &amp;= row_charts\n\n    final_chart_optuna_hp = charts_optuna_hp.resolve_scale(color=\"independent\")\n\n    display(final_chart_optuna_hp)\n</code></pre>"},{"location":"examples/multi_workflow/","title":"Multi workflow","text":"<p>This example demonstrates how to create a workflow using Octopus with the diabetes dataset.</p> <pre><code>### Necessary imports for this example\nimport os\n</code></pre> <pre><code>from sklearn.datasets import load_diabetes\n</code></pre> <pre><code>from octopus import OctoStudy\nfrom octopus.modules import Mrmr, Octo\n</code></pre> <pre><code>### Load the diabetes dataset\ndiabetes = load_diabetes(as_frame=True)\n</code></pre> <pre><code>### Create and run OctoStudy with multi-step workflow\nstudy = OctoStudy(\n    name=\"example_multiworkflow\",\n    path=os.environ.get(\"STUDIES_PATH\", \"./studies\"),\n    ml_type=\"regression\",\n    target_metric=\"R2\",\n    feature_columns=diabetes[\"feature_names\"],\n    target_columns=[\"target\"],\n    sample_id=\"index\",\n    ignore_data_health_warning=True,\n    outer_parallelization=False,\n    run_single_experiment_num=1,\n    workflow=[\n        Octo(\n            description=\"step1_octofull\",\n            task_id=0,\n            depends_on_task=-1,\n            models=[\"ExtraTreesRegressor\", \"RandomForestRegressor\"],\n            n_trials=2,\n            max_features=70,\n        ),\n        Mrmr(\n            description=\"step2_mrmr\",\n            task_id=1,\n            depends_on_task=0,\n            n_features=6,\n            correlation_type=\"rdc\",\n        ),\n        Octo(\n            description=\"step3_octo_reduced\",\n            task_id=2,\n            depends_on_task=1,\n            models=[\"ExtraTreesRegressor\", \"RandomForestRegressor\"],\n            n_trials=1,\n            max_features=70,\n        ),\n    ],\n)\n</code></pre> <pre><code>study.fit(data=diabetes[\"frame\"].reset_index())\n</code></pre> <pre><code>print(\"Multi-workflow completed\")\n</code></pre>"},{"location":"examples/use_own_hyperparameters/","title":"Use own hyperparameters","text":"<p>This example demonstrates how to use Octopus with custom hyperparameters. Instead of letting Optuna automatically search the hyperparameter space, you can define your own hyperparameter ranges for the models. We will use the diabetes dataset for this purpose.</p> <pre><code>### Necessary imports for this example\nimport os\n</code></pre> <pre><code>from sklearn.datasets import load_diabetes\n</code></pre> <pre><code>from octopus import OctoStudy\nfrom octopus.models.hyperparameter import IntHyperparameter\nfrom octopus.modules import Octo\n</code></pre> <pre><code>### Load the diabetes dataset\ndiabetes = load_diabetes(as_frame=True)\n</code></pre> <pre><code>### Create and run OctoStudy with custom hyperparameters\nstudy = OctoStudy(\n    name=\"use_own_hyperparameters_example\",\n    path=os.environ.get(\"STUDIES_PATH\", \"./studies\"),\n    ml_type=\"regression\",\n    target_metric=\"MAE\",\n    feature_columns=diabetes[\"feature_names\"],\n    target_columns=[\"target\"],\n    sample_id=\"index\",\n    ignore_data_health_warning=True,\n    outer_parallelization=False,\n    run_single_experiment_num=0,\n    workflow=[\n        Octo(\n            task_id=0,\n            models=[\"RandomForestRegressor\"],\n            n_trials=3,\n            hyperparameters={\n                \"RandomForestRegressor\": [\n                    IntHyperparameter(name=\"max_depth\", low=2, high=32),\n                    IntHyperparameter(name=\"min_samples_split\", low=2, high=100),\n                ]\n            },\n        ),\n    ],\n)\n</code></pre> <pre><code>study.fit(data=diabetes[\"frame\"].reset_index())\n</code></pre> <pre><code>print(\"Workflow completed\")\n</code></pre> <p>This example demonstrates how to use custom hyperparameters with Octopus. The key difference from the basic example is the use of the <code>hyperparameters</code> parameter in the Octo configuration, where you can define custom hyperparameter ranges for each model using the Hyperparameter class.</p>"},{"location":"examples/wf_multiclass_wine/","title":"Wf multiclass wine","text":"<p>Multiclass classification example using Octopus</p> <p>This example demonstrates how to use Octopus to create a multiclass classification model. We will use the Wine dataset from sklearn for this purpose. The Wine dataset contains 3 classes (wine types) with 13 features. Please ensure your dataset is clean, with no missing values (<code>NaN</code>), and that all features are numeric.</p> <pre><code>import os\n</code></pre> <pre><code>from sklearn.datasets import load_wine\n</code></pre> <pre><code>from octopus import OctoStudy\nfrom octopus.modules import Octo\n</code></pre> <pre><code>### Load and Preprocess Data\nwine = load_wine(as_frame=True)\n</code></pre> <pre><code>df = wine[\"frame\"].reset_index()\ndf.columns = df.columns.str.replace(\" \", \"_\")\nfeatures = list(wine[\"feature_names\"])\nfeatures = [feature.replace(\" \", \"_\") for feature in features]\n</code></pre> <pre><code>print(\"Dataset info:\")\nprint(f\"  Features: {len(features)}\")\nprint(f\"  Samples: {df.shape[0]}\")\nprint(f\"  Classes: {len(wine.target_names)} - {wine.target_names}\")\nprint(f\"  Target distribution: {df['target'].value_counts().sort_index().to_dict()}\")\n</code></pre> <pre><code>### Create and run OctoStudy for multiclass classification\nstudy = OctoStudy(\n    name=\"multiclass_wine\",\n    path=os.environ.get(\"STUDIES_PATH\", \"./studies\"),\n    ml_type=\"multiclass\",\n    target_metric=\"AUCROC_MACRO\",\n    feature_columns=features,\n    target_columns=[\"target\"],\n    sample_id=\"index\",\n    stratification_column=\"target\",\n    metrics=[\"AUCROC_MACRO\", \"AUCROC_WEIGHTED\", \"ACCBAL_MC\"],\n    datasplit_seed_outer=1234,\n    ignore_data_health_warning=True,\n    outer_parallelization=True,\n    run_single_experiment_num=0,  # only process first outer loop experiment, for quick testing\n    workflow=[\n        Octo(\n            task_id=0,\n            depends_on_task=-1,\n            description=\"step_1_octo_multiclass\",\n            load_task=False,\n            n_folds_inner=5,\n            models=[\n                \"ExtraTreesClassifier\",\n                \"RandomForestClassifier\",\n                \"XGBClassifier\",\n                \"CatBoostClassifier\",\n            ],\n            model_seed=0,\n            n_jobs=1,\n            max_outl=0,\n            fi_methods_bestbag=[\"permutation\"],\n            inner_parallelization=True,\n            n_workers=5,\n            n_trials=20,\n        ),\n    ],\n)\n</code></pre> <pre><code>study.fit(data=df)\n</code></pre> <pre><code>print(\"Workflow completed successfully!\")\nprint(f\"Results saved to: {study.output_path}\")\n</code></pre>"},{"location":"examples/wf_octo_autogluon/","title":"Wf octo autogluon","text":"<p>This example demonstrates how to use Octopus with both Octo and AutoGluon modules in a PARALLEL workflow for binary classification. In this case, both modules are run on the same input data.</p> <p>The workflow includes: 1. Octo module 2. AutoGluon module Both modules operate on the same base input data.</p> <pre><code>import os\n</code></pre> <pre><code>import pandas as pd\nfrom sklearn.datasets import make_classification\n</code></pre> <pre><code>from octopus import OctoStudy\nfrom octopus.modules import AutoGluon, Octo\n</code></pre> <pre><code>### Generate Synthetic Binary Classification Dataset\nn_informative = 30\nn_redundant = 30\nn_repeated = 0\n</code></pre> <pre><code>X, y = make_classification(\n    n_samples=300,\n    n_features=1000,\n    n_informative=n_informative,\n    n_redundant=n_redundant,  # generated as random linear combinations of the informative features\n    n_repeated=n_repeated,  # drawn randomly from the informative and the redundant features.\n    n_classes=2,\n    class_sep=1.0,  # Controls class separability (higher = easier)\n    weights=[0.5, 0.5],  # 60% class 0, 40% class 1\n    flip_y=0.01,  # Add 1% label noise for realism\n    random_state=42,\n    shuffle=False,  # ensure order of features\n)\n</code></pre> <pre><code># Create a pandas DataFrame with proper structure\n# Without shuffling, features are ordered: informative, redundant, repeated, then noise\nfeature_names = []\n# Informative features (first n_informative)\nfeature_names.extend([f\"informative_{i}\" for i in range(n_informative)])\n# Redundant features (next n_redundant)\nfeature_names.extend([f\"redundant_{i}\" for i in range(n_redundant)])\n# Repeated features (next n_repeated)\nif n_repeated &gt; 0:\n    feature_names.extend([f\"repeated_{i}\" for i in range(n_repeated)])\n# Remaining features are noise\nn_noise = X.shape[1] - n_informative - n_redundant - n_repeated\nfeature_names.extend([f\"noise_{i}\" for i in range(n_noise)])\n</code></pre> <pre><code>df = pd.DataFrame(X, columns=feature_names)\ndf[\"target\"] = y\ndf = df.reset_index()\n</code></pre> <pre><code># Display dataset information\nprint(\"=== Synthetic Dataset Information ===\")\nprint(f\"Dataset shape: {df.shape}\")\nprint(f\"Features: {len(feature_names)}\")\nprint(f\"Class distribution:\\n{df['target'].value_counts()}\")\nprint(f\"Class balance: {df['target'].value_counts(normalize=True).to_dict()}\")\nprint(\"=====================================\\n\")\n</code></pre>"},{"location":"examples/wf_octo_autogluon/#create-and-run-octostudy-with-parallel-octo-autogluon-workflow","title":"Create and run OctoStudy with PARALLEL Octo + AutoGluon workflow","text":"<pre><code>study = OctoStudy(\n    name=\"wf_octo_autogluon_parallel\",\n    path=os.environ.get(\"STUDIES_PATH\", \"./studies\"),\n    ml_type=\"classification\",\n    target_metric=\"AUCROC\",  # Area Under ROC Curve for binary classification\n    feature_columns=feature_names,\n    target_columns=[\"target\"],\n    sample_id=\"index\",\n    stratification_column=\"target\",  # Ensure balanced splits\n    metrics=[\"AUCROC\", \"ACCBAL\", \"ACC\", \"LOGLOSS\", \"F1\"],\n    n_folds_outer=5,  # 5-fold outer cross-validation\n    ignore_data_health_warning=True,\n    outer_parallelization=True,\n    run_single_experiment_num=-1,  # process all outersplits\n    workflow=[\n        # Step 0: octo\n        Octo(\n            description=\"step_0_octo\",\n            task_id=0,\n            depends_on_task=-1,  # -1 = base input (parallel with AutoGluon)\n            # Cross-validation settings\n            n_folds_inner=5,\n            # Model selection - using tree-based models for feature importance\n            models=[\n                \"ExtraTreesClassifier\",\n            ],\n            fi_methods_bestbag=[\"permutation\"],  # Feature importance method\n            # Parallelization settings\n            inner_parallelization=True,\n            n_workers=5,\n            n_trials=100,  # Number of hyperparameter optimization trials\n            # Constrained hyperparameter optimization\n            # max_features=60,  # Maximum number of features to select\n            # penalty_factor=1.0,  # Complexity penalty for feature selection\n        ),\n        # Step 1: AutoGluon\n        AutoGluon(\n            description=\"step_1_autogluon\",\n            task_id=1,\n            depends_on_task=-1,  # -1 = base input (parallel with Octo)\n            verbosity=3,  # Standard logging\n            time_limit=600,\n            presets=[\"medium_quality\"],  # Balance between speed and accuracy\n            num_bag_folds=5,  # 5-fold bagging for ensemble models\n            included_model_types=[\n                \"XT\",  # ExtraTrees\n            ],\n        ),\n    ],\n)\n</code></pre> <pre><code># Run the study on the synthetic data\nprint(\"Starting Octo + AutoGluon workflow...\")\nstudy.fit(data=df)\n</code></pre> <pre><code>print(\"Workflow completed successfully!\")\nprint(f\"Results saved to: {study.output_path}\")\n</code></pre>"},{"location":"examples/wf_octo_mrmr_octo/","title":"Wf octo mrmr octo","text":"<pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import make_classification\n</code></pre> <pre><code>from octopus import OctoStudy\nfrom octopus.modules import Mrmr, Octo\n</code></pre> <pre><code># Set random seed for reproducibility\nnp.random.seed(42)\n</code></pre> <pre><code># Create artificial classification dataset\n# Parameters chosen to make the problem \"not too easy\":\n# - 30 features total\n# - Only 15 informative features (50%)\n# - 10 redundant features (correlated with informative)\n# - 5 repeated features (duplicates)\n# - class_sep=0.5 for moderate difficulty (lower = harder)\n# - flip_y=0.1 to add 10% label noise\nX, y = make_classification(\n    n_samples=500,\n    n_features=30,\n    n_informative=15,\n    n_redundant=10,\n    n_repeated=5,\n    n_classes=2,\n    n_clusters_per_class=3,\n    weights=[0.6, 0.4],  # Imbalanced classes\n    flip_y=0.1,  # 10% label noise\n    class_sep=0.5,  # Moderate class separation (not too easy)\n    random_state=42,\n)\n</code></pre> <pre><code># Create DataFrame with feature names\nfeature_names = [f\"feature_{i:02d}\" for i in range(30)]\ndf = pd.DataFrame(X, columns=feature_names)\ndf[\"target\"] = y\ndf = df.reset_index()\n</code></pre> <pre><code>print(\"Dataset created:\")\nprint(f\"  Samples: {len(df)}\")\nprint(f\"  Features: {len(feature_names)}\")\nprint(f\"  Class distribution: {df['target'].value_counts().to_dict()}\")\nprint()\n</code></pre> <pre><code># Create and run OctoStudy with sequential multi-step workflow\nstudy = OctoStudy(\n    name=\"wf_octo_mrmr_octo\",\n    ml_type=\"classification\",\n    target_metric=\"ACCBAL\",\n    feature_columns=feature_names,\n    target_columns=[\"target\"],\n    sample_id=\"index\",\n    stratification_column=\"target\",\n    n_folds_outer=5,  # 5 outer folds\n    ignore_data_health_warning=True,\n    outer_parallelization=True,  # Run all outer folds in parallel\n    workflow=[\n        # Task 0: Initial Octo with all features\n        Octo(\n            description=\"step1_octo_full\",\n            task_id=0,\n            depends_on_task=-1,  # First task, depends on input\n            models=[\"ExtraTreesClassifier\"],\n            n_trials=100,  # 100 trials for hyperparameter optimization\n            n_folds_inner=5,  # 5 inner folds\n            max_features=30,  # Use all 30 features\n        ),\n        # Task 1: Feature selection using Mrmr\n        Mrmr(\n            description=\"step2_mrmr\",\n            task_id=1,\n            depends_on_task=0,\n            n_features=15,  # Select top 15 features\n            correlation_type=\"spearman\",\n        ),\n        # Task 2: Octo with reduced features\n        Octo(\n            description=\"step3_octo_reduced\",\n            task_id=2,\n            depends_on_task=1,\n            models=[\"ExtraTreesClassifier\"],\n            n_trials=100,\n            n_folds_inner=5,\n            ensemble_selection=True,\n        ),\n    ],\n)\n</code></pre> <pre><code>print(\"Starting workflow execution...\")\n</code></pre> <pre><code>study.fit(data=df)\n</code></pre> <pre><code>print(\"Workflow completed successfully!\")\nprint(f\"Results saved to: {study.output_path}\")\n</code></pre>"},{"location":"examples/wf_roc_octo/","title":"Wf roc octo","text":"<p>This example demonstrates how to use Octopus with ROC (Remove Outliers and Correlations) and Octo modules for binary classification on the breast cancer dataset. The workflow includes: 1. ROC module for feature correlation analysis and filtering 2. Octo module for model training and hyperparameter optimization</p> <pre><code>import os\n</code></pre> <pre><code>from sklearn.datasets import load_breast_cancer\n</code></pre> <pre><code>from octopus import OctoStudy\nfrom octopus.modules import Octo, Roc\n</code></pre>"},{"location":"examples/wf_roc_octo/#load-and-preprocess-data","title":"Load and Preprocess Data","text":"<p>Load the breast cancer dataset from sklearn This is a binary classification dataset with 30 features Target: 0 = malignant, 1 = benign</p> <pre><code>breast_cancer = load_breast_cancer(as_frame=True)\n</code></pre> <pre><code>df = breast_cancer[\"frame\"].reset_index()\ndf.columns = df.columns.str.replace(\" \", \"_\")\nfeatures = list(breast_cancer[\"feature_names\"])\nfeatures = [feature.replace(\" \", \"_\") for feature in features]\n</code></pre>"},{"location":"examples/wf_roc_octo/#create-and-run-octostudy-with-roc-octo-workflow","title":"Create and run OctoStudy with ROC + Octo workflow","text":"<pre><code>study = OctoStudy(\n    name=\"example_roc_octo\",\n    path=os.environ.get(\"STUDIES_PATH\", \"./studies\"),\n    ml_type=\"classification\",\n    target_metric=\"ACCBAL\",  # Balanced accuracy for binary classification\n    feature_columns=features,\n    target_columns=[\"target\"],\n    sample_id=\"index\",\n    stratification_column=\"target\",\n    metrics=[\"AUCROC\", \"ACCBAL\", \"ACC\", \"LOGLOSS\"],\n    datasplit_seed_outer=1234,\n    ignore_data_health_warning=True,\n    outer_parallelization=True,\n    run_single_experiment_num=0,  # Process only first outer loop experiment for quick testing\n    workflow=[\n        # Step 0: ROC - Remove highly correlated features and apply statistical filtering\n        Roc(\n            description=\"step_0_roc\",\n            task_id=0,\n            depends_on_task=-1,  # First step, no input dependency\n            load_task=False,\n            threshold=0.85,  # Remove features with correlation &gt; 0.85\n            correlation_type=\"spearmanr\",  # Use Spearman correlation\n            filter_type=\"f_statistics\",  # Apply F-statistics filtering\n        ),\n        # Step 1: Octo - Train models on filtered features from ROC step\n        Octo(\n            description=\"step_1_octo\",\n            task_id=1,\n            depends_on_task=0,  # Use output from ROC step\n            load_task=False,\n            # Cross-validation settings\n            n_folds_inner=5,\n            # Model selection\n            models=[\n                \"ExtraTreesClassifier\",\n                # \"RandomForestClassifier\",\n            ],\n            model_seed=0,\n            n_jobs=1,\n            max_outl=0,  # No outlier removal\n            fi_methods_bestbag=[\"permutation\"],  # Feature importance method\n            # Parallelization settings\n            inner_parallelization=True,\n            n_workers=5,\n            # Hyperparameter optimization with Optuna\n            optuna_seed=0,\n            n_optuna_startup_trials=10,\n            resume_optimization=False,\n            n_trials=12,  # Number of hyperparameter optimization trials\n            max_features=12,  # Maximum number of features to select\n            penalty_factor=1.0,\n        ),\n    ],\n)\n</code></pre> <pre><code>study.fit(data=df)\n</code></pre> <pre><code>print(\"Workflow completed successfully!\")\nprint(f\"Results saved to: {study.output_path}\")\n</code></pre>"},{"location":"reference/manager/","title":"octopus.manager","text":"<p>Manager module for Octopus experiments.</p>"},{"location":"reference/manager/#octopus.manager.ExecutionStrategy","title":"<code>ExecutionStrategy</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for experiment execution strategies.</p> Source code in <code>octopus/manager/execution.py</code> <pre><code>class ExecutionStrategy(Protocol):\n    \"\"\"Protocol for experiment execution strategies.\"\"\"\n\n    def execute(\n        self,\n        experiments: list[\"OctoExperiment\"],\n        run_fn: \"Callable[[OctoExperiment], None]\",\n    ) -&gt; None:\n        \"\"\"Execute experiments using this strategy.\"\"\"\n        ...\n</code></pre>"},{"location":"reference/manager/#octopus.manager.ExecutionStrategy.execute","title":"<code>execute(experiments, run_fn)</code>","text":"<p>Execute experiments using this strategy.</p> Source code in <code>octopus/manager/execution.py</code> <pre><code>def execute(\n    self,\n    experiments: list[\"OctoExperiment\"],\n    run_fn: \"Callable[[OctoExperiment], None]\",\n) -&gt; None:\n    \"\"\"Execute experiments using this strategy.\"\"\"\n    ...\n</code></pre>"},{"location":"reference/manager/#octopus.manager.OctoManager","title":"<code>OctoManager</code>","text":"<p>Orchestrates the execution of Octopus experiments.</p> Source code in <code>octopus/manager/core.py</code> <pre><code>@define\nclass OctoManager:\n    \"\"\"Orchestrates the execution of Octopus experiments.\"\"\"\n\n    base_experiments: list[OctoExperiment] = field(validator=[validators.instance_of(list)])\n    workflow: list[Task] = field(validator=[validators.instance_of(list)])\n    log_dir: UPath = field(\n        validator=[validators.instance_of(UPath)],\n    )\n    outer_parallelization: bool = field(default=True, validator=[validators.instance_of(bool)])\n    run_single_experiment_num: int = field(default=-1, validator=[validators.instance_of(int)])\n\n    def run_outer_experiments(self) -&gt; None:\n        \"\"\"Run outer experiments.\"\"\"\n        if not self.base_experiments:\n            logger.error(\"No experiments defined\")\n            raise ValueError(\"No experiments defined\")\n\n        # Initialize Ray upfront to ensure worker setup hooks are registered before any workflows execute.\n        # This is critical for:\n        # 1. Inner parallelization: ML modules (e.g., Octo, AutoGluon) may spawn Ray workers for their\n        #    internal operations (bagging, hyperparameter tuning) even when outer_parallelization=False\n        # 2. Safety checks: The worker setup hook (_check_parallelization_disabled) must be configured\n        #    before any Ray workers start, to detect and prevent thread-level parallelization issues\n        # 3. Lifecycle clarity: Explicit init \u2192 run \u2192 shutdown at the manager level makes the\n        #    Ray lifecycle predictable and easier to reason about\n        init_ray(start_local_if_missing=True)\n\n        resources = ResourceConfig.create(\n            num_experiments=len(self.base_experiments),\n            outer_parallelization=self.outer_parallelization,\n            run_single_experiment_num=self.run_single_experiment_num,\n        )\n        logger.info(f\"Preparing execution | {resources}\")\n\n        try:\n            runner = WorkflowTaskRunner(self.workflow, resources.cpus_per_experiment, self.log_dir)\n            strategy = self._select_strategy(resources.num_workers)\n            strategy.execute(self.base_experiments, runner.run)\n        finally:\n            shutdown_ray()\n\n    def _select_strategy(self, num_workers: int) -&gt; ExecutionStrategy:\n        \"\"\"Select execution strategy based on configuration.\n\n        Args:\n            num_workers: Number of parallel workers for ParallelRayStrategy.\n\n        Returns:\n            Appropriate execution strategy based on configuration.\n        \"\"\"\n        if self.run_single_experiment_num != -1:\n            return SingleExperimentStrategy(self.run_single_experiment_num)\n        if self.outer_parallelization:\n            return ParallelRayStrategy(num_workers, self.log_dir)\n        return SequentialStrategy()\n</code></pre>"},{"location":"reference/manager/#octopus.manager.OctoManager.run_outer_experiments","title":"<code>run_outer_experiments()</code>","text":"<p>Run outer experiments.</p> Source code in <code>octopus/manager/core.py</code> <pre><code>def run_outer_experiments(self) -&gt; None:\n    \"\"\"Run outer experiments.\"\"\"\n    if not self.base_experiments:\n        logger.error(\"No experiments defined\")\n        raise ValueError(\"No experiments defined\")\n\n    # Initialize Ray upfront to ensure worker setup hooks are registered before any workflows execute.\n    # This is critical for:\n    # 1. Inner parallelization: ML modules (e.g., Octo, AutoGluon) may spawn Ray workers for their\n    #    internal operations (bagging, hyperparameter tuning) even when outer_parallelization=False\n    # 2. Safety checks: The worker setup hook (_check_parallelization_disabled) must be configured\n    #    before any Ray workers start, to detect and prevent thread-level parallelization issues\n    # 3. Lifecycle clarity: Explicit init \u2192 run \u2192 shutdown at the manager level makes the\n    #    Ray lifecycle predictable and easier to reason about\n    init_ray(start_local_if_missing=True)\n\n    resources = ResourceConfig.create(\n        num_experiments=len(self.base_experiments),\n        outer_parallelization=self.outer_parallelization,\n        run_single_experiment_num=self.run_single_experiment_num,\n    )\n    logger.info(f\"Preparing execution | {resources}\")\n\n    try:\n        runner = WorkflowTaskRunner(self.workflow, resources.cpus_per_experiment, self.log_dir)\n        strategy = self._select_strategy(resources.num_workers)\n        strategy.execute(self.base_experiments, runner.run)\n    finally:\n        shutdown_ray()\n</code></pre>"},{"location":"reference/manager/#octopus.manager.ParallelRayStrategy","title":"<code>ParallelRayStrategy</code>","text":"<p>Run experiments in parallel using Ray.</p> Source code in <code>octopus/manager/execution.py</code> <pre><code>@define\nclass ParallelRayStrategy:\n    \"\"\"Run experiments in parallel using Ray.\"\"\"\n\n    num_workers: int\n    log_dir: UPath\n\n    def execute(\n        self,\n        experiments: list[\"OctoExperiment\"],\n        run_fn: \"Callable[[OctoExperiment], None]\",\n    ) -&gt; None:\n        \"\"\"Execute all experiments in parallel using Ray.\"\"\"\n\n        def wrapped_run(experiment: \"OctoExperiment\", index: int):\n            logger.set_log_group(LogGroup.PROCESSING, f\"EXP {index}\")\n            logger.info(\"Starting execution\")\n            try:\n                run_fn(experiment)\n                logger.set_log_group(LogGroup.PREPARE_EXECUTION, f\"EXP {index}\")\n                logger.info(\"Completed successfully\")\n                return True\n            except Exception as e:\n                logger.exception(f\"Exception in task {index}: {e!s}\")\n                return None\n\n        run_parallel_outer_ray(\n            base_experiments=experiments,\n            create_execute_mlmodules=wrapped_run,\n            log_dir=self.log_dir,\n            num_workers=self.num_workers,\n        )\n</code></pre>"},{"location":"reference/manager/#octopus.manager.ParallelRayStrategy.execute","title":"<code>execute(experiments, run_fn)</code>","text":"<p>Execute all experiments in parallel using Ray.</p> Source code in <code>octopus/manager/execution.py</code> <pre><code>def execute(\n    self,\n    experiments: list[\"OctoExperiment\"],\n    run_fn: \"Callable[[OctoExperiment], None]\",\n) -&gt; None:\n    \"\"\"Execute all experiments in parallel using Ray.\"\"\"\n\n    def wrapped_run(experiment: \"OctoExperiment\", index: int):\n        logger.set_log_group(LogGroup.PROCESSING, f\"EXP {index}\")\n        logger.info(\"Starting execution\")\n        try:\n            run_fn(experiment)\n            logger.set_log_group(LogGroup.PREPARE_EXECUTION, f\"EXP {index}\")\n            logger.info(\"Completed successfully\")\n            return True\n        except Exception as e:\n            logger.exception(f\"Exception in task {index}: {e!s}\")\n            return None\n\n    run_parallel_outer_ray(\n        base_experiments=experiments,\n        create_execute_mlmodules=wrapped_run,\n        log_dir=self.log_dir,\n        num_workers=self.num_workers,\n    )\n</code></pre>"},{"location":"reference/manager/#octopus.manager.ResourceConfig","title":"<code>ResourceConfig</code>","text":"<p>Immutable configuration for CPU resources.</p> <p>Attributes:</p> Name Type Description <code>num_cpus</code> <code>int</code> <p>Total available CPUs on the system.</p> <code>num_workers</code> <code>int</code> <p>Number of parallel outer workers.</p> <code>cpus_per_experiment</code> <code>int</code> <p>CPUs allocated to each experiment for inner parallelization.</p> <code>outer_parallelization</code> <code>bool</code> <p>Whether outer parallelization is enabled.</p> <code>run_single_experiment_num</code> <code>int</code> <p>Index of single experiment to run (-1 for all).</p> <code>num_experiments</code> <code>int</code> <p>Total number of experiments in the study.</p> Source code in <code>octopus/manager/core.py</code> <pre><code>@define(frozen=True)\nclass ResourceConfig:\n    \"\"\"Immutable configuration for CPU resources.\n\n    Attributes:\n        num_cpus: Total available CPUs on the system.\n        num_workers: Number of parallel outer workers.\n        cpus_per_experiment: CPUs allocated to each experiment for inner parallelization.\n        outer_parallelization: Whether outer parallelization is enabled.\n        run_single_experiment_num: Index of single experiment to run (-1 for all).\n        num_experiments: Total number of experiments in the study.\n    \"\"\"\n\n    num_cpus: int\n    num_workers: int\n    cpus_per_experiment: int\n    outer_parallelization: bool\n    run_single_experiment_num: int\n    num_experiments: int\n\n    @classmethod\n    def create(\n        cls,\n        num_experiments: int,\n        outer_parallelization: bool,\n        run_single_experiment_num: int,\n        num_cpus: int | None = None,\n    ) -&gt; \"ResourceConfig\":\n        \"\"\"Create ResourceConfig with computed values.\n\n        Args:\n            num_experiments: Total number of experiments in the study.\n            outer_parallelization: Whether to run experiments in parallel.\n            run_single_experiment_num: Index of single experiment to run (-1 for all).\n            num_cpus: Total CPUs available (auto-detected if None).\n\n        Returns:\n            ResourceConfig with computed worker and CPU allocation.\n\n        Raises:\n            ValueError: If any input parameter is invalid.\n        \"\"\"\n        if num_experiments &lt;= 0:\n            raise ValueError(f\"num_experiments must be positive, got {num_experiments}\")\n\n        if run_single_experiment_num &lt; -1:\n            raise ValueError(\n                f\"run_single_experiment_num must be -1 (all experiments) or a valid index &gt;= 0, \"\n                f\"got {run_single_experiment_num}\"\n            )\n        if run_single_experiment_num &gt;= num_experiments:\n            raise ValueError(\n                f\"run_single_experiment_num ({run_single_experiment_num}) must be less than \"\n                f\"num_experiments ({num_experiments})\"\n            )\n\n        # Get or validate num_cpus\n        if num_cpus is None:\n            num_cpus = get_available_cpus()\n        elif num_cpus &lt;= 0:\n            raise ValueError(f\"num_cpus must be positive, got {num_cpus}\")\n\n        # Calculate effective number of experiments for resource allocation\n        effective_num_experiments = 1 if run_single_experiment_num != -1 else num_experiments\n\n        # Calculate resource allocation\n        num_workers = min(effective_num_experiments, num_cpus)\n        if num_workers == 0:\n            raise ValueError(\n                f\"Cannot allocate resources: num_workers computed as 0 \"\n                f\"(effective_num_experiments={effective_num_experiments}, num_cpus={num_cpus})\"\n            )\n\n        cpus_per_experiment = max(1, math.floor(num_cpus / num_workers)) if outer_parallelization else num_cpus\n\n        return cls(\n            num_cpus=num_cpus,\n            num_workers=num_workers,\n            cpus_per_experiment=cpus_per_experiment,\n            outer_parallelization=outer_parallelization,\n            run_single_experiment_num=run_single_experiment_num,\n            num_experiments=num_experiments,\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return string representation of resource configuration.\"\"\"\n        return (\n            f\"Parallelization: {self.outer_parallelization} | \"\n            f\"Single exp: {self.run_single_experiment_num} | \"\n            f\"Outer folds: {self.num_experiments} | \"\n            f\"CPUs: {self.num_cpus} | \"\n            f\"Workers: {self.num_workers} | \"\n            f\"CPUs/exp: {self.cpus_per_experiment}\"\n        )\n</code></pre>"},{"location":"reference/manager/#octopus.manager.ResourceConfig.__str__","title":"<code>__str__()</code>","text":"<p>Return string representation of resource configuration.</p> Source code in <code>octopus/manager/core.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return string representation of resource configuration.\"\"\"\n    return (\n        f\"Parallelization: {self.outer_parallelization} | \"\n        f\"Single exp: {self.run_single_experiment_num} | \"\n        f\"Outer folds: {self.num_experiments} | \"\n        f\"CPUs: {self.num_cpus} | \"\n        f\"Workers: {self.num_workers} | \"\n        f\"CPUs/exp: {self.cpus_per_experiment}\"\n    )\n</code></pre>"},{"location":"reference/manager/#octopus.manager.ResourceConfig.create","title":"<code>create(num_experiments, outer_parallelization, run_single_experiment_num, num_cpus=None)</code>  <code>classmethod</code>","text":"<p>Create ResourceConfig with computed values.</p> <p>Parameters:</p> Name Type Description Default <code>num_experiments</code> <code>int</code> <p>Total number of experiments in the study.</p> required <code>outer_parallelization</code> <code>bool</code> <p>Whether to run experiments in parallel.</p> required <code>run_single_experiment_num</code> <code>int</code> <p>Index of single experiment to run (-1 for all).</p> required <code>num_cpus</code> <code>int | None</code> <p>Total CPUs available (auto-detected if None).</p> <code>None</code> <p>Returns:</p> Type Description <code>ResourceConfig</code> <p>ResourceConfig with computed worker and CPU allocation.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any input parameter is invalid.</p> Source code in <code>octopus/manager/core.py</code> <pre><code>@classmethod\ndef create(\n    cls,\n    num_experiments: int,\n    outer_parallelization: bool,\n    run_single_experiment_num: int,\n    num_cpus: int | None = None,\n) -&gt; \"ResourceConfig\":\n    \"\"\"Create ResourceConfig with computed values.\n\n    Args:\n        num_experiments: Total number of experiments in the study.\n        outer_parallelization: Whether to run experiments in parallel.\n        run_single_experiment_num: Index of single experiment to run (-1 for all).\n        num_cpus: Total CPUs available (auto-detected if None).\n\n    Returns:\n        ResourceConfig with computed worker and CPU allocation.\n\n    Raises:\n        ValueError: If any input parameter is invalid.\n    \"\"\"\n    if num_experiments &lt;= 0:\n        raise ValueError(f\"num_experiments must be positive, got {num_experiments}\")\n\n    if run_single_experiment_num &lt; -1:\n        raise ValueError(\n            f\"run_single_experiment_num must be -1 (all experiments) or a valid index &gt;= 0, \"\n            f\"got {run_single_experiment_num}\"\n        )\n    if run_single_experiment_num &gt;= num_experiments:\n        raise ValueError(\n            f\"run_single_experiment_num ({run_single_experiment_num}) must be less than \"\n            f\"num_experiments ({num_experiments})\"\n        )\n\n    # Get or validate num_cpus\n    if num_cpus is None:\n        num_cpus = get_available_cpus()\n    elif num_cpus &lt;= 0:\n        raise ValueError(f\"num_cpus must be positive, got {num_cpus}\")\n\n    # Calculate effective number of experiments for resource allocation\n    effective_num_experiments = 1 if run_single_experiment_num != -1 else num_experiments\n\n    # Calculate resource allocation\n    num_workers = min(effective_num_experiments, num_cpus)\n    if num_workers == 0:\n        raise ValueError(\n            f\"Cannot allocate resources: num_workers computed as 0 \"\n            f\"(effective_num_experiments={effective_num_experiments}, num_cpus={num_cpus})\"\n        )\n\n    cpus_per_experiment = max(1, math.floor(num_cpus / num_workers)) if outer_parallelization else num_cpus\n\n    return cls(\n        num_cpus=num_cpus,\n        num_workers=num_workers,\n        cpus_per_experiment=cpus_per_experiment,\n        outer_parallelization=outer_parallelization,\n        run_single_experiment_num=run_single_experiment_num,\n        num_experiments=num_experiments,\n    )\n</code></pre>"},{"location":"reference/manager/#octopus.manager.SequentialStrategy","title":"<code>SequentialStrategy</code>","text":"<p>Run experiments one after another.</p> Source code in <code>octopus/manager/execution.py</code> <pre><code>@define\nclass SequentialStrategy:\n    \"\"\"Run experiments one after another.\"\"\"\n\n    def execute(\n        self,\n        experiments: list[\"OctoExperiment\"],\n        run_fn: \"Callable[[OctoExperiment], None]\",\n    ) -&gt; None:\n        \"\"\"Execute all experiments sequentially.\"\"\"\n        logger.set_log_group(LogGroup.PROCESSING)\n        for idx, experiment in enumerate(experiments):\n            logger.info(f\"Running outer split: {idx}\")\n            run_fn(experiment)\n</code></pre>"},{"location":"reference/manager/#octopus.manager.SequentialStrategy.execute","title":"<code>execute(experiments, run_fn)</code>","text":"<p>Execute all experiments sequentially.</p> Source code in <code>octopus/manager/execution.py</code> <pre><code>def execute(\n    self,\n    experiments: list[\"OctoExperiment\"],\n    run_fn: \"Callable[[OctoExperiment], None]\",\n) -&gt; None:\n    \"\"\"Execute all experiments sequentially.\"\"\"\n    logger.set_log_group(LogGroup.PROCESSING)\n    for idx, experiment in enumerate(experiments):\n        logger.info(f\"Running outer split: {idx}\")\n        run_fn(experiment)\n</code></pre>"},{"location":"reference/manager/#octopus.manager.SingleExperimentStrategy","title":"<code>SingleExperimentStrategy</code>","text":"<p>Run a single experiment by index.</p> Source code in <code>octopus/manager/execution.py</code> <pre><code>@define\nclass SingleExperimentStrategy:\n    \"\"\"Run a single experiment by index.\"\"\"\n\n    experiment_index: int\n\n    def execute(\n        self,\n        experiments: list[\"OctoExperiment\"],\n        run_fn: \"Callable[[OctoExperiment], None]\",\n    ) -&gt; None:\n        \"\"\"Execute only the experiment at experiment_index.\"\"\"\n        logger.set_log_group(LogGroup.PROCESSING)\n        logger.info(f\"Running single experiment: {self.experiment_index}\")\n        run_fn(experiments[self.experiment_index])\n</code></pre>"},{"location":"reference/manager/#octopus.manager.SingleExperimentStrategy.execute","title":"<code>execute(experiments, run_fn)</code>","text":"<p>Execute only the experiment at experiment_index.</p> Source code in <code>octopus/manager/execution.py</code> <pre><code>def execute(\n    self,\n    experiments: list[\"OctoExperiment\"],\n    run_fn: \"Callable[[OctoExperiment], None]\",\n) -&gt; None:\n    \"\"\"Execute only the experiment at experiment_index.\"\"\"\n    logger.set_log_group(LogGroup.PROCESSING)\n    logger.info(f\"Running single experiment: {self.experiment_index}\")\n    run_fn(experiments[self.experiment_index])\n</code></pre>"},{"location":"reference/manager/#octopus.manager.WorkflowTaskRunner","title":"<code>WorkflowTaskRunner</code>","text":"<p>Runs workflow tasks for a single base experiment.</p> <p>Handles the lifecycle of processing workflow tasks: - Creating new experiments from templates - Loading existing experiments - Running ML modules and saving results</p> <p>Attributes:</p> Name Type Description <code>workflow</code> <code>list[Task]</code> <p>List of workflow tasks to process.</p> <code>cpus_per_experiment</code> <code>int</code> <p>Number of CPUs allocated to each experiment for inner parallelization.</p> <code>log_dir</code> <code>UPath</code> <p>Directory for individual worker logs.</p> Source code in <code>octopus/manager/workflow_runner.py</code> <pre><code>@define\nclass WorkflowTaskRunner:\n    \"\"\"Runs workflow tasks for a single base experiment.\n\n    Handles the lifecycle of processing workflow tasks:\n    - Creating new experiments from templates\n    - Loading existing experiments\n    - Running ML modules and saving results\n\n    Attributes:\n        workflow: List of workflow tasks to process.\n        cpus_per_experiment: Number of CPUs allocated to each experiment for inner parallelization.\n        log_dir: Directory for individual worker logs.\n    \"\"\"\n\n    workflow: list[Task] = field(validator=[validators.instance_of(list)])\n    cpus_per_experiment: int = field(validator=[validators.instance_of(int)])\n    log_dir: UPath = field(validator=[validators.instance_of(UPath)])\n\n    def run(self, base_experiment: OctoExperiment) -&gt; None:\n        \"\"\"Process all workflow tasks for a base experiment.\n\n        Args:\n            base_experiment: The base experiment to process.\n\n        Raises:\n            RuntimeError: If Ray is not initialized. Ray must be initialized by\n                OctoManager.run_outer_experiments() before calling this method.\n        \"\"\"\n        if not ray.is_initialized():\n            raise RuntimeError(\n                \"Ray is not initialized. WorkflowTaskRunner.run() must be called \"\n                \"after Ray initialization by OctoManager.run_outer_experiments().\"\n            )\n\n        exp_path_dict: dict[int, UPath] = {}\n\n        for task in self.workflow:\n            self._log_task_info(task)\n\n            if task.load_task:\n                self._load_experiment(base_experiment, task)\n            else:\n                self._run_task(base_experiment, task, exp_path_dict)\n\n    def _run_task(\n        self,\n        base_experiment: OctoExperiment,\n        task: Task,\n        exp_path_dict: dict[int, UPath],\n    ) -&gt; None:\n        \"\"\"Run a single workflow task.\"\"\"\n        experiment = self._create_experiment(base_experiment, task)\n        workflow_dir = self._ensure_workflow_dir(experiment)\n        save_path = workflow_dir / f\"exp{experiment.experiment_id}_{experiment.task_id}.pkl\"\n        assert experiment.task_id is not None  # Set in _create_experiment\n        exp_path_dict[experiment.task_id] = save_path\n\n        self._apply_dependencies(experiment, exp_path_dict)\n        self._execute_and_save(experiment, workflow_dir, save_path)\n\n    def _create_experiment(self, base_experiment: OctoExperiment, task: Task) -&gt; OctoExperiment:\n        \"\"\"Create a new experiment from base experiment and task.\"\"\"\n        experiment = copy.deepcopy(base_experiment)\n        experiment.ml_module = task.module  # type: ignore[attr-defined]  # ClassVar in Task subclasses\n        experiment.ml_config = task\n        experiment.id = f\"{experiment.id}_{task.task_id}\"\n        experiment.task_id = task.task_id\n        experiment.depends_on_task = task.depends_on_task\n        experiment._task_path = UPath(\n            f\"outersplit{experiment.experiment_id}\",\n            f\"workflowtask{task.task_id}\",\n        )\n        experiment.num_assigned_cpus = self.cpus_per_experiment\n        return experiment\n\n    def _ensure_workflow_dir(self, experiment: OctoExperiment) -&gt; UPath:\n        \"\"\"Create and return the workflow directory for an experiment.\"\"\"\n        workflow_dir = experiment.path_study / experiment.task_path\n        workflow_dir.mkdir(parents=True, exist_ok=True)\n        return workflow_dir\n\n    def _apply_dependencies(self, experiment: OctoExperiment, exp_path_dict: dict[int, UPath]) -&gt; None:\n        \"\"\"Apply dependencies from previous workflow tasks.\"\"\"\n        if experiment.depends_on_task is not None and experiment.depends_on_task &gt;= 0:\n            input_path = exp_path_dict[experiment.depends_on_task]\n            if not input_path.exists():\n                raise FileNotFoundError(\"Workflow task to be loaded does not exist\")\n\n            input_experiment = OctoExperiment.from_pickle(input_path)\n            experiment.feature_columns = input_experiment.selected_features\n            experiment.prior_results = input_experiment.results\n            logger.info(f\"Prior results keys: {experiment.prior_results.keys()}\")\n\n        experiment.feature_groups = experiment.calculate_feature_groups(experiment.feature_columns)\n\n    def _execute_and_save(\n        self,\n        experiment: OctoExperiment,\n        workflow_dir: UPath,\n        save_path: UPath,\n    ) -&gt; None:\n        \"\"\"Execute the ML module and save results.\"\"\"\n        logger.info(f\"Running experiment: {experiment.id}\")\n        experiment.to_pickle(save_path)\n\n        module = self._get_module(experiment)\n        experiment = module.run_experiment()\n\n        self._save_results(experiment, workflow_dir)\n        experiment.to_pickle(save_path)\n\n    def _get_module(self, experiment: OctoExperiment):\n        \"\"\"Get the ML module for an experiment.\"\"\"\n        if experiment.ml_module not in modules_inventory:\n            raise ValueError(f\"ml_module {experiment.ml_module} not supported\")\n        return modules_inventory[experiment.ml_module](experiment=experiment, log_dir=self.log_dir)\n\n    def _save_results(self, experiment: OctoExperiment, workflow_dir: UPath) -&gt; None:\n        \"\"\"Save experiment results (predictions and feature importance).\"\"\"\n        if not experiment.results:\n            return\n\n        for key in experiment.results:\n            result = experiment.results[key]\n\n            # Save predictions\n            predictions_path = (\n                workflow_dir / f\"predictions_{experiment.experiment_id}_{experiment.task_id}_{key}.parquet\"\n            )\n            result.create_prediction_df().to_parquet(\n                str(predictions_path),\n                storage_options=predictions_path.storage_options,\n                engine=\"pyarrow\",\n            )\n\n            # Save feature importance\n            fi_path = workflow_dir / f\"feature-importance_{experiment.experiment_id}_{experiment.task_id}_{key}.parquet\"\n            result.create_feature_importance_df().to_parquet(\n                str(fi_path),\n                storage_options=fi_path.storage_options,\n                engine=\"pyarrow\",\n            )\n\n    def _load_experiment(self, base_experiment: OctoExperiment, task: Task) -&gt; None:\n        \"\"\"Validate that an existing experiment exists on disk.\n\n        Args:\n            base_experiment: The base experiment to determine the path.\n            task: The workflow task to load.\n\n        Raises:\n            FileNotFoundError: If the experiment file does not exist.\n        \"\"\"\n        workflow_dir = (\n            base_experiment.path_study / f\"outersplit{base_experiment.experiment_id}\" / f\"workflowtask{task.task_id}\"\n        )\n        load_path = workflow_dir / f\"exp{base_experiment.experiment_id}_{task.task_id}.pkl\"\n\n        if not load_path.exists():\n            raise FileNotFoundError(\"Workflow task to be loaded does not exist\")\n\n        OctoExperiment.from_pickle(load_path)\n        logger.info(f\"Validated existing experiment at: {load_path}\")\n\n    def _log_task_info(self, task: Task) -&gt; None:\n        \"\"\"Log information about a workflow task.\"\"\"\n        logger.info(\n            f\"Processing workflow task: {task.task_id} | \"\n            f\"Input item: {task.depends_on_task} | \"\n            f\"Module: {task.module} | \"  # type: ignore[attr-defined]\n            f\"Description: {task.description} | \"\n            f\"Load existing workflow task: {task.load_task}\"\n        )\n</code></pre>"},{"location":"reference/manager/#octopus.manager.WorkflowTaskRunner.run","title":"<code>run(base_experiment)</code>","text":"<p>Process all workflow tasks for a base experiment.</p> <p>Parameters:</p> Name Type Description Default <code>base_experiment</code> <code>OctoExperiment</code> <p>The base experiment to process.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If Ray is not initialized. Ray must be initialized by OctoManager.run_outer_experiments() before calling this method.</p> Source code in <code>octopus/manager/workflow_runner.py</code> <pre><code>def run(self, base_experiment: OctoExperiment) -&gt; None:\n    \"\"\"Process all workflow tasks for a base experiment.\n\n    Args:\n        base_experiment: The base experiment to process.\n\n    Raises:\n        RuntimeError: If Ray is not initialized. Ray must be initialized by\n            OctoManager.run_outer_experiments() before calling this method.\n    \"\"\"\n    if not ray.is_initialized():\n        raise RuntimeError(\n            \"Ray is not initialized. WorkflowTaskRunner.run() must be called \"\n            \"after Ray initialization by OctoManager.run_outer_experiments().\"\n        )\n\n    exp_path_dict: dict[int, UPath] = {}\n\n    for task in self.workflow:\n        self._log_task_info(task)\n\n        if task.load_task:\n            self._load_experiment(base_experiment, task)\n        else:\n            self._run_task(base_experiment, task, exp_path_dict)\n</code></pre>"},{"location":"reference/manager/#octopus.manager.get_available_cpus","title":"<code>get_available_cpus()</code>","text":"<p>Get available CPUs on the system.</p> Source code in <code>octopus/manager/core.py</code> <pre><code>def get_available_cpus() -&gt; int:\n    \"\"\"Get available CPUs on the system.\"\"\"\n    total_cpus = os.cpu_count()\n    if total_cpus is None:\n        raise RuntimeError(\"Could not determine number of CPUs.\")\n    return total_cpus\n</code></pre>"},{"location":"reference/manager/#octopus.manager.init_ray","title":"<code>init_ray(address=None, num_cpus=None, start_local_if_missing=False, **kwargs)</code>","text":"<p>Initialize Ray for the current process.</p> <p>Connects to an existing cluster if an address is provided or set via environment variables; otherwise, optionally starts a local Ray instance.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str | None</code> <p>Ray head address (e.g., \"auto\", \"127.0.0.1:6379\"). If None, uses env vars RAY_ADDRESS or RAY_HEAD_ADDRESS if set.</p> <code>None</code> <code>num_cpus</code> <code>int | None</code> <p>CPU limit when starting a local Ray instance (only used if starting locally).</p> <code>None</code> <code>start_local_if_missing</code> <code>bool</code> <p>If True and no address is available, start a local Ray instance.</p> <code>False</code> <code>**kwargs</code> <p>Extra args forwarded to ray.init (e.g., runtime_env, log_to_driver, namespace).</p> <code>{}</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If no address is available and start_local_if_missing is False.</p> Source code in <code>octopus/manager/ray_parallel.py</code> <pre><code>def init_ray(\n    address: str | None = None,\n    num_cpus: int | None = None,\n    start_local_if_missing: bool = False,\n    **kwargs,\n) -&gt; None:\n    \"\"\"Initialize Ray for the current process.\n\n    Connects to an existing cluster if an address is provided or set via\n    environment variables; otherwise, optionally starts a local Ray instance.\n\n    Args:\n        address: Ray head address (e.g., \"auto\", \"127.0.0.1:6379\"). If None, uses\n            env vars RAY_ADDRESS or RAY_HEAD_ADDRESS if set.\n        num_cpus: CPU limit when starting a local Ray instance (only used if starting locally).\n        start_local_if_missing: If True and no address is available, start a local Ray instance.\n        **kwargs: Extra args forwarded to ray.init (e.g., runtime_env, log_to_driver, namespace).\n\n    Raises:\n        RuntimeError: If no address is available and start_local_if_missing is False.\n    \"\"\"\n    if ray.is_initialized():\n        return\n\n    addr = address or os.environ.get(\"RAY_ADDRESS\") or os.environ.get(\"RAY_HEAD_ADDRESS\")\n    if addr:\n        ray.init(\n            address=addr,\n            runtime_env={\"worker_process_setup_hook\": _check_parallelization_disabled},\n            **kwargs,\n        )\n        return\n\n    if start_local_if_missing:\n        ray.init(\n            num_cpus=num_cpus,\n            runtime_env={\"worker_process_setup_hook\": _check_parallelization_disabled},\n            **kwargs,\n        )\n        return\n\n    raise RuntimeError(\n        \"No Ray address provided. Set RAY_ADDRESS env, pass address='auto', or call init_ray(..., start_local_if_missing=True) once in the driver.\"\n    )\n</code></pre>"},{"location":"reference/manager/#octopus.manager.run_parallel_inner","title":"<code>run_parallel_inner(trainings, log_dir, num_cpus=1)</code>","text":"<p>Run training.fit() for each item in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>trainings</code> <code>Iterable[Any]</code> <p>Objects with fit() method.</p> required <code>log_dir</code> <code>UPath</code> <p>Directory to store individual Ray worker logs.</p> required <code>num_cpus</code> <code>int</code> <p>CPUs per training task.</p> <code>1</code> <p>Returns:</p> Type Description <code>list[Any]</code> <p>Results from each training.fit() in input order.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If Ray is not initialized.</p> Source code in <code>octopus/manager/ray_parallel.py</code> <pre><code>def run_parallel_inner(trainings: Iterable[Any], log_dir: UPath, num_cpus: int = 1) -&gt; list[Any]:\n    \"\"\"Run training.fit() for each item in parallel.\n\n    Args:\n        trainings: Objects with fit() method.\n        log_dir: Directory to store individual Ray worker logs.\n        num_cpus: CPUs per training task.\n\n    Returns:\n        Results from each training.fit() in input order.\n\n    Raises:\n        RuntimeError: If Ray is not initialized.\n    \"\"\"\n    if not ray.is_initialized():\n        raise RuntimeError(\"Ray is not initialized. Call init_ray() first.\")\n\n    @ray.remote(num_cpus=num_cpus)\n    def execute_training(training: Any, idx: int, log_dir: UPath) -&gt; Any:\n        _setup_worker_logging(log_dir)\n        return training.fit()\n\n    futures = [execute_training.remote(training, idx, log_dir) for idx, training in enumerate(trainings)]\n    return ray.get(futures)\n</code></pre>"},{"location":"reference/manager/#octopus.manager.run_parallel_outer_ray","title":"<code>run_parallel_outer_ray(base_experiments, create_execute_mlmodules, log_dir, num_workers)</code>","text":"<p>Execute create_execute_mlmodules(base_experiment, index) in parallel using Ray.</p> <p>Preserves input order and limits concurrency to num_workers. Outer tasks reserve 0 CPUs so inner Ray work can use available CPUs.</p> <p>Parameters:</p> Name Type Description Default <code>base_experiments</code> <code>Iterable[OctoExperiment]</code> <p>Items to process.</p> required <code>create_execute_mlmodules</code> <code>Callable[[OctoExperiment, int], T]</code> <p>Function called as create_execute_mlmodules(base_experiment, index). If your function only accepts (base_experiment), wrap it (e.g., lambda be, i: f(be)).</p> required <code>log_dir</code> <code>UPath</code> <p>Directory to store individual Ray worker logs.</p> required <code>num_workers</code> <code>int</code> <p>Maximum number of concurrent outer tasks.</p> required <p>Returns:</p> Type Description <code>list[T]</code> <p>Results from create_execute_mlmodules in the same order as base_experiments.</p> Source code in <code>octopus/manager/ray_parallel.py</code> <pre><code>def run_parallel_outer_ray[T](\n    base_experiments: Iterable[\"OctoExperiment\"],\n    create_execute_mlmodules: Callable[[\"OctoExperiment\", int], T],\n    log_dir: UPath,\n    num_workers: int,\n) -&gt; list[T]:\n    \"\"\"Execute create_execute_mlmodules(base_experiment, index) in parallel using Ray.\n\n    Preserves input order and limits concurrency to num_workers. Outer tasks reserve\n    0 CPUs so inner Ray work can use available CPUs.\n\n    Args:\n        base_experiments: Items to process.\n        create_execute_mlmodules: Function called as create_execute_mlmodules(base_experiment, index).\n            If your function only accepts (base_experiment), wrap it (e.g., lambda be, i: f(be)).\n        log_dir: Directory to store individual Ray worker logs.\n        num_workers: Maximum number of concurrent outer tasks.\n\n    Returns:\n        Results from create_execute_mlmodules in the same order as base_experiments.\n    \"\"\"\n    # Ensure Ray is ready in the driver (connect or start local)\n    init_ray(start_local_if_missing=True)\n\n    # If outer jobs do non-trivial CPU tasks - use a small fractional CPU for outers,\n    # e.g., num_cpus=0.1. This limits oversubscription.\n    @ray.remote(num_cpus=0)\n    def outer_task(idx: int, experiment: \"OctoExperiment\", log_dir: UPath):\n        _setup_worker_logging(log_dir)\n        # Do not re-initialize Ray here; workers already have a Ray context.\n        return idx, create_execute_mlmodules(experiment, idx)\n\n    items = list(base_experiments)\n    n = len(items)\n    if n == 0:\n        return []\n\n    max_concurrent = max(1, min(num_workers, n))\n    results: list[T | None] = [None] * n\n    inflight: list[ObjectRef] = []\n    next_i = 0\n\n    # Prime up to max_concurrent tasks\n    while next_i &lt; n and len(inflight) &lt; max_concurrent:\n        inflight.append(outer_task.remote(next_i, items[next_i], log_dir))\n        next_i += 1\n\n    # Drain with backpressure; fill results by original index to preserve order\n    while inflight:\n        done, inflight = ray.wait(inflight, num_returns=1)\n        idx, res = ray.get(done[0])\n        results[idx] = res\n        if next_i &lt; n:\n            inflight.append(outer_task.remote(next_i, items[next_i], log_dir))\n            next_i += 1\n\n    return cast(\"list[T]\", results)\n</code></pre>"},{"location":"reference/manager/#octopus.manager.setup_ray_for_external_library","title":"<code>setup_ray_for_external_library()</code>","text":"<p>Configure environment to enable external libraries to use the existing Ray instance.</p> <p>Sets RAY_ADDRESS to the current Ray GCS address, preventing external libraries (e.g., AutoGluon, Ray Tune) from creating separate Ray instances that would cause resource conflicts.</p> <p>Should be called before using external libraries that may use Ray.</p> Source code in <code>octopus/manager/ray_parallel.py</code> <pre><code>def setup_ray_for_external_library() -&gt; None:\n    \"\"\"Configure environment to enable external libraries to use the existing Ray instance.\n\n    Sets RAY_ADDRESS to the current Ray GCS address, preventing external libraries\n    (e.g., AutoGluon, Ray Tune) from creating separate Ray instances that would\n    cause resource conflicts.\n\n    Should be called before using external libraries that may use Ray.\n    \"\"\"\n    if ray.is_initialized():\n        ray_address = ray.get_runtime_context().gcs_address\n        if ray_address:\n            os.environ[\"RAY_ADDRESS\"] = ray_address\n    else:\n        # If Ray is not initialized, clear the RAY_ADDRESS to avoid stale references\n        os.environ.pop(\"RAY_ADDRESS\", None)\n</code></pre>"},{"location":"reference/manager/#octopus.manager.shutdown_ray","title":"<code>shutdown_ray()</code>","text":"<p>Shut down Ray if initialized. Safe to call multiple times.</p> Source code in <code>octopus/manager/ray_parallel.py</code> <pre><code>def shutdown_ray() -&gt; None:\n    \"\"\"Shut down Ray if initialized. Safe to call multiple times.\"\"\"\n    if ray.is_initialized():\n        ray.shutdown()\n    # Clear RAY_ADDRESS to avoid stale references after shutdown\n    os.environ.pop(\"RAY_ADDRESS\", None)\n    os.environ.pop(\"RAY_HEAD_ADDRESS\", None)\n</code></pre>"},{"location":"reference/metrics/","title":"octopus.metrics","text":"<p>Init metrics.</p>"},{"location":"reference/metrics/#octopus.metrics.Metric","title":"<code>Metric</code>","text":"<p>Metric instance.</p> <p>Represents a metric with its configuration and calculation methods.</p> Source code in <code>octopus/metrics/config.py</code> <pre><code>@define\nclass Metric:\n    \"\"\"Metric instance.\n\n    Represents a metric with its configuration and calculation methods.\n    \"\"\"\n\n    name: str\n    metric_function: MetricFunction = field(validator=validators.is_callable())\n    ml_type: MLType = field(validator=validators.in_(ML_TYPES))\n    higher_is_better: bool = field(validator=validators.instance_of(bool))\n    prediction_type: PredType = field(validator=validators.in_(PRED_TYPES))\n    scorer_string: str = field(validator=validators.instance_of(str))  # needed for some sklearn functionalities\n    metric_params: dict[str, Any] = field(factory=dict)\n\n    @property\n    def direction(self) -&gt; str:\n        \"\"\"Optimization direction for Optuna ('maximize' or 'minimize').\"\"\"\n        return \"maximize\" if self.higher_is_better else \"minimize\"\n\n    def calculate(self, y_true: OctoArrayLike, y_pred: OctoArrayLike, **kwargs) -&gt; float:\n        \"\"\"Calculate metric for classification/regression tasks.\n\n        Args:\n            y_true: True target values\n            y_pred: Predicted values (predictions or probabilities depending on prediction_type)\n            **kwargs: Additional keyword arguments passed to metric function\n\n        Returns:\n            Metric value as float\n\n        Raises:\n            ValueError: If called on a time-to-event metric\n        \"\"\"\n        if self.ml_type == \"timetoevent\":\n            raise ValueError(\n                f\"Metric '{self.name}' is a time-to-event metric. \"\n                \"Use calculate_t2e(event_indicator, event_time, estimate) instead.\"\n            )\n        return float(self.metric_function(y_true, y_pred, **self.metric_params))\n\n    def calculate_t2e(\n        self, event_indicator: OctoArrayLike, event_time: OctoArrayLike, estimate: OctoArrayLike, **kwargs\n    ) -&gt; float:\n        \"\"\"Calculate metric for time-to-event tasks.\n\n        Args:\n            event_indicator: Boolean array indicating whether event occurred\n            event_time: Array of event/censoring times\n            estimate: Predicted risk/survival estimates from model\n            **kwargs: Additional keyword arguments passed to metric function\n\n        Returns:\n            Metric value as float\n\n        Raises:\n            ValueError: If called on a non-time-to-event metric\n        \"\"\"\n        if self.ml_type != \"timetoevent\":\n            raise ValueError(f\"Metric '{self.name}' is a {self.ml_type} metric. Use calculate(y_true, y_pred) instead.\")\n\n        # Merge metric_params with any additional kwargs\n        params = {**self.metric_params, **kwargs}\n        result = self.metric_function(event_indicator, event_time, estimate, **params)\n\n        # Handle tuple return (some T2E metrics return tuple)\n        return float(result[0] if isinstance(result, tuple) else result)\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.Metric.direction","title":"<code>direction</code>  <code>property</code>","text":"<p>Optimization direction for Optuna ('maximize' or 'minimize').</p>"},{"location":"reference/metrics/#octopus.metrics.Metric.calculate","title":"<code>calculate(y_true, y_pred, **kwargs)</code>","text":"<p>Calculate metric for classification/regression tasks.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>OctoArrayLike</code> <p>True target values</p> required <code>y_pred</code> <code>OctoArrayLike</code> <p>Predicted values (predictions or probabilities depending on prediction_type)</p> required <code>**kwargs</code> <p>Additional keyword arguments passed to metric function</p> <code>{}</code> <p>Returns:</p> Type Description <code>float</code> <p>Metric value as float</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If called on a time-to-event metric</p> Source code in <code>octopus/metrics/config.py</code> <pre><code>def calculate(self, y_true: OctoArrayLike, y_pred: OctoArrayLike, **kwargs) -&gt; float:\n    \"\"\"Calculate metric for classification/regression tasks.\n\n    Args:\n        y_true: True target values\n        y_pred: Predicted values (predictions or probabilities depending on prediction_type)\n        **kwargs: Additional keyword arguments passed to metric function\n\n    Returns:\n        Metric value as float\n\n    Raises:\n        ValueError: If called on a time-to-event metric\n    \"\"\"\n    if self.ml_type == \"timetoevent\":\n        raise ValueError(\n            f\"Metric '{self.name}' is a time-to-event metric. \"\n            \"Use calculate_t2e(event_indicator, event_time, estimate) instead.\"\n        )\n    return float(self.metric_function(y_true, y_pred, **self.metric_params))\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.Metric.calculate_t2e","title":"<code>calculate_t2e(event_indicator, event_time, estimate, **kwargs)</code>","text":"<p>Calculate metric for time-to-event tasks.</p> <p>Parameters:</p> Name Type Description Default <code>event_indicator</code> <code>OctoArrayLike</code> <p>Boolean array indicating whether event occurred</p> required <code>event_time</code> <code>OctoArrayLike</code> <p>Array of event/censoring times</p> required <code>estimate</code> <code>OctoArrayLike</code> <p>Predicted risk/survival estimates from model</p> required <code>**kwargs</code> <p>Additional keyword arguments passed to metric function</p> <code>{}</code> <p>Returns:</p> Type Description <code>float</code> <p>Metric value as float</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If called on a non-time-to-event metric</p> Source code in <code>octopus/metrics/config.py</code> <pre><code>def calculate_t2e(\n    self, event_indicator: OctoArrayLike, event_time: OctoArrayLike, estimate: OctoArrayLike, **kwargs\n) -&gt; float:\n    \"\"\"Calculate metric for time-to-event tasks.\n\n    Args:\n        event_indicator: Boolean array indicating whether event occurred\n        event_time: Array of event/censoring times\n        estimate: Predicted risk/survival estimates from model\n        **kwargs: Additional keyword arguments passed to metric function\n\n    Returns:\n        Metric value as float\n\n    Raises:\n        ValueError: If called on a non-time-to-event metric\n    \"\"\"\n    if self.ml_type != \"timetoevent\":\n        raise ValueError(f\"Metric '{self.name}' is a {self.ml_type} metric. Use calculate(y_true, y_pred) instead.\")\n\n    # Merge metric_params with any additional kwargs\n    params = {**self.metric_params, **kwargs}\n    result = self.metric_function(event_indicator, event_time, estimate, **params)\n\n    # Handle tuple return (some T2E metrics return tuple)\n    return float(result[0] if isinstance(result, tuple) else result)\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.Metrics","title":"<code>Metrics</code>","text":"<p>Central registry for metrics.</p> Usage Source code in <code>octopus/metrics/core.py</code> <pre><code>class Metrics:\n    \"\"\"Central registry for metrics.\n\n    Usage:\n        # Get metric instance\n        metric = Metrics.get_instance(\"AUCROC\")\n        metric.calculate(y_true, y_pred)\n\n        # Get direction\n        direction = Metrics.get_direction(\"AUCROC\")\n    \"\"\"\n\n    # Internal registry: metric name -&gt; function returning Metric\n    _config_factories: ClassVar[dict[str, Callable[[], Metric]]] = {}\n\n    # Internal cache: metric name -&gt; Metric\n    _metric_configs: ClassVar[dict[str, Metric]] = {}\n\n    @classmethod\n    def get_all_metrics(cls) -&gt; dict[str, Callable[[], Metric]]:\n        \"\"\"Get all registered metric factory functions.\n\n        Returns:\n            Dictionary mapping metric names to their factory functions.\n        \"\"\"\n        return cls._config_factories\n\n    @classmethod\n    def register(cls, name: str) -&gt; Callable[[Callable[[], Metric]], Callable[[], Metric]]:\n        \"\"\"Register a metric factory function under a given name.\n\n        Args:\n            name: The name to register the metric under.\n\n        Returns:\n            Decorator function.\n        \"\"\"\n\n        def decorator(factory: Callable[[], Metric]) -&gt; Callable[[], Metric]:\n            if name in cls._config_factories:\n                raise ValueError(f\"Metric '{name}' is already registered.\")\n            cls._config_factories[name] = factory\n            return factory\n\n        return decorator\n\n    @classmethod\n    def get_instance(cls, name: str) -&gt; Metric:\n        \"\"\"Get metric instance by name.\n\n        This is the primary method for getting a metric to use for calculation.\n        Returns a Metric instance that has calculate() and calculate_t2e() methods.\n\n        Args:\n            name: The name of the metric to retrieve.\n\n        Returns:\n            Metric instance with calculate methods.\n\n        Raises:\n            UnknownMetricError: If no metric with the specified name is found.\n\n        Usage:\n            metric = Metrics.get_instance(\"AUCROC\")\n            value = metric.calculate(y_true, y_pred)\n        \"\"\"\n        # Return cached config if available\n        if name in cls._metric_configs:\n            return cls._metric_configs[name]\n\n        # Lookup factory\n        factory = cls._config_factories.get(name)\n        if factory is None:\n            available = \", \".join(sorted(cls._config_factories.keys()))\n            raise UnknownMetricError(\n                f\"Unknown metric '{name}'. Available metrics are: {available}. \"\n                \"Please check the metric name and try again.\"\n            )\n\n        # Build config via factory and enforce name consistency\n        config = factory()\n        object.__setattr__(config, \"name\", name)\n        cls._metric_configs[name] = config\n        return config\n\n    @classmethod\n    def get_direction(cls, name: str) -&gt; str:\n        \"\"\"Get the optuna direction by name.\n\n        Args:\n            name: The name of the metric.\n\n        Returns:\n            \"maximize\" if higher_is_better is True, else \"minimize\".\n        \"\"\"\n        return \"maximize\" if cls.get_instance(name).higher_is_better else \"minimize\"\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.Metrics--get-metric-instance","title":"Get metric instance","text":"<p>metric = Metrics.get_instance(\"AUCROC\") metric.calculate(y_true, y_pred)</p>"},{"location":"reference/metrics/#octopus.metrics.Metrics--get-direction","title":"Get direction","text":"<p>direction = Metrics.get_direction(\"AUCROC\")</p>"},{"location":"reference/metrics/#octopus.metrics.Metrics.get_all_metrics","title":"<code>get_all_metrics()</code>  <code>classmethod</code>","text":"<p>Get all registered metric factory functions.</p> <p>Returns:</p> Type Description <code>dict[str, Callable[[], Metric]]</code> <p>Dictionary mapping metric names to their factory functions.</p> Source code in <code>octopus/metrics/core.py</code> <pre><code>@classmethod\ndef get_all_metrics(cls) -&gt; dict[str, Callable[[], Metric]]:\n    \"\"\"Get all registered metric factory functions.\n\n    Returns:\n        Dictionary mapping metric names to their factory functions.\n    \"\"\"\n    return cls._config_factories\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.Metrics.get_direction","title":"<code>get_direction(name)</code>  <code>classmethod</code>","text":"<p>Get the optuna direction by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the metric.</p> required <p>Returns:</p> Type Description <code>str</code> <p>\"maximize\" if higher_is_better is True, else \"minimize\".</p> Source code in <code>octopus/metrics/core.py</code> <pre><code>@classmethod\ndef get_direction(cls, name: str) -&gt; str:\n    \"\"\"Get the optuna direction by name.\n\n    Args:\n        name: The name of the metric.\n\n    Returns:\n        \"maximize\" if higher_is_better is True, else \"minimize\".\n    \"\"\"\n    return \"maximize\" if cls.get_instance(name).higher_is_better else \"minimize\"\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.Metrics.get_instance","title":"<code>get_instance(name)</code>  <code>classmethod</code>","text":"<p>Get metric instance by name.</p> <p>This is the primary method for getting a metric to use for calculation. Returns a Metric instance that has calculate() and calculate_t2e() methods.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the metric to retrieve.</p> required <p>Returns:</p> Type Description <code>Metric</code> <p>Metric instance with calculate methods.</p> <p>Raises:</p> Type Description <code>UnknownMetricError</code> <p>If no metric with the specified name is found.</p> Usage <p>metric = Metrics.get_instance(\"AUCROC\") value = metric.calculate(y_true, y_pred)</p> Source code in <code>octopus/metrics/core.py</code> <pre><code>@classmethod\ndef get_instance(cls, name: str) -&gt; Metric:\n    \"\"\"Get metric instance by name.\n\n    This is the primary method for getting a metric to use for calculation.\n    Returns a Metric instance that has calculate() and calculate_t2e() methods.\n\n    Args:\n        name: The name of the metric to retrieve.\n\n    Returns:\n        Metric instance with calculate methods.\n\n    Raises:\n        UnknownMetricError: If no metric with the specified name is found.\n\n    Usage:\n        metric = Metrics.get_instance(\"AUCROC\")\n        value = metric.calculate(y_true, y_pred)\n    \"\"\"\n    # Return cached config if available\n    if name in cls._metric_configs:\n        return cls._metric_configs[name]\n\n    # Lookup factory\n    factory = cls._config_factories.get(name)\n    if factory is None:\n        available = \", \".join(sorted(cls._config_factories.keys()))\n        raise UnknownMetricError(\n            f\"Unknown metric '{name}'. Available metrics are: {available}. \"\n            \"Please check the metric name and try again.\"\n        )\n\n    # Build config via factory and enforce name consistency\n    config = factory()\n    object.__setattr__(config, \"name\", name)\n    cls._metric_configs[name] = config\n    return config\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.Metrics.register","title":"<code>register(name)</code>  <code>classmethod</code>","text":"<p>Register a metric factory function under a given name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to register the metric under.</p> required <p>Returns:</p> Type Description <code>Callable[[Callable[[], Metric]], Callable[[], Metric]]</code> <p>Decorator function.</p> Source code in <code>octopus/metrics/core.py</code> <pre><code>@classmethod\ndef register(cls, name: str) -&gt; Callable[[Callable[[], Metric]], Callable[[], Metric]]:\n    \"\"\"Register a metric factory function under a given name.\n\n    Args:\n        name: The name to register the metric under.\n\n    Returns:\n        Decorator function.\n    \"\"\"\n\n    def decorator(factory: Callable[[], Metric]) -&gt; Callable[[], Metric]:\n        if name in cls._config_factories:\n            raise ValueError(f\"Metric '{name}' is already registered.\")\n        cls._config_factories[name] = factory\n        return factory\n\n    return decorator\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.acc_metric","title":"<code>acc_metric()</code>","text":"<p>Accuracy metric configuration.</p> Source code in <code>octopus/metrics/classification.py</code> <pre><code>@Metrics.register(\"ACC\")\ndef acc_metric() -&gt; Metric:\n    \"\"\"Accuracy metric configuration.\"\"\"\n    return Metric(\n        name=\"ACC\",\n        metric_function=accuracy_score,\n        ml_type=\"classification\",\n        higher_is_better=True,\n        prediction_type=\"predict\",\n        scorer_string=\"accuracy\",\n    )\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.accbal_metric","title":"<code>accbal_metric()</code>","text":"<p>Balanced accuracy metric configuration.</p> Source code in <code>octopus/metrics/classification.py</code> <pre><code>@Metrics.register(\"ACCBAL\")\ndef accbal_metric() -&gt; Metric:\n    \"\"\"Balanced accuracy metric configuration.\"\"\"\n    return Metric(\n        name=\"ACCBAL\",\n        metric_function=balanced_accuracy_score,\n        ml_type=\"classification\",\n        higher_is_better=True,\n        prediction_type=\"predict\",\n        scorer_string=\"balanced_accuracy\",\n    )\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.accbal_multiclass_metric","title":"<code>accbal_multiclass_metric()</code>","text":"<p>Balanced accuracy metric configuration for multiclass problems.</p> Source code in <code>octopus/metrics/multiclass.py</code> <pre><code>@Metrics.register(\"ACCBAL_MC\")\ndef accbal_multiclass_metric() -&gt; Metric:\n    \"\"\"Balanced accuracy metric configuration for multiclass problems.\"\"\"\n    return Metric(\n        name=\"ACCBAL_MC\",\n        metric_function=balanced_accuracy_score,\n        ml_type=\"multiclass\",\n        higher_is_better=True,\n        prediction_type=\"predict\",\n        scorer_string=\"balanced_accuracy\",\n    )\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.aucpr_metric","title":"<code>aucpr_metric()</code>","text":"<p>AUCPR metric configuration.</p> Source code in <code>octopus/metrics/classification.py</code> <pre><code>@Metrics.register(\"AUCPR\")\ndef aucpr_metric() -&gt; Metric:\n    \"\"\"AUCPR metric configuration.\"\"\"\n    return Metric(\n        name=\"AUCPR\",\n        metric_function=average_precision_score,\n        ml_type=\"classification\",\n        higher_is_better=True,\n        prediction_type=\"predict_proba\",\n        scorer_string=\"average_precision\",\n    )\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.aucroc_macro_multiclass_metric","title":"<code>aucroc_macro_multiclass_metric()</code>","text":"<p>AUCROC metric configuration for multiclass problems (macro-average).</p> Source code in <code>octopus/metrics/multiclass.py</code> <pre><code>@Metrics.register(\"AUCROC_MACRO\")\ndef aucroc_macro_multiclass_metric() -&gt; Metric:\n    \"\"\"AUCROC metric configuration for multiclass problems (macro-average).\"\"\"\n    return Metric(\n        name=\"AUCROC_MACRO\",\n        metric_function=roc_auc_score,\n        metric_params={\"multi_class\": \"ovr\", \"average\": \"macro\"},\n        ml_type=\"multiclass\",\n        higher_is_better=True,\n        prediction_type=\"predict_proba\",\n        scorer_string=\"roc_auc_ovr\",\n    )\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.aucroc_metric","title":"<code>aucroc_metric()</code>","text":"<p>AUCROC metric configuration.</p> Source code in <code>octopus/metrics/classification.py</code> <pre><code>@Metrics.register(\"AUCROC\")\ndef aucroc_metric() -&gt; Metric:\n    \"\"\"AUCROC metric configuration.\"\"\"\n    return Metric(\n        name=\"AUCROC\",\n        metric_function=roc_auc_score,\n        ml_type=\"classification\",\n        higher_is_better=True,\n        prediction_type=\"predict_proba\",\n        scorer_string=\"roc_auc\",\n    )\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.aucroc_weighted_multiclass_metric","title":"<code>aucroc_weighted_multiclass_metric()</code>","text":"<p>AUCROC metric configuration for multiclass problems (weighted-average).</p> Source code in <code>octopus/metrics/multiclass.py</code> <pre><code>@Metrics.register(\"AUCROC_WEIGHTED\")\ndef aucroc_weighted_multiclass_metric() -&gt; Metric:\n    \"\"\"AUCROC metric configuration for multiclass problems (weighted-average).\"\"\"\n    return Metric(\n        name=\"AUCROC_WEIGHTED\",\n        metric_function=roc_auc_score,\n        metric_params={\"multi_class\": \"ovr\", \"average\": \"weighted\"},\n        ml_type=\"multiclass\",\n        higher_is_better=True,\n        prediction_type=\"predict_proba\",\n        scorer_string=\"roc_auc_ovr_weighted\",\n    )\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.f1_metric","title":"<code>f1_metric()</code>","text":"<p>F1 metric configuration.</p> Source code in <code>octopus/metrics/classification.py</code> <pre><code>@Metrics.register(\"F1\")\ndef f1_metric() -&gt; Metric:\n    \"\"\"F1 metric configuration.\"\"\"\n    return Metric(\n        name=\"F1\",\n        metric_function=f1_score,\n        ml_type=\"classification\",\n        higher_is_better=True,\n        prediction_type=\"predict\",\n        scorer_string=\"f1\",\n    )\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.logloss_metric","title":"<code>logloss_metric()</code>","text":"<p>Log loss metric configuration.</p> Source code in <code>octopus/metrics/classification.py</code> <pre><code>@Metrics.register(\"LOGLOSS\")\ndef logloss_metric() -&gt; Metric:\n    \"\"\"Log loss metric configuration.\"\"\"\n    return Metric(\n        name=\"LOGLOSS\",\n        metric_function=log_loss,\n        ml_type=\"classification\",\n        higher_is_better=True,\n        prediction_type=\"predict_proba\",\n        scorer_string=\"neg_log_loss\",\n    )\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.mae_metric","title":"<code>mae_metric()</code>","text":"<p>MAE metric configuration.</p> Source code in <code>octopus/metrics/regression.py</code> <pre><code>@Metrics.register(\"MAE\")\ndef mae_metric() -&gt; Metric:\n    \"\"\"MAE metric configuration.\"\"\"\n    return Metric(\n        name=\"MAE\",\n        metric_function=mean_absolute_error,\n        ml_type=\"regression\",\n        higher_is_better=False,\n        prediction_type=\"predict\",\n        scorer_string=\"neg_mean_absolute_error\",\n    )\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.mcc_metric","title":"<code>mcc_metric()</code>","text":"<p>Matthews Correlation Coefficient metric configuration.</p> Source code in <code>octopus/metrics/classification.py</code> <pre><code>@Metrics.register(\"MCC\")\ndef mcc_metric() -&gt; Metric:\n    \"\"\"Matthews Correlation Coefficient metric configuration.\"\"\"\n    return Metric(\n        name=\"MCC\",\n        metric_function=matthews_corrcoef,\n        ml_type=\"classification\",\n        higher_is_better=True,\n        prediction_type=\"predict\",\n        scorer_string=\"matthews_corrcoef\",\n    )\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.mse_metric","title":"<code>mse_metric()</code>","text":"<p>MSE metric configuration.</p> Source code in <code>octopus/metrics/regression.py</code> <pre><code>@Metrics.register(\"MSE\")\ndef mse_metric() -&gt; Metric:\n    \"\"\"MSE metric configuration.\"\"\"\n    return Metric(\n        name=\"MSE\",\n        metric_function=mean_squared_error,\n        ml_type=\"regression\",\n        higher_is_better=False,\n        prediction_type=\"predict\",\n        scorer_string=\"neg_mean_squared_error\",\n    )\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.negbrierscore_metric","title":"<code>negbrierscore_metric()</code>","text":"<p>Brier score metric configuration.</p> Source code in <code>octopus/metrics/classification.py</code> <pre><code>@Metrics.register(\"NEGBRIERSCORE\")\ndef negbrierscore_metric() -&gt; Metric:\n    \"\"\"Brier score metric configuration.\"\"\"\n    return Metric(\n        name=\"NEGBRIERSCORE\",\n        metric_function=brier_score_loss,\n        ml_type=\"classification\",\n        higher_is_better=True,\n        prediction_type=\"predict_proba\",\n        scorer_string=\"neg_brier_score\",\n    )\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.precision_metric","title":"<code>precision_metric()</code>","text":"<p>Precision metric configuration.</p> Source code in <code>octopus/metrics/classification.py</code> <pre><code>@Metrics.register(\"PRECISION\")\ndef precision_metric() -&gt; Metric:\n    \"\"\"Precision metric configuration.\"\"\"\n    return Metric(\n        name=\"PRECISION\",\n        metric_function=precision_score,\n        ml_type=\"classification\",\n        higher_is_better=True,\n        prediction_type=\"predict\",\n        scorer_string=\"precision\",\n    )\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.r2_metric","title":"<code>r2_metric()</code>","text":"<p>R2 metric configuration.</p> Source code in <code>octopus/metrics/regression.py</code> <pre><code>@Metrics.register(\"R2\")\ndef r2_metric() -&gt; Metric:\n    \"\"\"R2 metric configuration.\"\"\"\n    return Metric(\n        name=\"R2\",\n        metric_function=r2_score,\n        ml_type=\"regression\",\n        higher_is_better=True,\n        prediction_type=\"predict\",\n        scorer_string=\"r2\",\n    )\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.recall_metric","title":"<code>recall_metric()</code>","text":"<p>Recall metric configuration.</p> Source code in <code>octopus/metrics/classification.py</code> <pre><code>@Metrics.register(\"RECALL\")\ndef recall_metric() -&gt; Metric:\n    \"\"\"Recall metric configuration.\"\"\"\n    return Metric(\n        name=\"RECALL\",\n        metric_function=recall_score,\n        ml_type=\"classification\",\n        higher_is_better=True,\n        prediction_type=\"predict\",\n        scorer_string=\"recall\",\n    )\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.rmse_metric","title":"<code>rmse_metric()</code>","text":"<p>RMSE metric configuration.</p> Source code in <code>octopus/metrics/regression.py</code> <pre><code>@Metrics.register(\"RMSE\")\ndef rmse_metric() -&gt; Metric:\n    \"\"\"RMSE metric configuration.\"\"\"\n    return Metric(\n        name=\"RMSE\",\n        metric_function=root_mean_squared_error,\n        ml_type=\"regression\",\n        higher_is_better=False,\n        prediction_type=\"predict\",\n        scorer_string=\"neg_root_mean_squared_error\",\n    )\n</code></pre>"},{"location":"reference/metrics/#octopus.metrics.root_mean_squared_error","title":"<code>root_mean_squared_error(y_true, y_pred)</code>","text":"<p>Calculate Root Mean Squared Error (RMSE).</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>True target values</p> required <code>y_pred</code> <code>ndarray</code> <p>Predicted target values</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>RMSE value</p> Source code in <code>octopus/metrics/regression.py</code> <pre><code>def root_mean_squared_error(y_true: np.ndarray, y_pred: np.ndarray) -&gt; float:\n    \"\"\"Calculate Root Mean Squared Error (RMSE).\n\n    Args:\n        y_true: True target values\n        y_pred: Predicted target values\n\n    Returns:\n        float: RMSE value\n    \"\"\"\n    return math.sqrt(mean_squared_error(y_true, y_pred))\n</code></pre>"},{"location":"reference/models/","title":"octopus.models","text":"<p>Init.</p>"},{"location":"reference/models/#octopus.models.CategoricalHyperparameter","title":"<code>CategoricalHyperparameter</code>","text":"<p>               Bases: <code>Hyperparameter</code></p> <p>Categorical Hyperparameter class.</p> Source code in <code>octopus/models/hyperparameter.py</code> <pre><code>@define\nclass CategoricalHyperparameter(Hyperparameter):\n    \"\"\"Categorical Hyperparameter class.\"\"\"\n\n    choices: list[Any] = field(factory=list)\n\n    def __attrs_post_init__(self):\n        if len(self.choices) == 0:\n            raise ValueError(\"choices must be a non-empty list.\")\n\n    def suggest(self, trial: optuna.trial.Trial, unique_name: str) -&gt; Any:\n        \"\"\"Suggest a categorical value using Optuna trial.\"\"\"\n        return trial.suggest_categorical(name=unique_name, choices=self.choices)\n</code></pre>"},{"location":"reference/models/#octopus.models.CategoricalHyperparameter.suggest","title":"<code>suggest(trial, unique_name)</code>","text":"<p>Suggest a categorical value using Optuna trial.</p> Source code in <code>octopus/models/hyperparameter.py</code> <pre><code>def suggest(self, trial: optuna.trial.Trial, unique_name: str) -&gt; Any:\n    \"\"\"Suggest a categorical value using Optuna trial.\"\"\"\n    return trial.suggest_categorical(name=unique_name, choices=self.choices)\n</code></pre>"},{"location":"reference/models/#octopus.models.FixedHyperparameter","title":"<code>FixedHyperparameter</code>","text":"<p>               Bases: <code>Hyperparameter</code></p> <p>Fixed Hyperparameter class.</p> Source code in <code>octopus/models/hyperparameter.py</code> <pre><code>@define\nclass FixedHyperparameter(Hyperparameter):\n    \"\"\"Fixed Hyperparameter class.\"\"\"\n\n    value: Any = field()\n\n    def __attrs_post_init__(self):\n        if self.value is None:\n            raise ValueError(\"value must be provided for FixedHyperparameter.\")\n\n    def suggest(self, trial: optuna.trial.Trial, unique_name: str) -&gt; Any:\n        \"\"\"Return the fixed value (no trial suggestion needed).\"\"\"\n        return self.value\n</code></pre>"},{"location":"reference/models/#octopus.models.FixedHyperparameter.suggest","title":"<code>suggest(trial, unique_name)</code>","text":"<p>Return the fixed value (no trial suggestion needed).</p> Source code in <code>octopus/models/hyperparameter.py</code> <pre><code>def suggest(self, trial: optuna.trial.Trial, unique_name: str) -&gt; Any:\n    \"\"\"Return the fixed value (no trial suggestion needed).\"\"\"\n    return self.value\n</code></pre>"},{"location":"reference/models/#octopus.models.FloatHyperparameter","title":"<code>FloatHyperparameter</code>","text":"<p>               Bases: <code>Hyperparameter</code></p> <p>Float Hyperparameter class.</p> Source code in <code>octopus/models/hyperparameter.py</code> <pre><code>@define\nclass FloatHyperparameter(Hyperparameter):\n    \"\"\"Float Hyperparameter class.\"\"\"\n\n    low: float = field(validator=validators.instance_of((float, int)))\n    high: float = field(validator=validators.instance_of((float, int)))\n    step: float | None = field(default=None, validator=validators.optional(validators.instance_of((float, int))))\n    log: bool = False\n\n    def __attrs_post_init__(self):\n        if self.low &gt; self.high:\n            raise ValueError(\"Low limit must be &lt;= high limit.\")\n\n        if self.step is not None:\n            if self.step &lt;= 0:\n                raise ValueError(\"step must be greater than 0.\")\n            if self.log:\n                raise ValueError(\"Both step and log cannot be selected at the same time.\")\n\n    def suggest(self, trial: optuna.trial.Trial, unique_name: str) -&gt; float:\n        \"\"\"Suggest a float value using Optuna trial.\"\"\"\n        if self.step is not None:\n            return trial.suggest_float(name=unique_name, low=self.low, high=self.high, step=self.step)\n        else:\n            return trial.suggest_float(name=unique_name, low=self.low, high=self.high, log=self.log)\n</code></pre>"},{"location":"reference/models/#octopus.models.FloatHyperparameter.suggest","title":"<code>suggest(trial, unique_name)</code>","text":"<p>Suggest a float value using Optuna trial.</p> Source code in <code>octopus/models/hyperparameter.py</code> <pre><code>def suggest(self, trial: optuna.trial.Trial, unique_name: str) -&gt; float:\n    \"\"\"Suggest a float value using Optuna trial.\"\"\"\n    if self.step is not None:\n        return trial.suggest_float(name=unique_name, low=self.low, high=self.high, step=self.step)\n    else:\n        return trial.suggest_float(name=unique_name, low=self.low, high=self.high, log=self.log)\n</code></pre>"},{"location":"reference/models/#octopus.models.GPClassifierWrapper","title":"<code>GPClassifierWrapper</code>","text":"<p>               Bases: <code>ClassifierMixin</code>, <code>BaseEstimator</code></p> <p>Wrapper for Gaussian Process Classifier.</p> Source code in <code>octopus/models/wrapper_models/GaussianProcessClassifier.py</code> <pre><code>class GPClassifierWrapper(ClassifierMixin, BaseEstimator):\n    \"\"\"Wrapper for Gaussian Process Classifier.\"\"\"\n\n    _estimator_type = \"classifier\"\n\n    def __init__(\n        self,\n        kernel: str | Kernel = \"RBF\",\n        optimizer: Literal[\"fmin_l_bfgs_b\"] | Callable | None = \"fmin_l_bfgs_b\",\n        n_restarts_optimizer: int = 0,\n        max_iter_predict: int = 100,\n        warm_start: bool = False,\n        copy_X_train: bool = True,\n        random_state: int | None = None,\n        multi_class: Literal[\"one_vs_rest\", \"one_vs_one\"] = \"one_vs_rest\",\n    ) -&gt; None:\n        self.kernel = kernel\n        self.optimizer = optimizer\n        self.n_restarts_optimizer = n_restarts_optimizer\n        self.max_iter_predict = max_iter_predict\n        self.warm_start = warm_start\n        self.copy_X_train = copy_X_train\n        self.random_state = random_state\n        self.multi_class = multi_class\n\n    @property\n    def classes_(self) -&gt; np.ndarray:\n        \"\"\"Get the class labels.\"\"\"\n        check_is_fitted(self, \"model_\")\n        return self.model_.classes_\n\n    def fit(self, X: Any, y: Any) -&gt; \"GPClassifierWrapper\":\n        \"\"\"Fit the Gaussian Process model.\"\"\"\n        X, y = check_X_y(X, y)\n        kernel = self._get_kernel(self.kernel)\n        self.model_ = GaussianProcessClassifier(\n            kernel=kernel,\n            optimizer=self.optimizer,\n            n_restarts_optimizer=self.n_restarts_optimizer,\n            max_iter_predict=self.max_iter_predict,\n            warm_start=self.warm_start,\n            copy_X_train=self.copy_X_train,\n            random_state=self.random_state,\n            multi_class=self.multi_class,\n        )\n        self.model_.fit(X, y)\n        return self\n\n    def predict(self, X: Any) -&gt; np.ndarray:\n        \"\"\"Predict using the Gaussian Process model.\"\"\"\n        check_is_fitted(self, \"model_\")\n        X = check_array(X)\n        return self.model_.predict(X)\n\n    def predict_proba(self, X: Any) -&gt; np.ndarray:\n        \"\"\"Predict class probabilities using the Gaussian Process model.\"\"\"\n        check_is_fitted(self, \"model_\")\n        X = check_array(X)\n        return self.model_.predict_proba(X)\n\n    def _get_kernel(self, kernel_str: str | Kernel) -&gt; Kernel:\n        \"\"\"Get the kernel object based on the kernel string.\"\"\"\n        if isinstance(kernel_str, Kernel):\n            return kernel_str\n        elif kernel_str == \"RBF\":\n            return RBF()\n        elif kernel_str == \"Matern\":\n            return Matern()\n        elif kernel_str == \"RationalQuadratic\":\n            return RationalQuadratic()\n        else:\n            raise ValueError(f\"Unknown kernel: {kernel_str}\")\n</code></pre>"},{"location":"reference/models/#octopus.models.GPClassifierWrapper.classes_","title":"<code>classes_</code>  <code>property</code>","text":"<p>Get the class labels.</p>"},{"location":"reference/models/#octopus.models.GPClassifierWrapper.fit","title":"<code>fit(X, y)</code>","text":"<p>Fit the Gaussian Process model.</p> Source code in <code>octopus/models/wrapper_models/GaussianProcessClassifier.py</code> <pre><code>def fit(self, X: Any, y: Any) -&gt; \"GPClassifierWrapper\":\n    \"\"\"Fit the Gaussian Process model.\"\"\"\n    X, y = check_X_y(X, y)\n    kernel = self._get_kernel(self.kernel)\n    self.model_ = GaussianProcessClassifier(\n        kernel=kernel,\n        optimizer=self.optimizer,\n        n_restarts_optimizer=self.n_restarts_optimizer,\n        max_iter_predict=self.max_iter_predict,\n        warm_start=self.warm_start,\n        copy_X_train=self.copy_X_train,\n        random_state=self.random_state,\n        multi_class=self.multi_class,\n    )\n    self.model_.fit(X, y)\n    return self\n</code></pre>"},{"location":"reference/models/#octopus.models.GPClassifierWrapper.predict","title":"<code>predict(X)</code>","text":"<p>Predict using the Gaussian Process model.</p> Source code in <code>octopus/models/wrapper_models/GaussianProcessClassifier.py</code> <pre><code>def predict(self, X: Any) -&gt; np.ndarray:\n    \"\"\"Predict using the Gaussian Process model.\"\"\"\n    check_is_fitted(self, \"model_\")\n    X = check_array(X)\n    return self.model_.predict(X)\n</code></pre>"},{"location":"reference/models/#octopus.models.GPClassifierWrapper.predict_proba","title":"<code>predict_proba(X)</code>","text":"<p>Predict class probabilities using the Gaussian Process model.</p> Source code in <code>octopus/models/wrapper_models/GaussianProcessClassifier.py</code> <pre><code>def predict_proba(self, X: Any) -&gt; np.ndarray:\n    \"\"\"Predict class probabilities using the Gaussian Process model.\"\"\"\n    check_is_fitted(self, \"model_\")\n    X = check_array(X)\n    return self.model_.predict_proba(X)\n</code></pre>"},{"location":"reference/models/#octopus.models.GPRegressorWrapper","title":"<code>GPRegressorWrapper</code>","text":"<p>               Bases: <code>RegressorMixin</code>, <code>BaseEstimator</code></p> <p>Wrapper for Gaussian Process Regressor.</p> Source code in <code>octopus/models/wrapper_models/GaussianProcessRegressor.py</code> <pre><code>class GPRegressorWrapper(RegressorMixin, BaseEstimator):\n    \"\"\"Wrapper for Gaussian Process Regressor.\"\"\"\n\n    _estimator_type = \"regressor\"\n\n    def __init__(\n        self,\n        kernel: Literal[\"RBF\", \"Matern\", \"RationalQuadratic\"] | Kernel = \"RBF\",\n        alpha: float = 1e-10,\n        optimizer: Literal[\"fmin_l_bfgs_b\"] | Callable | None = \"fmin_l_bfgs_b\",\n        n_restarts_optimizer: int = 0,\n        normalize_y: bool = False,\n        copy_X_train: bool = True,\n        random_state: int | None = None,\n    ) -&gt; None:\n        self.kernel = kernel\n        self.alpha = alpha\n        self.optimizer = optimizer\n        self.n_restarts_optimizer = n_restarts_optimizer\n        self.normalize_y = normalize_y\n        self.copy_X_train = copy_X_train\n        self.random_state = random_state\n\n    def fit(self, X: Any, y: Any) -&gt; \"GPRegressorWrapper\":\n        \"\"\"Fit the Gaussian Process model.\"\"\"\n        X, y = check_X_y(X, y, y_numeric=True)\n        kernel = self._get_kernel(self.kernel)\n        self.model_ = GaussianProcessRegressor(\n            kernel=kernel,\n            alpha=self.alpha,\n            optimizer=self.optimizer,\n            n_restarts_optimizer=self.n_restarts_optimizer,\n            normalize_y=self.normalize_y,\n            copy_X_train=self.copy_X_train,\n            random_state=self.random_state,\n        )\n        self.model_.fit(X, y)\n        return self\n\n    def predict(self, X: Any) -&gt; np.ndarray:\n        \"\"\"Predict using the Gaussian Process model.\"\"\"\n        check_is_fitted(self, \"model_\")\n        X = check_array(X)\n        return self.model_.predict(X)\n\n    def _get_kernel(self, kernel_str: Literal[\"RBF\", \"Matern\", \"RationalQuadratic\"] | Kernel) -&gt; Kernel:\n        \"\"\"Get the kernel object based on the kernel string.\"\"\"\n        if isinstance(kernel_str, Kernel):\n            return kernel_str\n        elif kernel_str == \"RBF\":\n            return RBF()\n        elif kernel_str == \"Matern\":\n            return Matern()\n        elif kernel_str == \"RationalQuadratic\":\n            return RationalQuadratic()\n        else:\n            raise ValueError(f\"Unknown kernel: {kernel_str}\")\n</code></pre>"},{"location":"reference/models/#octopus.models.GPRegressorWrapper.fit","title":"<code>fit(X, y)</code>","text":"<p>Fit the Gaussian Process model.</p> Source code in <code>octopus/models/wrapper_models/GaussianProcessRegressor.py</code> <pre><code>def fit(self, X: Any, y: Any) -&gt; \"GPRegressorWrapper\":\n    \"\"\"Fit the Gaussian Process model.\"\"\"\n    X, y = check_X_y(X, y, y_numeric=True)\n    kernel = self._get_kernel(self.kernel)\n    self.model_ = GaussianProcessRegressor(\n        kernel=kernel,\n        alpha=self.alpha,\n        optimizer=self.optimizer,\n        n_restarts_optimizer=self.n_restarts_optimizer,\n        normalize_y=self.normalize_y,\n        copy_X_train=self.copy_X_train,\n        random_state=self.random_state,\n    )\n    self.model_.fit(X, y)\n    return self\n</code></pre>"},{"location":"reference/models/#octopus.models.GPRegressorWrapper.predict","title":"<code>predict(X)</code>","text":"<p>Predict using the Gaussian Process model.</p> Source code in <code>octopus/models/wrapper_models/GaussianProcessRegressor.py</code> <pre><code>def predict(self, X: Any) -&gt; np.ndarray:\n    \"\"\"Predict using the Gaussian Process model.\"\"\"\n    check_is_fitted(self, \"model_\")\n    X = check_array(X)\n    return self.model_.predict(X)\n</code></pre>"},{"location":"reference/models/#octopus.models.IntHyperparameter","title":"<code>IntHyperparameter</code>","text":"<p>               Bases: <code>Hyperparameter</code></p> <p>Integer Hyperparameter class.</p> Source code in <code>octopus/models/hyperparameter.py</code> <pre><code>@define\nclass IntHyperparameter(Hyperparameter):\n    \"\"\"Integer Hyperparameter class.\"\"\"\n\n    low: int = field(validator=validators.instance_of(int))\n    high: int = field(validator=validators.instance_of(int))\n    step: int | None = field(default=None, validator=validators.optional(validators.instance_of(int)))\n    log: bool = False\n\n    def __attrs_post_init__(self):\n        if self.low &gt; self.high:\n            raise ValueError(\"Low limit must be &lt;= high limit.\")\n\n        if self.step is not None:\n            if self.step &lt;= 0:\n                raise ValueError(\"step must be greater than 0.\")\n            if self.log:\n                raise ValueError(\"Both step and log cannot be selected at the same time.\")\n\n    def suggest(self, trial: optuna.trial.Trial, unique_name: str) -&gt; int:\n        \"\"\"Suggest an int value using Optuna trial.\"\"\"\n        if self.step is not None:\n            return trial.suggest_int(name=unique_name, low=self.low, high=self.high, step=self.step)\n        else:\n            return trial.suggest_int(name=unique_name, low=self.low, high=self.high, log=self.log)\n</code></pre>"},{"location":"reference/models/#octopus.models.IntHyperparameter.suggest","title":"<code>suggest(trial, unique_name)</code>","text":"<p>Suggest an int value using Optuna trial.</p> Source code in <code>octopus/models/hyperparameter.py</code> <pre><code>def suggest(self, trial: optuna.trial.Trial, unique_name: str) -&gt; int:\n    \"\"\"Suggest an int value using Optuna trial.\"\"\"\n    if self.step is not None:\n        return trial.suggest_int(name=unique_name, low=self.low, high=self.high, step=self.step)\n    else:\n        return trial.suggest_int(name=unique_name, low=self.low, high=self.high, log=self.log)\n</code></pre>"},{"location":"reference/models/#octopus.models.ModelConfig","title":"<code>ModelConfig</code>","text":"<p>Create model config.</p> Source code in <code>octopus/models/config.py</code> <pre><code>@define(slots=False)\nclass ModelConfig:\n    \"\"\"Create model config.\"\"\"\n\n    model_class: type[BaseModel]\n    feature_method: str\n    ml_type: MLType = field(validator=validators.in_(ML_TYPES))\n    hyperparameters: list[Hyperparameter] = field(validator=validate_hyperparameters)\n    n_repeats: None | int = field(factory=lambda: None)\n    n_jobs: None | str = field(factory=lambda: \"n_jobs\")\n    model_seed: None | str = field(factory=lambda: \"model_seed\")\n    chpo_compatible: bool = field(default=False)\n    scaler: None | str = field(default=None, validator=validators.in_([None, \"StandardScaler\"]))\n    imputation_required: bool = field(default=True)\n    categorical_enabled: bool = field(default=False)\n</code></pre>"},{"location":"reference/models/#octopus.models.Models","title":"<code>Models</code>","text":"<p>Central registry and inventory for models.</p> Usage Source code in <code>octopus/models/core.py</code> <pre><code>class Models:\n    \"\"\"Central registry and inventory for models.\n\n    Usage:\n        # Get config\n        cfg = Models.get_config(\"ExtraTreesClassifier\")\n\n        # Create Optuna params (with optional custom hyperparameters)\n        params = Models.create_trial_parameters(\n            trial=trial,\n            model_name=\"ExtraTreesClassifier\",\n            custom_hyperparameters=None,  # or {\"ExtraTreesClassifier\": [custom_hps]}\n            n_jobs=4,\n            model_seed=42,\n        )\n\n        # Instantiate estimator\n        model = Models.get_instance(\"ExtraTreesClassifier\", params)\n    \"\"\"\n\n    # Internal registry: model name -&gt; function returning ModelConfig\n    _config_factories: ClassVar[dict[str, Callable[[], ModelConfig]]] = {}\n\n    # Internal cache: model name -&gt; ModelConfig\n    _model_configs: ClassVar[dict[str, ModelConfig]] = {}\n\n    @classmethod\n    def register(cls, name: str) -&gt; Callable[[Callable[[], ModelConfig]], Callable[[], ModelConfig]]:\n        \"\"\"Register a model configuration factory function under a given name.\n\n        Args:\n            name: The name to register the model under.\n\n        Returns:\n            Decorator function.\n        \"\"\"\n\n        def decorator(factory: Callable[[], ModelConfig]) -&gt; Callable[[], ModelConfig]:\n            if name in cls._config_factories:\n                raise ValueError(f\"Model '{name}' is already registered.\")\n            cls._config_factories[name] = factory\n            return factory\n\n        return decorator\n\n    @classmethod\n    def get_config(cls, name: str) -&gt; ModelConfig:\n        \"\"\"Get model configuration by name.\n\n        Args:\n            name: The name of the model to retrieve.\n\n        Returns:\n            The ModelConfig instance for the specified model.\n\n        Raises:\n            UnknownModelError: If no model with the specified name is found.\n        \"\"\"\n        # Return cached config if available\n        if name in cls._model_configs:\n            return cls._model_configs[name]\n\n        # Lookup factory\n        factory = cls._config_factories.get(name)\n        if factory is None:\n            available = \", \".join(sorted(cls._config_factories.keys()))\n            raise UnknownModelError(\n                f\"Unknown model '{name}'. Available models are: {available}. Please check the model name and try again.\"\n            )\n\n        # Build config via factory and enforce name consistency\n        config = factory()\n        # Use object.__setattr__ to bypass attrs' attribute restrictions\n        object.__setattr__(config, \"name\", name)\n        cls._model_configs[name] = config\n        return config\n\n    @classmethod\n    def get_instance(cls, name: str, params: dict[str, Any]):\n        \"\"\"Get model class by name and initialize it with the provided parameters.\n\n        Args:\n            name: The name of the model to retrieve.\n            params: The parameters for model initialization.\n\n        Returns:\n            The initialized model instance.\n        \"\"\"\n        model_config = cls.get_config(name)\n        return model_config.model_class(**params)\n\n    @classmethod\n    def create_trial_parameters(\n        cls,\n        trial: optuna.trial.Trial,\n        model_name: str,\n        custom_hyperparameters: dict[str, list[Hyperparameter]] | None,\n        n_jobs: int,\n        model_seed: int,\n    ) -&gt; dict[str, Any]:\n        \"\"\"Create Optuna parameters for a specific model.\n\n        Args:\n            trial: The Optuna trial object.\n            model_name: The name of the model to create parameters for.\n            custom_hyperparameters: Optional dict mapping model names to custom hyperparameter lists.\n                                   If None or model not in dict, uses default hyperparameters from config.\n            n_jobs: Number of jobs for parallel execution.\n            model_seed: Random seed for the model.\n\n        Returns:\n            Dictionary of parameter names to values.\n        \"\"\"\n        # Get model configuration\n        model_item = cls.get_config(model_name)\n\n        # Resolve hyperparameters: use custom if provided, otherwise use defaults\n        if custom_hyperparameters is not None and model_name in custom_hyperparameters:\n            hyperparameters = custom_hyperparameters[model_name]\n        else:\n            hyperparameters = model_item.hyperparameters\n\n        # Create parameters\n        params: dict[str, Any] = {}\n\n        for hp in hyperparameters:\n            # get_config() always sets name, safe to access\n            unique_name = f\"{hp.name}_{model_item.name}\"  # type: ignore[attr-defined]\n            params[hp.name] = hp.suggest(trial, unique_name)\n\n        if model_item.n_jobs is not None:\n            params[model_item.n_jobs] = n_jobs\n        if model_item.model_seed is not None:\n            params[model_item.model_seed] = model_seed\n\n        return params\n</code></pre>"},{"location":"reference/models/#octopus.models.Models--get-config","title":"Get config","text":"<p>cfg = Models.get_config(\"ExtraTreesClassifier\")</p>"},{"location":"reference/models/#octopus.models.Models--create-optuna-params-with-optional-custom-hyperparameters","title":"Create Optuna params (with optional custom hyperparameters)","text":"<p>params = Models.create_trial_parameters(     trial=trial,     model_name=\"ExtraTreesClassifier\",     custom_hyperparameters=None,  # or {\"ExtraTreesClassifier\": [custom_hps]}     n_jobs=4,     model_seed=42, )</p>"},{"location":"reference/models/#octopus.models.Models--instantiate-estimator","title":"Instantiate estimator","text":"<p>model = Models.get_instance(\"ExtraTreesClassifier\", params)</p>"},{"location":"reference/models/#octopus.models.Models.create_trial_parameters","title":"<code>create_trial_parameters(trial, model_name, custom_hyperparameters, n_jobs, model_seed)</code>  <code>classmethod</code>","text":"<p>Create Optuna parameters for a specific model.</p> <p>Parameters:</p> Name Type Description Default <code>trial</code> <code>Trial</code> <p>The Optuna trial object.</p> required <code>model_name</code> <code>str</code> <p>The name of the model to create parameters for.</p> required <code>custom_hyperparameters</code> <code>dict[str, list[Hyperparameter]] | None</code> <p>Optional dict mapping model names to custom hyperparameter lists.                    If None or model not in dict, uses default hyperparameters from config.</p> required <code>n_jobs</code> <code>int</code> <p>Number of jobs for parallel execution.</p> required <code>model_seed</code> <code>int</code> <p>Random seed for the model.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary of parameter names to values.</p> Source code in <code>octopus/models/core.py</code> <pre><code>@classmethod\ndef create_trial_parameters(\n    cls,\n    trial: optuna.trial.Trial,\n    model_name: str,\n    custom_hyperparameters: dict[str, list[Hyperparameter]] | None,\n    n_jobs: int,\n    model_seed: int,\n) -&gt; dict[str, Any]:\n    \"\"\"Create Optuna parameters for a specific model.\n\n    Args:\n        trial: The Optuna trial object.\n        model_name: The name of the model to create parameters for.\n        custom_hyperparameters: Optional dict mapping model names to custom hyperparameter lists.\n                               If None or model not in dict, uses default hyperparameters from config.\n        n_jobs: Number of jobs for parallel execution.\n        model_seed: Random seed for the model.\n\n    Returns:\n        Dictionary of parameter names to values.\n    \"\"\"\n    # Get model configuration\n    model_item = cls.get_config(model_name)\n\n    # Resolve hyperparameters: use custom if provided, otherwise use defaults\n    if custom_hyperparameters is not None and model_name in custom_hyperparameters:\n        hyperparameters = custom_hyperparameters[model_name]\n    else:\n        hyperparameters = model_item.hyperparameters\n\n    # Create parameters\n    params: dict[str, Any] = {}\n\n    for hp in hyperparameters:\n        # get_config() always sets name, safe to access\n        unique_name = f\"{hp.name}_{model_item.name}\"  # type: ignore[attr-defined]\n        params[hp.name] = hp.suggest(trial, unique_name)\n\n    if model_item.n_jobs is not None:\n        params[model_item.n_jobs] = n_jobs\n    if model_item.model_seed is not None:\n        params[model_item.model_seed] = model_seed\n\n    return params\n</code></pre>"},{"location":"reference/models/#octopus.models.Models.get_config","title":"<code>get_config(name)</code>  <code>classmethod</code>","text":"<p>Get model configuration by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the model to retrieve.</p> required <p>Returns:</p> Type Description <code>ModelConfig</code> <p>The ModelConfig instance for the specified model.</p> <p>Raises:</p> Type Description <code>UnknownModelError</code> <p>If no model with the specified name is found.</p> Source code in <code>octopus/models/core.py</code> <pre><code>@classmethod\ndef get_config(cls, name: str) -&gt; ModelConfig:\n    \"\"\"Get model configuration by name.\n\n    Args:\n        name: The name of the model to retrieve.\n\n    Returns:\n        The ModelConfig instance for the specified model.\n\n    Raises:\n        UnknownModelError: If no model with the specified name is found.\n    \"\"\"\n    # Return cached config if available\n    if name in cls._model_configs:\n        return cls._model_configs[name]\n\n    # Lookup factory\n    factory = cls._config_factories.get(name)\n    if factory is None:\n        available = \", \".join(sorted(cls._config_factories.keys()))\n        raise UnknownModelError(\n            f\"Unknown model '{name}'. Available models are: {available}. Please check the model name and try again.\"\n        )\n\n    # Build config via factory and enforce name consistency\n    config = factory()\n    # Use object.__setattr__ to bypass attrs' attribute restrictions\n    object.__setattr__(config, \"name\", name)\n    cls._model_configs[name] = config\n    return config\n</code></pre>"},{"location":"reference/models/#octopus.models.Models.get_instance","title":"<code>get_instance(name, params)</code>  <code>classmethod</code>","text":"<p>Get model class by name and initialize it with the provided parameters.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the model to retrieve.</p> required <code>params</code> <code>dict[str, Any]</code> <p>The parameters for model initialization.</p> required <p>Returns:</p> Type Description <p>The initialized model instance.</p> Source code in <code>octopus/models/core.py</code> <pre><code>@classmethod\ndef get_instance(cls, name: str, params: dict[str, Any]):\n    \"\"\"Get model class by name and initialize it with the provided parameters.\n\n    Args:\n        name: The name of the model to retrieve.\n        params: The parameters for model initialization.\n\n    Returns:\n        The initialized model instance.\n    \"\"\"\n    model_config = cls.get_config(name)\n    return model_config.model_class(**params)\n</code></pre>"},{"location":"reference/models/#octopus.models.Models.register","title":"<code>register(name)</code>  <code>classmethod</code>","text":"<p>Register a model configuration factory function under a given name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to register the model under.</p> required <p>Returns:</p> Type Description <code>Callable[[Callable[[], ModelConfig]], Callable[[], ModelConfig]]</code> <p>Decorator function.</p> Source code in <code>octopus/models/core.py</code> <pre><code>@classmethod\ndef register(cls, name: str) -&gt; Callable[[Callable[[], ModelConfig]], Callable[[], ModelConfig]]:\n    \"\"\"Register a model configuration factory function under a given name.\n\n    Args:\n        name: The name to register the model under.\n\n    Returns:\n        Decorator function.\n    \"\"\"\n\n    def decorator(factory: Callable[[], ModelConfig]) -&gt; Callable[[], ModelConfig]:\n        if name in cls._config_factories:\n            raise ValueError(f\"Model '{name}' is already registered.\")\n        cls._config_factories[name] = factory\n        return factory\n\n    return decorator\n</code></pre>"},{"location":"reference/models/#octopus.models.ard_regressor","title":"<code>ard_regressor()</code>","text":"<p>ARD regression model class.</p> Source code in <code>octopus/models/regression_models.py</code> <pre><code>@Models.register(\"ARDRegressor\")\ndef ard_regressor() -&gt; ModelConfig:\n    \"\"\"ARD regression model class.\"\"\"\n    return ModelConfig(\n        model_class=ARDRegression,\n        ml_type=\"regression\",\n        feature_method=\"permutation\",\n        n_repeats=2,\n        chpo_compatible=False,\n        scaler=\"StandardScaler\",\n        imputation_required=True,\n        categorical_enabled=False,\n        hyperparameters=[\n            FloatHyperparameter(name=\"alpha_1\", low=1e-10, high=1e-3, log=True),\n            FloatHyperparameter(name=\"alpha_2\", low=1e-10, high=1e-3, log=True),\n            FloatHyperparameter(name=\"lambda_1\", low=1e-10, high=1e-3, log=True),\n            FloatHyperparameter(name=\"lambda_2\", low=1e-10, high=1e-3, log=True),\n            FloatHyperparameter(name=\"threshold_lambda\", low=1e3, high=1e5, log=True),\n            FloatHyperparameter(name=\"tol\", low=1e-5, high=1e-1, log=True),\n            FixedHyperparameter(name=\"fit_intercept\", value=True),\n        ],\n        n_jobs=None,\n        model_seed=None,\n    )\n</code></pre>"},{"location":"reference/models/#octopus.models.catboost_classifier","title":"<code>catboost_classifier()</code>","text":"<p>CatBoost classification model config.</p> Source code in <code>octopus/models/classification_models.py</code> <pre><code>@Models.register(\"CatBoostClassifier\")\ndef catboost_classifier() -&gt; ModelConfig:\n    \"\"\"CatBoost classification model config.\"\"\"\n    return ModelConfig(\n        model_class=CatBoostClassifier,\n        ml_type=\"classification\",\n        feature_method=\"internal\",\n        chpo_compatible=True,\n        scaler=None,\n        imputation_required=False,\n        categorical_enabled=True,\n        hyperparameters=[\n            FloatHyperparameter(name=\"learning_rate\", low=1e-2, high=1e-1, log=True),\n            IntHyperparameter(name=\"depth\", low=3, high=10),\n            FloatHyperparameter(name=\"l2_leaf_reg\", low=2, high=10),\n            FloatHyperparameter(name=\"random_strength\", low=2, high=10),\n            FloatHyperparameter(name=\"rsm\", low=0.1, high=1),\n            FixedHyperparameter(name=\"iterations\", value=1000),\n            CategoricalHyperparameter(name=\"auto_class_weights\", choices=[None, \"Balanced\"]),\n            FixedHyperparameter(name=\"allow_writing_files\", value=False),\n            FixedHyperparameter(name=\"logging_level\", value=\"Silent\"),\n            FixedHyperparameter(name=\"thread_count\", value=1),\n            FixedHyperparameter(name=\"task_type\", value=\"CPU\"),\n        ],\n        n_jobs=\"thread_count\",\n        model_seed=\"random_state\",\n    )\n</code></pre>"},{"location":"reference/models/#octopus.models.catboost_regressor","title":"<code>catboost_regressor()</code>","text":"<p>Cat boost regression model class.</p> Source code in <code>octopus/models/regression_models.py</code> <pre><code>@Models.register(\"CatBoostRegressor\")\ndef catboost_regressor() -&gt; ModelConfig:\n    \"\"\"Cat boost regression model class.\"\"\"\n    return ModelConfig(\n        model_class=CatBoostRegressor,\n        ml_type=\"regression\",\n        feature_method=\"internal\",\n        chpo_compatible=True,\n        scaler=None,\n        imputation_required=False,\n        categorical_enabled=True,\n        hyperparameters=[\n            FloatHyperparameter(name=\"learning_rate\", low=1e-3, high=1e-1, log=True),\n            IntHyperparameter(name=\"depth\", low=3, high=10),\n            FloatHyperparameter(name=\"l2_leaf_reg\", low=2, high=10),\n            FloatHyperparameter(name=\"random_strength\", low=2, high=10),\n            FloatHyperparameter(name=\"rsm\", low=0.1, high=1),\n            FixedHyperparameter(name=\"iterations\", value=500),\n            FixedHyperparameter(name=\"allow_writing_files\", value=False),\n            FixedHyperparameter(name=\"logging_level\", value=\"Silent\"),\n            FixedHyperparameter(name=\"thread_count\", value=1),\n            FixedHyperparameter(name=\"task_type\", value=\"CPU\"),\n        ],\n        n_jobs=\"thread_count\",\n        model_seed=\"random_state\",\n    )\n</code></pre>"},{"location":"reference/models/#octopus.models.elastic_net_regressor","title":"<code>elastic_net_regressor()</code>","text":"<p>ElasticNet regression model class.</p> Source code in <code>octopus/models/regression_models.py</code> <pre><code>@Models.register(\"ElasticNetRegressor\")\ndef elastic_net_regressor() -&gt; ModelConfig:\n    \"\"\"ElasticNet regression model class.\"\"\"\n    return ModelConfig(\n        model_class=ElasticNet,\n        ml_type=\"regression\",\n        feature_method=\"shap\",\n        chpo_compatible=True,\n        scaler=\"StandardScaler\",\n        imputation_required=True,\n        categorical_enabled=False,\n        hyperparameters=[\n            FloatHyperparameter(name=\"alpha\", low=1e-10, high=1e2, log=True),\n            FloatHyperparameter(name=\"l1_ratio\", low=0, high=1, log=False),\n            CategoricalHyperparameter(name=\"fit_intercept\", choices=[True, False]),\n            FloatHyperparameter(name=\"tol\", low=1e-5, high=1e-1, log=True),\n            FixedHyperparameter(name=\"max_iter\", value=4000),\n            FixedHyperparameter(name=\"selection\", value=\"random\"),\n        ],\n        n_jobs=None,\n        model_seed=\"random_state\",\n    )\n</code></pre>"},{"location":"reference/models/#octopus.models.extra_trees_classifier","title":"<code>extra_trees_classifier()</code>","text":"<p>ExtraTrees classification model config.</p> Source code in <code>octopus/models/classification_models.py</code> <pre><code>@Models.register(\"ExtraTreesClassifier\")\ndef extra_trees_classifier() -&gt; ModelConfig:\n    \"\"\"ExtraTrees classification model config.\"\"\"\n    return ModelConfig(\n        model_class=ExtraTreesClassifier,\n        ml_type=\"classification\",\n        feature_method=\"internal\",\n        chpo_compatible=True,\n        scaler=None,\n        imputation_required=True,\n        categorical_enabled=False,\n        hyperparameters=[\n            IntHyperparameter(name=\"max_depth\", low=2, high=32),\n            IntHyperparameter(name=\"min_samples_split\", low=2, high=100),\n            IntHyperparameter(name=\"min_samples_leaf\", low=1, high=50),\n            FloatHyperparameter(name=\"max_features\", low=0.1, high=1),\n            IntHyperparameter(name=\"n_estimators\", low=100, high=500, log=False),\n            CategoricalHyperparameter(name=\"class_weight\", choices=[None, \"balanced\"]),\n            FixedHyperparameter(name=\"criterion\", value=\"entropy\"),\n            FixedHyperparameter(name=\"bootstrap\", value=True),\n        ],\n        n_jobs=\"n_jobs\",\n        model_seed=\"random_state\",\n    )\n</code></pre>"},{"location":"reference/models/#octopus.models.extra_trees_regressor","title":"<code>extra_trees_regressor()</code>","text":"<p>ExtraTrees regression model class.</p> Source code in <code>octopus/models/regression_models.py</code> <pre><code>@Models.register(\"ExtraTreesRegressor\")\ndef extra_trees_regressor() -&gt; ModelConfig:\n    \"\"\"ExtraTrees regression model class.\"\"\"\n    return ModelConfig(\n        model_class=ExtraTreesRegressor,\n        ml_type=\"regression\",\n        feature_method=\"internal\",\n        chpo_compatible=True,\n        scaler=None,\n        imputation_required=True,\n        categorical_enabled=False,\n        hyperparameters=[\n            IntHyperparameter(name=\"max_depth\", low=2, high=32),\n            IntHyperparameter(name=\"min_samples_split\", low=2, high=100),\n            IntHyperparameter(name=\"min_samples_leaf\", low=1, high=50),\n            IntHyperparameter(name=\"n_estimators\", low=100, high=500, log=False),\n            FloatHyperparameter(name=\"max_features\", low=0.1, high=1),\n        ],\n        n_jobs=\"n_jobs\",\n        model_seed=\"random_state\",\n    )\n</code></pre>"},{"location":"reference/models/#octopus.models.gaussian_process_classifier","title":"<code>gaussian_process_classifier()</code>","text":"<p>Gaussian process classification model config.</p> Source code in <code>octopus/models/classification_models.py</code> <pre><code>@Models.register(\"GaussianProcessClassifier\")\ndef gaussian_process_classifier() -&gt; ModelConfig:\n    \"\"\"Gaussian process classification model config.\"\"\"\n    return ModelConfig(\n        model_class=GPClassifierWrapper,\n        ml_type=\"classification\",\n        feature_method=\"permutation\",\n        n_repeats=2,\n        chpo_compatible=False,\n        scaler=\"StandardScaler\",\n        imputation_required=True,\n        categorical_enabled=False,\n        hyperparameters=[\n            CategoricalHyperparameter(name=\"kernel\", choices=[\"RBF\", \"Matern\", \"RationalQuadratic\"]),\n            CategoricalHyperparameter(name=\"optimizer\", choices=[\"fmin_l_bfgs_b\", None]),\n            IntHyperparameter(name=\"n_restarts_optimizer\", low=0, high=10, log=False),\n            IntHyperparameter(name=\"max_iter_predict\", low=50, high=200, log=False),\n        ],\n        n_jobs=None,\n        model_seed=\"random_state\",\n    )\n</code></pre>"},{"location":"reference/models/#octopus.models.gaussian_process_regressor","title":"<code>gaussian_process_regressor()</code>","text":"<p>Gaussian process regression model class.</p> Source code in <code>octopus/models/regression_models.py</code> <pre><code>@Models.register(\"GaussianProcessRegressor\")\ndef gaussian_process_regressor() -&gt; ModelConfig:\n    \"\"\"Gaussian process regression model class.\"\"\"\n    return ModelConfig(\n        model_class=GPRegressorWrapper,\n        ml_type=\"regression\",\n        feature_method=\"permutation\",\n        n_repeats=2,\n        chpo_compatible=False,\n        scaler=\"StandardScaler\",\n        imputation_required=True,\n        categorical_enabled=False,\n        hyperparameters=[\n            CategoricalHyperparameter(name=\"kernel\", choices=[\"RBF\", \"Matern\", \"RationalQuadratic\"]),\n            FloatHyperparameter(name=\"alpha\", low=1e-10, high=1e-1, log=True),\n            FloatHyperparameter(name=\"alpha\", low=1e-10, high=1e-1, log=True),\n            CategoricalHyperparameter(name=\"normalize_y\", choices=[True, False]),\n            CategoricalHyperparameter(name=\"optimizer\", choices=[\"fmin_l_bfgs_b\", None]),\n            IntHyperparameter(name=\"n_restarts_optimizer\", low=0, high=10, log=False),\n        ],\n        n_jobs=None,\n        model_seed=\"random_state\",\n    )\n</code></pre>"},{"location":"reference/models/#octopus.models.gradient_boosting_classifier","title":"<code>gradient_boosting_classifier()</code>","text":"<p>Gradient boosting classification model config.</p> Source code in <code>octopus/models/classification_models.py</code> <pre><code>@Models.register(\"GradientBoostingClassifier\")\ndef gradient_boosting_classifier() -&gt; ModelConfig:\n    \"\"\"Gradient boosting classification model config.\"\"\"\n    return ModelConfig(\n        model_class=GradientBoostingClassifier,\n        ml_type=\"classification\",\n        feature_method=\"internal\",\n        chpo_compatible=True,\n        scaler=None,\n        imputation_required=True,\n        categorical_enabled=False,\n        hyperparameters=[\n            FloatHyperparameter(name=\"learning_rate\", low=0.01, high=1, log=True),\n            IntHyperparameter(name=\"min_samples_leaf\", low=1, high=200),\n            IntHyperparameter(name=\"max_leaf_nodes\", low=3, high=2047),\n            IntHyperparameter(name=\"max_depth\", low=3, high=9, step=2),\n            IntHyperparameter(name=\"n_estimators\", low=30, high=500),\n            FloatHyperparameter(name=\"max_features\", low=0.1, high=1),\n            FixedHyperparameter(name=\"loss\", value=\"log_loss\"),\n        ],\n        n_jobs=None,\n        model_seed=\"random_state\",\n    )\n</code></pre>"},{"location":"reference/models/#octopus.models.gradient_boosting_regressor","title":"<code>gradient_boosting_regressor()</code>","text":"<p>Gradient boost regression model class.</p> Source code in <code>octopus/models/regression_models.py</code> <pre><code>@Models.register(\"GradientBoostingRegressor\")\ndef gradient_boosting_regressor() -&gt; ModelConfig:\n    \"\"\"Gradient boost regression model class.\"\"\"\n    return ModelConfig(\n        model_class=GradientBoostingRegressor,\n        ml_type=\"regression\",\n        feature_method=\"internal\",\n        chpo_compatible=True,\n        scaler=None,\n        imputation_required=True,\n        categorical_enabled=False,\n        hyperparameters=[\n            FloatHyperparameter(name=\"learning_rate\", low=0.01, high=1, log=True),\n            IntHyperparameter(name=\"min_samples_leaf\", low=1, high=200),\n            IntHyperparameter(name=\"max_leaf_nodes\", low=3, high=2047),\n            IntHyperparameter(name=\"max_depth\", low=3, high=9, step=2),\n            IntHyperparameter(name=\"n_estimators\", low=30, high=500),\n            FloatHyperparameter(name=\"max_features\", low=0.1, high=1),\n            FixedHyperparameter(name=\"loss\", value=\"squared_error\"),\n        ],\n        n_jobs=None,\n        model_seed=\"random_state\",\n    )\n</code></pre>"},{"location":"reference/models/#octopus.models.hist_gradient_boosting_classifier","title":"<code>hist_gradient_boosting_classifier()</code>","text":"<p>Histogram-based gradient boosting classification model config (scikit-learn 1.6.1).</p> Source code in <code>octopus/models/classification_models.py</code> <pre><code>@Models.register(\"HistGradientBoostingClassifier\")\ndef hist_gradient_boosting_classifier() -&gt; ModelConfig:\n    \"\"\"Histogram-based gradient boosting classification model config (scikit-learn 1.6.1).\"\"\"\n    return ModelConfig(\n        model_class=HistGradientBoostingClassifier,\n        ml_type=\"classification\",\n        feature_method=\"internal\",\n        chpo_compatible=True,\n        scaler=None,\n        imputation_required=False,\n        categorical_enabled=True,\n        hyperparameters=[\n            FloatHyperparameter(name=\"learning_rate\", low=0.01, high=0.3, log=True),\n            IntHyperparameter(name=\"max_iter\", low=50, high=1000),\n            IntHyperparameter(name=\"max_leaf_nodes\", low=7, high=256),\n            IntHyperparameter(name=\"min_samples_leaf\", low=1, high=200),\n            IntHyperparameter(name=\"max_bins\", low=16, high=255),\n            FloatHyperparameter(name=\"l2_regularization\", low=0.0, high=10.0, log=False),\n            FixedHyperparameter(name=\"loss\", value=\"log_loss\"),\n        ],\n        # HistGradientBoostingClassifier uses `random_state` for seeding (map model_seed -&gt; \"random_state\")\n        n_jobs=None,\n        model_seed=\"random_state\",\n    )\n</code></pre>"},{"location":"reference/models/#octopus.models.hist_gradient_boosting_regressor","title":"<code>hist_gradient_boosting_regressor()</code>","text":"<p>Histogram-based gradient boosting regression model class (scikit-learn 1.6.1).</p> Source code in <code>octopus/models/regression_models.py</code> <pre><code>@Models.register(\"HistGradientBoostingRegressor\")\ndef hist_gradient_boosting_regressor() -&gt; ModelConfig:\n    \"\"\"Histogram-based gradient boosting regression model class (scikit-learn 1.6.1).\"\"\"\n    return ModelConfig(\n        model_class=HistGradientBoostingRegressor,\n        ml_type=\"regression\",\n        feature_method=\"internal\",\n        chpo_compatible=True,\n        scaler=None,\n        imputation_required=False,\n        categorical_enabled=True,\n        hyperparameters=[\n            FloatHyperparameter(name=\"learning_rate\", low=0.01, high=0.3, log=True),\n            IntHyperparameter(name=\"max_iter\", low=50, high=1000),\n            IntHyperparameter(name=\"max_leaf_nodes\", low=7, high=256),\n            FloatHyperparameter(name=\"l2_regularization\", low=1e-6, high=10.0, log=True),\n            IntHyperparameter(name=\"min_samples_leaf\", low=1, high=200),\n            IntHyperparameter(name=\"max_bins\", low=16, high=255),\n            FixedHyperparameter(name=\"loss\", value=\"squared_error\"),\n        ],\n        n_jobs=None,\n        model_seed=\"random_state\",\n    )\n</code></pre>"},{"location":"reference/models/#octopus.models.logistic_regression_classifier","title":"<code>logistic_regression_classifier()</code>","text":"<p>Logistic regression classification model config.</p> Source code in <code>octopus/models/classification_models.py</code> <pre><code>@Models.register(\"LogisticRegressionClassifier\")\ndef logistic_regression_classifier() -&gt; ModelConfig:\n    \"\"\"Logistic regression classification model config.\"\"\"\n    return ModelConfig(\n        model_class=LogisticRegression,\n        ml_type=\"classification\",\n        feature_method=\"permutation\",\n        n_repeats=2,\n        chpo_compatible=True,\n        scaler=\"StandardScaler\",\n        imputation_required=True,\n        categorical_enabled=False,\n        hyperparameters=[\n            IntHyperparameter(name=\"max_iter\", low=100, high=500),\n            FloatHyperparameter(name=\"C\", low=1e-2, high=100, log=True),\n            FloatHyperparameter(name=\"tol\", low=1e-4, high=1e-2, log=True),\n            CategoricalHyperparameter(name=\"penalty\", choices=[\"l2\", None]),\n            CategoricalHyperparameter(name=\"fit_intercept\", choices=[True, False]),\n            CategoricalHyperparameter(name=\"class_weight\", choices=[None, \"balanced\"]),\n            FixedHyperparameter(name=\"solver\", value=\"lbfgs\"),\n        ],\n        n_jobs=\"n_jobs\",\n        model_seed=\"random_state\",\n    )\n</code></pre>"},{"location":"reference/models/#octopus.models.random_forest_classifier","title":"<code>random_forest_classifier()</code>","text":"<p>Random forest classification model config.</p> Source code in <code>octopus/models/classification_models.py</code> <pre><code>@Models.register(\"RandomForestClassifier\")\ndef random_forest_classifier() -&gt; ModelConfig:\n    \"\"\"Random forest classification model config.\"\"\"\n    return ModelConfig(\n        model_class=RandomForestClassifier,\n        ml_type=\"classification\",\n        feature_method=\"internal\",\n        chpo_compatible=True,\n        scaler=None,\n        imputation_required=True,  # maybe: False - check!\n        categorical_enabled=False,\n        hyperparameters=[\n            IntHyperparameter(name=\"max_depth\", low=2, high=32),\n            IntHyperparameter(name=\"min_samples_split\", low=2, high=100),\n            IntHyperparameter(name=\"min_samples_leaf\", low=1, high=50),\n            FloatHyperparameter(name=\"max_features\", low=0.1, high=1),\n            IntHyperparameter(name=\"n_estimators\", low=100, high=500, log=False),\n            CategoricalHyperparameter(name=\"class_weight\", choices=[None, \"balanced\"]),\n        ],\n        n_jobs=\"n_jobs\",\n        model_seed=\"random_state\",\n    )\n</code></pre>"},{"location":"reference/models/#octopus.models.random_forest_regressor","title":"<code>random_forest_regressor()</code>","text":"<p>Random forrest regression model class.</p> Source code in <code>octopus/models/regression_models.py</code> <pre><code>@Models.register(\"RandomForestRegressor\")\ndef random_forest_regressor() -&gt; ModelConfig:\n    \"\"\"Random forrest regression model class.\"\"\"\n    return ModelConfig(\n        model_class=RandomForestRegressor,\n        ml_type=\"regression\",\n        feature_method=\"internal\",\n        chpo_compatible=True,\n        scaler=None,\n        imputation_required=True,  # maybe: False -- check!\n        categorical_enabled=False,\n        hyperparameters=[\n            IntHyperparameter(name=\"max_depth\", low=2, high=32),\n            IntHyperparameter(name=\"min_samples_split\", low=2, high=100),\n            IntHyperparameter(name=\"min_samples_leaf\", low=1, high=50),\n            IntHyperparameter(name=\"n_estimators\", low=100, high=500),\n            FloatHyperparameter(name=\"max_features\", low=0.1, high=1),\n        ],\n        n_jobs=\"n_jobs\",\n        model_seed=\"random_state\",\n    )\n</code></pre>"},{"location":"reference/models/#octopus.models.ridge_regressor","title":"<code>ridge_regressor()</code>","text":"<p>Ridge regression model class.</p> Source code in <code>octopus/models/regression_models.py</code> <pre><code>@Models.register(\"RidgeRegressor\")\ndef ridge_regressor() -&gt; ModelConfig:\n    \"\"\"Ridge regression model class.\"\"\"\n    return ModelConfig(\n        model_class=Ridge,\n        ml_type=\"regression\",\n        feature_method=\"shap\",\n        chpo_compatible=False,\n        scaler=\"StandardScaler\",\n        imputation_required=True,\n        categorical_enabled=False,\n        hyperparameters=[\n            FloatHyperparameter(name=\"alpha\", low=1e-5, high=1e5, log=True),\n            CategoricalHyperparameter(name=\"fit_intercept\", choices=[True, False]),\n            FixedHyperparameter(name=\"solver\", value=\"svd\"),\n        ],\n        n_jobs=None,\n        model_seed=\"random_state\",\n    )\n</code></pre>"},{"location":"reference/models/#octopus.models.svr_regressor","title":"<code>svr_regressor()</code>","text":"<p>Svr regression model class.</p> Source code in <code>octopus/models/regression_models.py</code> <pre><code>@Models.register(\"SvrRegressor\")\ndef svr_regressor() -&gt; ModelConfig:\n    \"\"\"Svr regression model class.\"\"\"\n    return ModelConfig(\n        model_class=SVR,\n        ml_type=\"regression\",\n        feature_method=\"permutation\",\n        n_repeats=2,\n        chpo_compatible=False,\n        scaler=\"StandardScaler\",\n        imputation_required=True,\n        categorical_enabled=False,\n        hyperparameters=[\n            FloatHyperparameter(name=\"C\", low=0.03125, high=32768, log=True),\n            FloatHyperparameter(name=\"epsilon\", low=0.001, high=1, log=True),\n            FloatHyperparameter(name=\"tol\", low=1e-5, high=1e-1, log=True),\n        ],\n        n_jobs=None,\n        model_seed=None,\n    )\n</code></pre>"},{"location":"reference/models/#octopus.models.tabular_nn_regressor","title":"<code>tabular_nn_regressor()</code>","text":"<p>Tabular Neural Network regression model class with categorical embeddings.</p> Source code in <code>octopus/models/regression_models.py</code> <pre><code>@Models.register(\"TabularNNRegressor\")\ndef tabular_nn_regressor() -&gt; ModelConfig:\n    \"\"\"Tabular Neural Network regression model class with categorical embeddings.\"\"\"\n    from .wrapper_models.TabularNNRegressor import TabularNNRegressor  # noqa: PLC0415\n\n    return ModelConfig(\n        model_class=TabularNNRegressor,\n        ml_type=\"regression\",\n        feature_method=\"permutation\",\n        n_repeats=2,\n        chpo_compatible=False,\n        scaler=\"StandardScaler\",\n        imputation_required=False,\n        categorical_enabled=True,\n        hyperparameters=[\n            CategoricalHyperparameter(\n                name=\"hidden_sizes\",\n                choices=[\n                    [512, 256, 128],\n                    [512, 256],\n                    [512, 128],\n                    [256, 256, 128],\n                    [256, 128, 64],\n                    [256, 128],\n                    [256, 64],\n                    [128, 128, 64],\n                    [128, 64],\n                    [128, 32],\n                ],\n            ),\n            FloatHyperparameter(name=\"dropout\", low=0.0, high=0.5),\n            FloatHyperparameter(name=\"learning_rate\", low=1e-5, high=1e-2, log=True),\n            FixedHyperparameter(name=\"weight_decay\", value=1e-5),\n            FixedHyperparameter(name=\"activation\", value=\"elu\"),\n            FixedHyperparameter(name=\"optimizer\", value=\"adamw\"),\n            CategoricalHyperparameter(name=\"batch_size\", choices=[32, 64, 128, 256]),\n            FixedHyperparameter(name=\"epochs\", value=200),\n        ],\n        n_jobs=None,\n        model_seed=\"random_state\",\n    )\n</code></pre>"},{"location":"reference/models/#octopus.models.xgb_classifier","title":"<code>xgb_classifier()</code>","text":"<p>XGBoost classification model config.</p> Source code in <code>octopus/models/classification_models.py</code> <pre><code>@Models.register(\"XGBClassifier\")\ndef xgb_classifier() -&gt; ModelConfig:\n    \"\"\"XGBoost classification model config.\"\"\"\n    return ModelConfig(\n        model_class=XGBClassifier,\n        ml_type=\"classification\",\n        feature_method=\"internal\",\n        chpo_compatible=True,\n        scaler=None,\n        imputation_required=False,\n        categorical_enabled=False,  # Maybe True - check!\n        hyperparameters=[\n            FloatHyperparameter(name=\"learning_rate\", low=1e-4, high=0.3, log=True),\n            IntHyperparameter(name=\"min_child_weight\", low=2, high=15),\n            FloatHyperparameter(name=\"subsample\", low=0.15, high=1.0),\n            IntHyperparameter(name=\"n_estimators\", low=30, high=200),\n            IntHyperparameter(name=\"max_depth\", low=3, high=9, step=2),\n            FixedHyperparameter(name=\"validate_parameters\", value=True),\n        ],\n        n_jobs=\"n_jobs\",\n        model_seed=\"random_state\",\n    )\n</code></pre>"},{"location":"reference/models/#octopus.models.xgb_regressor","title":"<code>xgb_regressor()</code>","text":"<p>XGBoost regression model class.</p> Source code in <code>octopus/models/regression_models.py</code> <pre><code>@Models.register(\"XGBRegressor\")\ndef xgb_regressor() -&gt; ModelConfig:\n    \"\"\"XGBoost regression model class.\"\"\"\n    return ModelConfig(\n        model_class=XGBRegressor,\n        ml_type=\"regression\",\n        feature_method=\"internal\",\n        chpo_compatible=True,\n        scaler=None,\n        imputation_required=False,\n        categorical_enabled=False,  # maybe:True -- check!\n        hyperparameters=[\n            FloatHyperparameter(name=\"learning_rate\", low=1e-4, high=0.3, log=True),\n            IntHyperparameter(name=\"min_child_weight\", low=2, high=15),\n            FloatHyperparameter(name=\"subsample\", low=0.15, high=1.0),\n            IntHyperparameter(name=\"n_estimators\", low=30, high=500),\n            IntHyperparameter(name=\"max_depth\", low=3, high=9, step=2),\n            FixedHyperparameter(name=\"validate_parameters\", value=True),\n            FloatHyperparameter(name=\"lambda\", low=1e-8, high=1, log=True),\n        ],\n        n_jobs=\"n_jobs\",\n        model_seed=\"random_state\",\n    )\n</code></pre>"},{"location":"reference/modules/","title":"octopus.modules","text":"<p>Init modules.</p>"},{"location":"reference/modules/#octopus.modules.AutoGluon","title":"<code>AutoGluon</code>","text":"<p>               Bases: <code>Task</code></p> <p>AG Config.</p> Source code in <code>octopus/modules/autogluon/module.py</code> <pre><code>@define\nclass AutoGluon(Task):\n    \"\"\"AG Config.\"\"\"\n\n    module: ClassVar[str] = \"autogluon\"\n    \"\"\"Module name.\"\"\"\n\n    description: str = field(default=\"\", validator=validators.instance_of(str))\n    \"\"\"Description.\"\"\"\n\n    verbosity: int = field(default=2, validator=validators.instance_of(int))\n    \"\"\"Verbosity levels control how much information is printed.\"\"\"\n    # 0: Only log exceptions\n    # 1: Only log warnings + exceptions\n    # 2: Standard logging\n    # 3: Verbose logging (ex: log validation score every 50 iterations)\n    # 4: Maximally verbose logging (ex: log validation score every iteration)\n\n    time_limit: int | None = field(default=None, validator=validators.optional(validators.instance_of(int)))\n    \"\"\"Approximately, how long a fit should run, in seconds. Default: No limit.\"\"\"\n\n    infer_limit: int | None = field(default=None, validator=validators.optional(validators.instance_of(int)))\n    \"\"\" Inference time limit in seconds per row to adhere to during fit.\"\"\"\n\n    memory_limit: float | Literal[\"auto\"] = field(\n        default=\"auto\", validator=validators.or_(validators.instance_of(float), validators.in_([\"auto\"]))\n    )\n    \"\"\"Amount of memory in GB you want AutoGluon predictor to use.\"\"\"\n\n    fit_strategy: Literal[\"sequential\"] = field(\n        default=\"sequential\", validator=validators.in_([\"sequential\", \"parallel\"])\n    )\n    \"\"\"The strategy used to fit models.\"\"\"\n\n    presets: list[str] = field(\n        default=[\"medium_quality\"],\n        validator=validators.deep_iterable(\n            member_validator=validators.and_(\n                validators.instance_of(str),\n                validators.in_(\n                    [\n                        \"best_quality\",\n                        \"high_quality\",\n                        \"good_quality\",\n                        \"medium_quality\",\n                        \"experimental_quality\",\n                        \"optimize_for_deployment\",\n                        \"interpretable\",\n                        \"ignore_text\",\n                    ]\n                ),\n            ),\n            iterable_validator=validators.instance_of(list),\n        ),\n    )\n    \"\"\"Autogluon presets.\"\"\"\n    # best_quality: Best predictive accuracy, high inference time and disk usage.\n    # high_quality: High predictive accuracy, fast inference. ~8x faster than best.\n    # good_quality: Good predictive accuracy, fast inference. ~4x faster than high.\n    # medium_quality: Medium accuracy, fast inference and training time. ~20x faster.\n    # experimental_quality: testing ground, later be added to the best_quality preset.\n    # optimize_for_deployment: deletes unused models and removes training artifacts.\n    # interpretable: Trades off predictive accuracy for conciseness.\n    # ignore_text: Disables automated feature generation for text features.\n\n    num_cpus: int | Literal[\"auto\"] = field(\n        default=\"auto\", validator=validators.or_(validators.instance_of(int), validators.in_([\"auto\"]))\n    )\n    \"\"\"Number of CPUs used by Autogluon instance. Can be an integer or \"auto\".\"\"\"\n\n    num_bag_folds: int = field(default=5, validator=[validators.instance_of(int), validators.gt(1)])\n    \"\"\"Number of cross validation folds.\"\"\"\n\n    included_model_types: list[str] | None = field(\n        default=None,\n        validator=validators.optional(\n            validators.deep_iterable(\n                member_validator=validators.and_(\n                    validators.instance_of(str),\n                    validators.in_(\n                        [\n                            \"GBM\",  # LightGBM\n                            \"CAT\",  # CatBoost\n                            \"XGB\",  # XGBoost\n                            \"RF\",  # Random Forest\n                            \"XT\",  # Extremely Randomized Trees\n                            \"KNN\",  # K-Nearest Neighbors\n                            \"LR\",  # Linear Regression\n                            \"NN_TORCH\",  # Neural Network implemented in Pytorch\n                            \"FASTAI\",  # Neural Network with FastAI backend\n                        ]\n                    ),\n                ),\n                iterable_validator=validators.instance_of(list),\n            )\n        ),\n    )\n    \"\"\"Includes only listed model types for training during fit.\"\"\"\n</code></pre>"},{"location":"reference/modules/#octopus.modules.AutoGluon.description","title":"<code>description = field(default='', validator=(validators.instance_of(str)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Description.</p>"},{"location":"reference/modules/#octopus.modules.AutoGluon.fit_strategy","title":"<code>fit_strategy = field(default='sequential', validator=(validators.in_(['sequential', 'parallel'])))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The strategy used to fit models.</p>"},{"location":"reference/modules/#octopus.modules.AutoGluon.included_model_types","title":"<code>included_model_types = field(default=None, validator=(validators.optional(validators.deep_iterable(member_validator=(validators.and_(validators.instance_of(str), validators.in_(['GBM', 'CAT', 'XGB', 'RF', 'XT', 'KNN', 'LR', 'NN_TORCH', 'FASTAI']))), iterable_validator=(validators.instance_of(list))))))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Includes only listed model types for training during fit.</p>"},{"location":"reference/modules/#octopus.modules.AutoGluon.infer_limit","title":"<code>infer_limit = field(default=None, validator=(validators.optional(validators.instance_of(int))))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Inference time limit in seconds per row to adhere to during fit.</p>"},{"location":"reference/modules/#octopus.modules.AutoGluon.memory_limit","title":"<code>memory_limit = field(default='auto', validator=(validators.or_(validators.instance_of(float), validators.in_(['auto']))))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Amount of memory in GB you want AutoGluon predictor to use.</p>"},{"location":"reference/modules/#octopus.modules.AutoGluon.module","title":"<code>module = 'autogluon'</code>  <code>class-attribute</code>","text":"<p>Module name.</p>"},{"location":"reference/modules/#octopus.modules.AutoGluon.num_bag_folds","title":"<code>num_bag_folds = field(default=5, validator=[validators.instance_of(int), validators.gt(1)])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of cross validation folds.</p>"},{"location":"reference/modules/#octopus.modules.AutoGluon.num_cpus","title":"<code>num_cpus = field(default='auto', validator=(validators.or_(validators.instance_of(int), validators.in_(['auto']))))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of CPUs used by Autogluon instance. Can be an integer or \"auto\".</p>"},{"location":"reference/modules/#octopus.modules.AutoGluon.presets","title":"<code>presets = field(default=['medium_quality'], validator=(validators.deep_iterable(member_validator=(validators.and_(validators.instance_of(str), validators.in_(['best_quality', 'high_quality', 'good_quality', 'medium_quality', 'experimental_quality', 'optimize_for_deployment', 'interpretable', 'ignore_text']))), iterable_validator=(validators.instance_of(list)))))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Autogluon presets.</p>"},{"location":"reference/modules/#octopus.modules.AutoGluon.time_limit","title":"<code>time_limit = field(default=None, validator=(validators.optional(validators.instance_of(int))))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Approximately, how long a fit should run, in seconds. Default: No limit.</p>"},{"location":"reference/modules/#octopus.modules.AutoGluon.verbosity","title":"<code>verbosity = field(default=2, validator=(validators.instance_of(int)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Verbosity levels control how much information is printed.</p>"},{"location":"reference/modules/#octopus.modules.Boruta","title":"<code>Boruta</code>","text":"<p>               Bases: <code>Task</code></p> <p>Boruta Config.</p> Source code in <code>octopus/modules/boruta/module.py</code> <pre><code>@define\nclass Boruta(Task):\n    \"\"\"Boruta Config.\"\"\"\n\n    module: ClassVar[str] = \"boruta\"\n    \"\"\"Module name.\"\"\"\n\n    model: str = field(validator=[validators.instance_of(str)], default=\"\")\n    \"\"\"Model used by Boruta.\"\"\"\n\n    cv: int = field(validator=[validators.instance_of(int)], default=5)\n    \"\"\"Number of folds for CV.\"\"\"\n\n    perc: int = field(validator=[validators.instance_of(int)], default=100)\n    \"\"\"Percentile (threshold) for comparison between shadow and real features.\"\"\"\n\n    alpha: float = field(validator=[validators.instance_of(float)], default=0.05)\n    \"\"\"Level at which the corrected p-values will get rejected.\"\"\"\n</code></pre>"},{"location":"reference/modules/#octopus.modules.Boruta.alpha","title":"<code>alpha = field(validator=[validators.instance_of(float)], default=0.05)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Level at which the corrected p-values will get rejected.</p>"},{"location":"reference/modules/#octopus.modules.Boruta.cv","title":"<code>cv = field(validator=[validators.instance_of(int)], default=5)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of folds for CV.</p>"},{"location":"reference/modules/#octopus.modules.Boruta.model","title":"<code>model = field(validator=[validators.instance_of(str)], default='')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Model used by Boruta.</p>"},{"location":"reference/modules/#octopus.modules.Boruta.module","title":"<code>module = 'boruta'</code>  <code>class-attribute</code>","text":"<p>Module name.</p>"},{"location":"reference/modules/#octopus.modules.Boruta.perc","title":"<code>perc = field(validator=[validators.instance_of(int)], default=100)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Percentile (threshold) for comparison between shadow and real features.</p>"},{"location":"reference/modules/#octopus.modules.Efs","title":"<code>Efs</code>","text":"<p>               Bases: <code>Task</code></p> <p>EFS Config.</p> Source code in <code>octopus/modules/efs/module.py</code> <pre><code>@define\nclass Efs(Task):\n    \"\"\"EFS Config.\"\"\"\n\n    module: ClassVar[str] = \"efs\"\n    \"\"\"Module name.\"\"\"\n\n    description: str = field(validator=[validators.instance_of(str)], default=\"\")\n    \"\"\"Description.\"\"\"\n\n    model: str = field(validator=[validators.instance_of(str)], default=\"\")\n    \"\"\"Model used by EFS.\"\"\"\n\n    subset_size: int = field(validator=[validators.instance_of(int)], default=30)\n    \"\"\"Number of features in the subset.\"\"\"\n\n    n_subsets: int = field(validator=[validators.instance_of(int)], default=100)\n    \"\"\"Number of subsets.\"\"\"\n\n    cv: int = field(validator=[validators.instance_of(int)], default=5)\n    \"\"\"Number of CV folds for EFS.\"\"\"\n\n    max_n_iterations: int = field(validator=[validators.instance_of(int)], default=50)\n    \"\"\"Number of iterations for ensemble optimization.\"\"\"\n\n    max_n_models: int = field(validator=[validators.instance_of(int)], default=30)\n    \"\"\"Maximum number of models used in optimization, pruning.\"\"\"\n</code></pre>"},{"location":"reference/modules/#octopus.modules.Efs.cv","title":"<code>cv = field(validator=[validators.instance_of(int)], default=5)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of CV folds for EFS.</p>"},{"location":"reference/modules/#octopus.modules.Efs.description","title":"<code>description = field(validator=[validators.instance_of(str)], default='')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Description.</p>"},{"location":"reference/modules/#octopus.modules.Efs.max_n_iterations","title":"<code>max_n_iterations = field(validator=[validators.instance_of(int)], default=50)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of iterations for ensemble optimization.</p>"},{"location":"reference/modules/#octopus.modules.Efs.max_n_models","title":"<code>max_n_models = field(validator=[validators.instance_of(int)], default=30)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Maximum number of models used in optimization, pruning.</p>"},{"location":"reference/modules/#octopus.modules.Efs.model","title":"<code>model = field(validator=[validators.instance_of(str)], default='')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Model used by EFS.</p>"},{"location":"reference/modules/#octopus.modules.Efs.module","title":"<code>module = 'efs'</code>  <code>class-attribute</code>","text":"<p>Module name.</p>"},{"location":"reference/modules/#octopus.modules.Efs.n_subsets","title":"<code>n_subsets = field(validator=[validators.instance_of(int)], default=100)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of subsets.</p>"},{"location":"reference/modules/#octopus.modules.Efs.subset_size","title":"<code>subset_size = field(validator=[validators.instance_of(int)], default=30)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of features in the subset.</p>"},{"location":"reference/modules/#octopus.modules.Mrmr","title":"<code>Mrmr</code>","text":"<p>               Bases: <code>Task</code></p> <p>MRMR Config.</p> Source code in <code>octopus/modules/mrmr/module.py</code> <pre><code>@define\nclass Mrmr(Task):\n    \"\"\"MRMR Config.\"\"\"\n\n    module: ClassVar[str] = \"mrmr\"\n    \"\"\"Module name.\"\"\"\n\n    n_features: int = field(validator=[validators.instance_of(int)], default=Factory(lambda: 30))\n    \"\"\"Number of features selected by MRMR.\"\"\"\n\n    correlation_type: Literal[\"pearson\", \"rdc\", \"spearman\"] = field(\n        validator=validators.in_([\"pearson\", \"rdc\", \"spearman\"]), default=\"spearman\"\n    )\n    \"\"\"Selection of correlation type.\"\"\"\n\n    relevance_type: Literal[\"permutation\", \"f-statistics\"] = field(\n        validator=validators.in_([\"permutation\", \"f-statistics\"]), default=\"permutation\"\n    )\n    \"\"\"Selection of relevance measure.\"\"\"\n\n    results_key: str = field(validator=validators.in_([\"best\", \"ensel\", \"autogluon\"]), default=\"best\")\n    \"\"\"Selection of model from with feature importances were created.\"\"\"\n\n    feature_importance_type: Literal[\"mean\", \"count\"] = field(\n        validator=validators.in_([\"mean\", \"count\"]), default=\"mean\"\n    )\n    \"\"\"Selection of feature importance type.\"\"\"\n\n    feature_importance_method: Literal[\"permutation\", \"shap\", \"internal\", \"lofo\"] = field(\n        validator=validators.in_([\"permutation\", \"shap\", \"internal\", \"lofo\"]), default=\"permutation\"\n    )\n    \"\"\"Selection of feature importance method.\"\"\"\n</code></pre>"},{"location":"reference/modules/#octopus.modules.Mrmr.correlation_type","title":"<code>correlation_type = field(validator=(validators.in_(['pearson', 'rdc', 'spearman'])), default='spearman')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Selection of correlation type.</p>"},{"location":"reference/modules/#octopus.modules.Mrmr.feature_importance_method","title":"<code>feature_importance_method = field(validator=(validators.in_(['permutation', 'shap', 'internal', 'lofo'])), default='permutation')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Selection of feature importance method.</p>"},{"location":"reference/modules/#octopus.modules.Mrmr.feature_importance_type","title":"<code>feature_importance_type = field(validator=(validators.in_(['mean', 'count'])), default='mean')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Selection of feature importance type.</p>"},{"location":"reference/modules/#octopus.modules.Mrmr.module","title":"<code>module = 'mrmr'</code>  <code>class-attribute</code>","text":"<p>Module name.</p>"},{"location":"reference/modules/#octopus.modules.Mrmr.n_features","title":"<code>n_features = field(validator=[validators.instance_of(int)], default=(Factory(lambda: 30)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of features selected by MRMR.</p>"},{"location":"reference/modules/#octopus.modules.Mrmr.relevance_type","title":"<code>relevance_type = field(validator=(validators.in_(['permutation', 'f-statistics'])), default='permutation')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Selection of relevance measure.</p>"},{"location":"reference/modules/#octopus.modules.Mrmr.results_key","title":"<code>results_key = field(validator=(validators.in_(['best', 'ensel', 'autogluon'])), default='best')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Selection of model from with feature importances were created.</p>"},{"location":"reference/modules/#octopus.modules.Octo","title":"<code>Octo</code>","text":"<p>               Bases: <code>Task</code></p> <p>Octofull workflow task config.</p> Source code in <code>octopus/modules/octo/module.py</code> <pre><code>@define\nclass Octo(Task):\n    \"\"\"Octofull workflow task config.\"\"\"\n\n    models: list[str] = field(\n        default=Factory(lambda: [\"ExtraTreesClassifier\"]),\n        converter=_unique_unordered,\n        validator=[\n            validators.instance_of(list),\n            validators.deep_iterable(\n                member_validator=validators.instance_of(str),\n                iterable_validator=validators.instance_of(list),\n            ),\n        ],\n    )\n    \"\"\"Models for ML.\"\"\"\n\n    module: ClassVar[str] = \"octo\"\n    \"\"\"Module name.\"\"\"\n\n    n_folds_inner: int = field(validator=[validators.instance_of(int)], default=Factory(lambda: 5))\n    \"\"\"Number of inner folds.\"\"\"\n\n    datasplit_seeds_inner: list[int] = field(\n        default=Factory(lambda: [0]),\n        validator=validators.deep_iterable(\n            member_validator=validators.instance_of(int),\n            iterable_validator=validators.instance_of(list),\n        ),\n    )\n    \"\"\"List of integers used as seeds for data splitting.\"\"\"\n    # model training\n\n    model_seed: int = field(validator=[validators.instance_of(int)], default=Factory(lambda: 0))\n    \"\"\"Model seed.\"\"\"\n\n    n_jobs: int = field(validator=[validators.instance_of(int)], default=Factory(lambda: 1))\n    \"\"\"Number of CPUs used for every model training.\"\"\"\n\n    max_outl: int = field(validator=[validators.instance_of(int)], default=Factory(lambda: 3))\n    \"\"\"Maximum number of outliers, optimized by Optuna\"\"\"\n\n    fi_methods_bestbag: list[str] = field(\n        default=Factory(lambda: [\"permutation\"]),\n        validator=validators.deep_iterable(\n            member_validator=validators.in_([\"permutation\", \"shap\", \"constant\"]),\n            iterable_validator=validators.instance_of(list),\n        ),\n    )\n\n    inner_parallelization: bool = field(validator=[validators.instance_of(bool)], default=Factory(lambda: True))\n    \"\"\"Enable inner paralization. Defaults is True.\"\"\"\n\n    n_workers: int = field(default=Factory(lambda: None))\n    \"\"\"Number of workers.\"\"\"\n\n    optuna_seed: int = field(validator=[validators.instance_of(int)], default=Factory(lambda: 0))\n    \"\"\"Seed for Optuna TPESampler, default=0\"\"\"\n\n    n_optuna_startup_trials: int = field(validator=[validators.instance_of(int)], default=Factory(lambda: 10))\n    \"\"\"Number of Optuna startup trials (random sampler)\"\"\"\n\n    ensemble_selection: bool = field(validator=[validators.in_([True, False])], default=Factory(lambda: False))\n    \"\"\"Whether to perform ensemble selection.\"\"\"\n\n    ensel_n_save_trials: int = field(validator=[validators.instance_of(int)], default=Factory(lambda: 50))\n    \"\"\"Number of top trials to be saved for ensemble selection (bags).\"\"\"\n\n    n_trials: int = field(validator=[validators.instance_of(int)], default=100 if not _RUNNING_IN_TESTSUITE else 3)\n    \"\"\"Number of Optuna trials.\"\"\"\n\n    hyperparameters: dict = field(validator=[validators.instance_of(dict)], default=Factory(dict))\n    \"\"\"Bring own hyperparameter space.\"\"\"\n\n    max_features: int = field(validator=[validators.instance_of(int)], default=Factory(lambda: 0))\n    \"\"\"Maximum features to constrain hyperparameter optimization. Default is zero (off).\"\"\"\n\n    penalty_factor: float = field(validator=[validators.instance_of(float)], default=Factory(lambda: 1.0))\n    \"\"\"Factor to penalyse optuna target related to feature constraint.\"\"\"\n\n    mrmr_feature_numbers: list = field(validator=[validators.instance_of(list)], default=Factory(list))\n    \"\"\"List of feature numbers to be investigated by mrmr.\"\"\"\n\n    resume_optimization: bool = field(validator=[validators.instance_of(bool)], default=Factory(lambda: False))\n    \"\"\"Resume HPO, use existing optuna.db, don't delete optuna.db\"\"\"\n\n    optuna_return: str = field(default=\"pool\", validator=[validators.in_([\"pool\", \"average\"])])\n    \"\"\"How to calculate the bag performance for the optuna optimization target.\"\"\"\n\n    def __attrs_post_init__(self):\n        # (1) set default of n_workers to n_folds_inner\n        if self.n_workers is None:\n            self.n_workers = self.n_folds_inner\n        if self.n_workers != self.n_folds_inner:\n            logger.warning(\n                f\"Octofull Warning: n_workers ({self.n_workers}) does not match n_folds_inner ({self.n_folds_inner})\",\n            )\n        # (2) Only enforce constrained-HPO compatibility when max_features &gt; 0\n        if self.max_features &gt; 0:\n            incompatible_models: list[str] = []\n\n            for m in self.models:\n                try:\n                    # Resolve model_config either by name (str) or by using get_model_config() on a class/object\n                    if isinstance(m, str):\n                        config = Models.get_config(m)\n                    else:\n                        get_cfg = getattr(m, \"get_model_config\", None)\n                        if callable(get_cfg):\n                            config = get_cfg()\n                            if not getattr(config, \"name\", None):\n                                config.name = getattr(m, \"__name__\", str(m))\n                        else:\n                            raise ValueError(\n                                f\"Model entry {m!r} is not a model name and does not provide get_model_config()\"\n                            )\n\n                    chpo_flag = bool(getattr(config, \"chpo_compatible\", False))\n                    # print/log chpo_compatible for each model\n                    # Models.get_config() always sets name, safe to access\n                    logger.info(f\"Model '{config.name}': chpo_compatible={chpo_flag}\")  # type: ignore[attr-defined]\n\n                    if not chpo_flag:\n                        incompatible_models.append(config.name)  # type: ignore[attr-defined]\n\n                except Exception as exc:\n                    logger.error(f\"Could not retrieve model_config for model '{m}': {exc}\")\n                    # stop construction on resolution failures\n                    raise ValueError(f\"Could not retrieve model_config for model '{m}': {exc}\") from exc\n\n            if incompatible_models:\n                msg = (\n                    \"Octo: The following models are not compatible with constrained HPO. \"\n                    \"Please remove those model or turn constrained HPO off (max_features=0): \"\n                    + \", \".join(incompatible_models)\n                )\n                logger.error(msg)\n                raise ValueError(msg)\n</code></pre>"},{"location":"reference/modules/#octopus.modules.Octo.datasplit_seeds_inner","title":"<code>datasplit_seeds_inner = field(default=(Factory(lambda: [0])), validator=(validators.deep_iterable(member_validator=(validators.instance_of(int)), iterable_validator=(validators.instance_of(list)))))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List of integers used as seeds for data splitting.</p>"},{"location":"reference/modules/#octopus.modules.Octo.ensel_n_save_trials","title":"<code>ensel_n_save_trials = field(validator=[validators.instance_of(int)], default=(Factory(lambda: 50)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of top trials to be saved for ensemble selection (bags).</p>"},{"location":"reference/modules/#octopus.modules.Octo.ensemble_selection","title":"<code>ensemble_selection = field(validator=[validators.in_([True, False])], default=(Factory(lambda: False)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether to perform ensemble selection.</p>"},{"location":"reference/modules/#octopus.modules.Octo.hyperparameters","title":"<code>hyperparameters = field(validator=[validators.instance_of(dict)], default=(Factory(dict)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Bring own hyperparameter space.</p>"},{"location":"reference/modules/#octopus.modules.Octo.inner_parallelization","title":"<code>inner_parallelization = field(validator=[validators.instance_of(bool)], default=(Factory(lambda: True)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Enable inner paralization. Defaults is True.</p>"},{"location":"reference/modules/#octopus.modules.Octo.max_features","title":"<code>max_features = field(validator=[validators.instance_of(int)], default=(Factory(lambda: 0)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Maximum features to constrain hyperparameter optimization. Default is zero (off).</p>"},{"location":"reference/modules/#octopus.modules.Octo.max_outl","title":"<code>max_outl = field(validator=[validators.instance_of(int)], default=(Factory(lambda: 3)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Maximum number of outliers, optimized by Optuna</p>"},{"location":"reference/modules/#octopus.modules.Octo.model_seed","title":"<code>model_seed = field(validator=[validators.instance_of(int)], default=(Factory(lambda: 0)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Model seed.</p>"},{"location":"reference/modules/#octopus.modules.Octo.models","title":"<code>models = field(default=(Factory(lambda: ['ExtraTreesClassifier'])), converter=_unique_unordered, validator=[validators.instance_of(list), validators.deep_iterable(member_validator=(validators.instance_of(str)), iterable_validator=(validators.instance_of(list)))])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Models for ML.</p>"},{"location":"reference/modules/#octopus.modules.Octo.module","title":"<code>module = 'octo'</code>  <code>class-attribute</code>","text":"<p>Module name.</p>"},{"location":"reference/modules/#octopus.modules.Octo.mrmr_feature_numbers","title":"<code>mrmr_feature_numbers = field(validator=[validators.instance_of(list)], default=(Factory(list)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List of feature numbers to be investigated by mrmr.</p>"},{"location":"reference/modules/#octopus.modules.Octo.n_folds_inner","title":"<code>n_folds_inner = field(validator=[validators.instance_of(int)], default=(Factory(lambda: 5)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of inner folds.</p>"},{"location":"reference/modules/#octopus.modules.Octo.n_jobs","title":"<code>n_jobs = field(validator=[validators.instance_of(int)], default=(Factory(lambda: 1)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of CPUs used for every model training.</p>"},{"location":"reference/modules/#octopus.modules.Octo.n_optuna_startup_trials","title":"<code>n_optuna_startup_trials = field(validator=[validators.instance_of(int)], default=(Factory(lambda: 10)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of Optuna startup trials (random sampler)</p>"},{"location":"reference/modules/#octopus.modules.Octo.n_trials","title":"<code>n_trials = field(validator=[validators.instance_of(int)], default=(100 if not _RUNNING_IN_TESTSUITE else 3))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of Optuna trials.</p>"},{"location":"reference/modules/#octopus.modules.Octo.n_workers","title":"<code>n_workers = field(default=(Factory(lambda: None)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of workers.</p>"},{"location":"reference/modules/#octopus.modules.Octo.optuna_return","title":"<code>optuna_return = field(default='pool', validator=[validators.in_(['pool', 'average'])])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>How to calculate the bag performance for the optuna optimization target.</p>"},{"location":"reference/modules/#octopus.modules.Octo.optuna_seed","title":"<code>optuna_seed = field(validator=[validators.instance_of(int)], default=(Factory(lambda: 0)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Seed for Optuna TPESampler, default=0</p>"},{"location":"reference/modules/#octopus.modules.Octo.penalty_factor","title":"<code>penalty_factor = field(validator=[validators.instance_of(float)], default=(Factory(lambda: 1.0)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Factor to penalyse optuna target related to feature constraint.</p>"},{"location":"reference/modules/#octopus.modules.Octo.resume_optimization","title":"<code>resume_optimization = field(validator=[validators.instance_of(bool)], default=(Factory(lambda: False)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Resume HPO, use existing optuna.db, don't delete optuna.db</p>"},{"location":"reference/modules/#octopus.modules.Rfe","title":"<code>Rfe</code>","text":"<p>               Bases: <code>Task</code></p> <p>RFE Config.</p> Source code in <code>octopus/modules/rfe/module.py</code> <pre><code>@define\nclass Rfe(Task):\n    \"\"\"RFE Config.\"\"\"\n\n    module: ClassVar[str] = \"rfe\"\n    \"\"\"Module name.\"\"\"\n\n    description: str = field(validator=[validators.instance_of(str)], default=\"\")\n    \"\"\"Description.\"\"\"\n\n    model: str = field(validator=[validators.instance_of(str)], default=\"\")\n    \"\"\"Model used by RFE.\"\"\"\n\n    step: int = field(validator=[validators.instance_of(int)], default=1)\n    \"\"\"Number of features to remove at each iteration.\"\"\"\n\n    min_features_to_select: int = field(validator=[validators.instance_of(int)], default=1)\n    \"\"\"Minimum number of features to be selected.\"\"\"\n\n    cv: int = field(validator=[validators.instance_of(int)], default=5)\n    \"\"\"Number of CV folds for RFE_CV.\"\"\"\n\n    mode: str = field(validator=[validators.in_([\"Mode1\", \"Mode2\"])], default=\"Mode1\")\n    \"\"\"Mode used by RFE.\"\"\"\n</code></pre>"},{"location":"reference/modules/#octopus.modules.Rfe.cv","title":"<code>cv = field(validator=[validators.instance_of(int)], default=5)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of CV folds for RFE_CV.</p>"},{"location":"reference/modules/#octopus.modules.Rfe.description","title":"<code>description = field(validator=[validators.instance_of(str)], default='')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Description.</p>"},{"location":"reference/modules/#octopus.modules.Rfe.min_features_to_select","title":"<code>min_features_to_select = field(validator=[validators.instance_of(int)], default=1)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Minimum number of features to be selected.</p>"},{"location":"reference/modules/#octopus.modules.Rfe.mode","title":"<code>mode = field(validator=[validators.in_(['Mode1', 'Mode2'])], default='Mode1')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Mode used by RFE.</p>"},{"location":"reference/modules/#octopus.modules.Rfe.model","title":"<code>model = field(validator=[validators.instance_of(str)], default='')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Model used by RFE.</p>"},{"location":"reference/modules/#octopus.modules.Rfe.module","title":"<code>module = 'rfe'</code>  <code>class-attribute</code>","text":"<p>Module name.</p>"},{"location":"reference/modules/#octopus.modules.Rfe.step","title":"<code>step = field(validator=[validators.instance_of(int)], default=1)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of features to remove at each iteration.</p>"},{"location":"reference/modules/#octopus.modules.Rfe2","title":"<code>Rfe2</code>","text":"<p>               Bases: <code>Octo</code></p> <p>Rf2 sequence config.</p> Source code in <code>octopus/modules/rfe2/module.py</code> <pre><code>@define\nclass Rfe2(Octo):\n    \"\"\"Rf2 sequence config.\"\"\"\n\n    module: ClassVar[str] = \"rfe2\"\n    \"\"\"Module name.\"\"\"\n\n    # step: int = field(validator=[validators.instance_of(int)], default=1)\n    # \"\"\"Number of features to remove at each iteration.\"\"\"\n\n    min_features_to_select: int = field(validator=[validators.instance_of(int)], default=1)\n    \"\"\"Minimum number of features to be selected.\"\"\"\n\n    fi_method_rfe: str = field(validator=[validators.in_([\"permutation\", \"shap\"])], default=\"permutation\")\n    \"\"\"Feature importance method for RFE.\"\"\"\n\n    selection_method: str = field(validator=[validators.in_([\"best\", \"parsimonious\"])], default=\"best\")\n    \"\"\"Method to select best solution. Parimonious: smallest solutions within sem.\"\"\"\n\n    abs_on_fi: bool = field(validator=[validators.instance_of(bool)], default=False)\n    \"\"\"Convert negative feature importances to positive (abs()).\"\"\"\n\n    def __attrs_post_init__(self):\n        # overwrite fi_methods_bestbag\n        self.fi_methods_bestbag = [self.fi_method_rfe]\n</code></pre>"},{"location":"reference/modules/#octopus.modules.Rfe2.abs_on_fi","title":"<code>abs_on_fi = field(validator=[validators.instance_of(bool)], default=False)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Convert negative feature importances to positive (abs()).</p>"},{"location":"reference/modules/#octopus.modules.Rfe2.fi_method_rfe","title":"<code>fi_method_rfe = field(validator=[validators.in_(['permutation', 'shap'])], default='permutation')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Feature importance method for RFE.</p>"},{"location":"reference/modules/#octopus.modules.Rfe2.min_features_to_select","title":"<code>min_features_to_select = field(validator=[validators.instance_of(int)], default=1)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Minimum number of features to be selected.</p>"},{"location":"reference/modules/#octopus.modules.Rfe2.module","title":"<code>module = 'rfe2'</code>  <code>class-attribute</code>","text":"<p>Module name.</p>"},{"location":"reference/modules/#octopus.modules.Rfe2.selection_method","title":"<code>selection_method = field(validator=[validators.in_(['best', 'parsimonious'])], default='best')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Method to select best solution. Parimonious: smallest solutions within sem.</p>"},{"location":"reference/modules/#octopus.modules.Roc","title":"<code>Roc</code>","text":"<p>               Bases: <code>Task</code></p> <p>Roc Config.</p> Source code in <code>octopus/modules/roc/module.py</code> <pre><code>@define\nclass Roc(Task):\n    \"\"\"Roc Config.\"\"\"\n\n    module: ClassVar[str] = \"roc\"\n    \"\"\"Module name.\"\"\"\n\n    description: str = field(validator=[validators.instance_of(str)], default=\"\")\n    \"\"\"Description.\"\"\"\n\n    threshold: float = field(validator=[validators.instance_of(float)], default=0.8)\n    \"\"\"Threshold for feature removal.\"\"\"\n\n    correlation_type: str = field(validator=[validators.in_([\"spearmanr\", \"rdc\"])], default=\"spearmanr\")\n    \"\"\"Selection of correlation type.\"\"\"\n\n    filter_type: str = field(\n        validator=[validators.in_([\"mutual_info\", \"f_statistics\"])],\n        default=\"f_statistics\",\n    )\n    \"\"\"Selection of filter type for correlated features.\"\"\"\n</code></pre>"},{"location":"reference/modules/#octopus.modules.Roc.correlation_type","title":"<code>correlation_type = field(validator=[validators.in_(['spearmanr', 'rdc'])], default='spearmanr')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Selection of correlation type.</p>"},{"location":"reference/modules/#octopus.modules.Roc.description","title":"<code>description = field(validator=[validators.instance_of(str)], default='')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Description.</p>"},{"location":"reference/modules/#octopus.modules.Roc.filter_type","title":"<code>filter_type = field(validator=[validators.in_(['mutual_info', 'f_statistics'])], default='f_statistics')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Selection of filter type for correlated features.</p>"},{"location":"reference/modules/#octopus.modules.Roc.module","title":"<code>module = 'roc'</code>  <code>class-attribute</code>","text":"<p>Module name.</p>"},{"location":"reference/modules/#octopus.modules.Roc.threshold","title":"<code>threshold = field(validator=[validators.instance_of(float)], default=0.8)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Threshold for feature removal.</p>"},{"location":"reference/modules/#octopus.modules.Sfs","title":"<code>Sfs</code>","text":"<p>               Bases: <code>Task</code></p> <p>SFS Config.</p> Source code in <code>octopus/modules/sfs/module.py</code> <pre><code>@define\nclass Sfs(Task):\n    \"\"\"SFS Config.\"\"\"\n\n    module: ClassVar[str] = \"sfs\"\n    \"\"\"Module name.\"\"\"\n\n    model: str = field(validator=[validators.instance_of(str)], default=\"\")\n    \"\"\"Model used by SFS.\"\"\"\n\n    cv: int = field(validator=[validators.instance_of(int)], default=5)\n    \"\"\"Number of CV folds for RFE_CV.\"\"\"\n\n    sfs_type: str = field(\n        validator=[validators.in_([\"forward\", \"backward\", \"floating_forward\", \"floating_backward\"])],\n        default=\"backward\",\n    )\n    \"\"\"Sfs type used.\"\"\"\n</code></pre>"},{"location":"reference/modules/#octopus.modules.Sfs.cv","title":"<code>cv = field(validator=[validators.instance_of(int)], default=5)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of CV folds for RFE_CV.</p>"},{"location":"reference/modules/#octopus.modules.Sfs.model","title":"<code>model = field(validator=[validators.instance_of(str)], default='')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Model used by SFS.</p>"},{"location":"reference/modules/#octopus.modules.Sfs.module","title":"<code>module = 'sfs'</code>  <code>class-attribute</code>","text":"<p>Module name.</p>"},{"location":"reference/modules/#octopus.modules.Sfs.sfs_type","title":"<code>sfs_type = field(validator=[validators.in_(['forward', 'backward', 'floating_forward', 'floating_backward'])], default='backward')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Sfs type used.</p>"},{"location":"reference/reference/","title":"Reference","text":"<p>Octopus - AutoML for small Datasets.</p>"},{"location":"reference/study/","title":"octopus.study","text":"<p>Study module.</p>"},{"location":"reference/study/#octopus.study.DatasplitType","title":"<code>DatasplitType</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Datasplit types.</p> Source code in <code>octopus/study/types.py</code> <pre><code>class DatasplitType(str, Enum):\n    \"\"\"Datasplit types.\"\"\"\n\n    SAMPLE = \"sample\"\n    GROUP_FEATURES = \"group_features\"\n    GROUP_SAMPLE_AND_FEATURES = \"group_sample_and_features\"\n</code></pre>"},{"location":"reference/study/#octopus.study.ImputationMethod","title":"<code>ImputationMethod</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Imputation methods.</p> Source code in <code>octopus/study/types.py</code> <pre><code>class ImputationMethod(str, Enum):\n    \"\"\"Imputation methods.\"\"\"\n\n    MEDIAN = \"median\"\n    HALFMIN = \"halfmin\"\n    MICE = \"mice\"\n</code></pre>"},{"location":"reference/study/#octopus.study.MLType","title":"<code>MLType</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Machine learning types.</p> Source code in <code>octopus/study/types.py</code> <pre><code>class MLType(str, Enum):\n    \"\"\"Machine learning types.\"\"\"\n\n    CLASSIFICATION = \"classification\"\n    MULTICLASS = \"multiclass\"\n    REGRESSION = \"regression\"\n    TIMETOEVENT = \"timetoevent\"\n</code></pre>"},{"location":"reference/study/#octopus.study.OctoStudy","title":"<code>OctoStudy</code>","text":"<p>OctoStudy.</p> Source code in <code>octopus/study/core.py</code> <pre><code>@define\nclass OctoStudy:\n    \"\"\"OctoStudy.\"\"\"\n\n    ml_type: MLType = field(\n        converter=lambda x: MLType(x.lower()) if isinstance(x, str) else x,\n        validator=validators.instance_of(MLType),\n    )\n    \"\"\"The type of machine learning model.\"\"\"\n\n    target_metric: str = field(validator=[validate_metric])\n    \"\"\"The primary metric used for model evaluation.\"\"\"\n\n    feature_columns: list[str] = field(validator=[validators.instance_of(list)])\n    \"\"\"List of all feature columns in the dataset.\"\"\"\n\n    target_columns: list[str] = field(validator=[validators.instance_of(list)])\n    \"\"\"List of target columns in the dataset. For regression and classification,\n    only one target is allowed. For time-to-event, two targets need to be provided.\n    \"\"\"\n\n    sample_id: str = field(validator=validators.instance_of(str))\n    \"\"\"Identifier for sample instances.\"\"\"\n\n    name: str = field(validator=[validators.instance_of(str)])\n    \"\"\"The name of the study.\"\"\"\n\n    datasplit_type: DatasplitType = field(\n        default=DatasplitType.SAMPLE,\n        converter=lambda x: DatasplitType(x.lower()) if isinstance(x, str) else x,\n        validator=validators.instance_of(DatasplitType),\n    )\n    \"\"\"Type of datasplit. Allowed are `sample`, `group_features` and `group_sample_and_features`.\"\"\"\n\n    row_id: str | None = field(\n        default=Factory(lambda: None),\n        validator=validators.optional(validators.instance_of(str)),\n    )\n    \"\"\"Unique row identifier.\"\"\"\n\n    target_assignments: dict[str, str] = field(default=Factory(dict), validator=[validators.instance_of(dict)])\n    \"\"\"Mapping of target assignments.\"\"\"\n\n    stratification_column: str | None = field(\n        default=Factory(lambda: None),\n        validator=validators.optional(validators.instance_of(str)),\n    )\n    \"\"\"List of columns used for stratification.\"\"\"\n\n    positive_class: int = field(default=1, validator=validators.instance_of(int))\n    \"\"\"The positive class label for binary classification. Defaults to 1. Not relevant for other ml_types.\"\"\"\n\n    n_folds_outer: int = field(default=5 if not _RUNNING_IN_TESTSUITE else 2, validator=[validators.instance_of(int)])\n    \"\"\"The number of outer folds for cross-validation. Defaults to 5.\"\"\"\n\n    datasplit_seed_outer: int = field(default=0, validator=[validators.instance_of(int)])\n    \"\"\"The seed used for data splitting in outer cross-validation. Defaults to 0.\"\"\"\n\n    imputation_method: ImputationMethod = field(\n        default=ImputationMethod.MEDIAN,\n        converter=lambda x: ImputationMethod(x.lower()) if isinstance(x, str) else x,\n        validator=validators.instance_of(ImputationMethod),\n    )\n\n    metrics: list = field(\n        default=Factory(lambda self: [self.target_metric], takes_self=True),\n        validator=[validators.instance_of(list), validate_metrics_list],\n    )\n    \"\"\"A list of metrics to be calculated. Defaults to target_metric value.\"\"\"\n\n    ignore_data_health_warning: bool = field(default=Factory(lambda: False), validator=[validators.instance_of(bool)])\n    \"\"\"Ignore data health checks warning and run machine learning workflow.\"\"\"\n\n    outer_parallelization: bool = field(default=Factory(lambda: True), validator=[validators.instance_of(bool)])\n    \"\"\"Indicates whether outer parallelization is enabled. Defaults to True.\"\"\"\n\n    run_single_experiment_num: int = field(default=Factory(lambda: -1), validator=[validators.instance_of(int)])\n    \"\"\"Select a single experiment to execute. Defaults to -1 to run all experiments\"\"\"\n\n    workflow: list[Task] = field(\n        default=Factory(lambda: [Octo(task_id=0)]),\n        validator=[validators.instance_of(list), validate_workflow],\n    )\n    \"\"\"A list of tasks that defines the processing workflow. Each item in the list is an instance of `Task`.\"\"\"\n\n    start_with_empty_study: bool = field(\n        default=True, validator=[validators.instance_of(bool), validate_start_with_empty_study]\n    )\n    \"\"\"If True, starts the study with an empty output directory. Defaults to True.\"\"\"\n\n    silently_overwrite_study: bool = field(default=Factory(lambda: False), validator=[validators.instance_of(bool)])\n    \"\"\"If False, prompts user for confirmation when overwriting existing study. Defaults to False.\"\"\"\n\n    path: UPath = field(default=UPath(\"./studies/\"), converter=lambda x: UPath(x))\n    \"\"\"The path where study outputs are saved. Defaults to \"./studies/\".\"\"\"\n\n    prepared: PreparedData = field(init=False)\n    \"\"\"Container for prepared study data and metadata after data preparation.\"\"\"\n\n    @property\n    def output_path(self) -&gt; UPath:\n        \"\"\"Full output path for this study (path/name).\"\"\"\n        return self.path / self.name\n\n    @property\n    def log_dir(self) -&gt; UPath:\n        \"\"\"Directory where logs are stored.\"\"\"\n        return self.output_path\n\n    @property\n    def relevant_columns(self) -&gt; list[str]:\n        \"\"\"Relevant columns for the dataset (computed from prepared data).\"\"\"\n        relevant_columns = list(set(self.prepared.feature_columns + self.target_columns))\n        if self.sample_id:\n            relevant_columns.append(self.sample_id)\n        if self.prepared.row_id:\n            relevant_columns.append(self.prepared.row_id)\n        if self.stratification_column:\n            relevant_columns.append(self.stratification_column)\n        if \"group_features\" in self.prepared.data.columns:\n            relevant_columns.append(\"group_features\")\n        if \"group_sample_and_features\" in self.prepared.data.columns:\n            relevant_columns.append(\"group_sample_and_features\")\n        return list(set(relevant_columns))\n\n    def _validate_data(self, data: pd.DataFrame) -&gt; None:\n        \"\"\"Validate the input data.\"\"\"\n        validator = OctoDataValidator(\n            data=data,\n            feature_columns=self.feature_columns,\n            target_columns=self.target_columns,\n            sample_id=self.sample_id,\n            row_id=self.row_id,\n            stratification_column=self.stratification_column,\n            target_assignments=self.target_assignments,\n            ml_type=self.ml_type.value,\n            positive_class=self.positive_class,\n        )\n        validator.validate()\n\n    def _initialize_study_directory(self) -&gt; None:\n        \"\"\"Initialize study directory.\"\"\"\n        if self.output_path.exists():\n            if not self.silently_overwrite_study:\n                confirmation = input(\"Study exists, do you want to continue? (yes/no): \")\n                if confirmation.strip().lower() != \"yes\":\n                    print(\"Exiting...\")\n                    sys.exit()\n                print(\"Continuing...\")\n\n            if self.start_with_empty_study:\n                print(\"Overwriting existing study....\")\n                self.output_path.rmdir(recursive=True)\n            else:\n                print(\"Resume existing study....\")\n\n        self.output_path.mkdir(parents=True, exist_ok=True)\n\n        self.log_dir.mkdir(parents=True, exist_ok=True)\n        set_logger_filename(log_file=self.log_dir / \"octo_manager.log\")\n\n    def _initialize_study_outputs(self, data: pd.DataFrame) -&gt; None:\n        \"\"\"Initialize study saving config and data into study directory.\"\"\"\n\n        def serialize_value(value):\n            \"\"\"Convert a value to JSON-serializable format.\"\"\"\n            if hasattr(value, \"value\"):\n                return value.value\n            elif isinstance(value, UPath):\n                return str(value)\n            elif has(type(value)):\n                # Convert to dict using asdict\n                result = asdict(value, value_serializer=lambda _, __, v: serialize_value(v))\n\n                # Add ClassVar 'module' field if it exists (for workflow tasks)\n                if hasattr(value, \"module\"):\n                    result[\"module\"] = value.module\n\n                return result\n            elif isinstance(value, list):\n                return [serialize_value(item) for item in value]\n            elif isinstance(value, dict):\n                return {k: serialize_value(v) for k, v in value.items()}\n            return value\n\n        config = {}\n        for attr in fields(OctoStudy):\n            if attr.name == \"prepared\":\n                continue\n            value = getattr(self, attr.name)\n            config[attr.name] = serialize_value(value)\n\n        config[\"prepared\"] = {\n            \"feature_columns\": self.prepared.feature_columns,\n            \"row_id\": self.prepared.row_id,\n            \"target_assignments\": self.prepared.target_assignments,\n        }\n\n        config_path = self.output_path / \"config.json\"\n        with config_path.open(\"w\") as f:\n            json.dump(config, f, indent=2)\n\n        data_path = self.output_path / \"data.parquet\"\n        data.to_parquet(\n            str(data_path),\n            index=False,\n            storage_options=data_path.storage_options,\n            engine=\"pyarrow\",\n        )\n        prepared_data_path = self.output_path / \"data_prepared.parquet\"\n        self.prepared.data.to_parquet(\n            str(prepared_data_path),\n            index=False,\n            storage_options=prepared_data_path.storage_options,\n            engine=\"pyarrow\",\n        )\n\n    def _prepare_data(self, data: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Prepare the data for training.\"\"\"\n        preparator = OctoDataPreparator(\n            data=data,\n            feature_columns=self.feature_columns,\n            target_columns=self.target_columns,\n            sample_id=self.sample_id,\n            row_id=self.row_id,\n            target_assignments=self.target_assignments,\n        )\n        prepared = preparator.prepare()\n        object.__setattr__(self, \"prepared\", prepared)\n\n        return prepared.data\n\n    def _create_datasplits(self, data: pd.DataFrame) -&gt; dict:\n        \"\"\"Create datasplits for outer cross-validation.\"\"\"\n        data_clean = data[self.relevant_columns]\n\n        if self.datasplit_type.value == \"sample\":\n            datasplit_col = self.sample_id\n        else:\n            datasplit_col = self.datasplit_type.value\n\n        datasplits: dict = DataSplit(\n            dataset=data_clean,\n            datasplit_col=datasplit_col,\n            seeds=[self.datasplit_seed_outer],\n            num_folds=self.n_folds_outer,\n            stratification_col=self.stratification_column,\n        ).get_datasplits()\n\n        return datasplits\n\n    def _create_experiments(self, datasplits: dict) -&gt; list[OctoExperiment]:\n        \"\"\"Create experiments from datasplits.\"\"\"\n        experiments = []\n\n        # Get datasplit column based on datasplit_type\n        if self.datasplit_type.value == \"sample\":\n            datasplit_col = self.sample_id\n        else:\n            datasplit_col = self.datasplit_type.value\n\n        for key, value in datasplits.items():\n            experiment: OctoExperiment = OctoExperiment(\n                id=str(key),\n                experiment_id=int(key),\n                task_id=None,  # indicating base experiment\n                depends_on_task=None,  # indicating base experiment\n                task_path=None,  # indicating base experiment\n                study_path=self.path,\n                study_name=self.name,\n                ml_type=self.ml_type.value,\n                target_metric=self.target_metric,\n                positive_class=self.positive_class,\n                metrics=self.metrics,\n                imputation_method=self.imputation_method.value,\n                datasplit_column=datasplit_col,\n                row_column=self.prepared.row_id,\n                feature_columns=self.prepared.feature_columns,\n                target_assignments=self.prepared.target_assignments,\n                data_traindev=value[\"train\"],\n                data_test=value[\"test\"],\n            )\n            experiments.append(experiment)\n\n        return experiments\n\n    def _run_health_check(self, data: pd.DataFrame, config: HealthCheckConfig | None) -&gt; None:\n        \"\"\"Run data health check, save results, and check for issues.\"\"\"\n        checker = OctoDataHealthChecker(\n            data=data,\n            feature_columns=self.prepared.feature_columns,\n            target_columns=self.target_columns,\n            row_id=self.prepared.row_id,\n            sample_id=self.sample_id,\n            stratification_column=self.stratification_column,\n            config=config or HealthCheckConfig(),\n        )\n        report = checker.generate_report()\n        report_path = self.output_path / \"health_check_report.csv\"\n        report.to_csv(\n            str(report_path),\n            index=False,\n            storage_options=report_path.storage_options,\n        )\n\n        if report.empty:\n            return\n\n        has_critical = False\n        has_warning = False\n\n        if \"severity\" in report.columns:\n            has_critical = (report[\"severity\"] == \"critical\").any()\n            has_warning = (report[\"severity\"] == \"warning\").any()\n\n        if has_critical:\n            raise ValueError(f\"Critical data issues detected. Please check: {report_path}\")\n\n        if has_warning and not self.ignore_data_health_warning:\n            raise ValueError(\n                f\"Data issues detected. Please check: {report_path}\\nTo proceed despite warnings, set `ignore_data_health_warning=True`.\"\n            )\n\n    def _flush_logger(self):\n        \"\"\"Flush and close all handlers of the logger.\"\"\"\n        for handler in logger.handlers:\n            handler.flush()\n            handler.close()\n\n        set_logger_filename(log_file=None)\n\n    def fit(\n        self,\n        data: pd.DataFrame,\n        health_check_config: HealthCheckConfig | None = None,\n    ) -&gt; None:\n        \"\"\"Fit study to data.\n\n        Args:\n            data: DataFrame containing the dataset.\n            health_check_config: Optional configuration for health check thresholds.\n        \"\"\"\n        self._initialize_study_directory()\n        self._validate_data(data)\n        prepared_data = self._prepare_data(data)\n        self._initialize_study_outputs(data)\n        self._run_health_check(prepared_data, health_check_config)\n\n        datasplits = self._create_datasplits(prepared_data)\n        experiments = self._create_experiments(datasplits)\n        manager = OctoManager(\n            base_experiments=experiments,\n            workflow=self.workflow,\n            outer_parallelization=self.outer_parallelization,\n            run_single_experiment_num=self.run_single_experiment_num,\n            log_dir=self.log_dir,\n        )\n        manager.run_outer_experiments()\n\n        self._flush_logger()\n</code></pre>"},{"location":"reference/study/#octopus.study.OctoStudy.datasplit_seed_outer","title":"<code>datasplit_seed_outer = field(default=0, validator=[validators.instance_of(int)])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The seed used for data splitting in outer cross-validation. Defaults to 0.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.datasplit_type","title":"<code>datasplit_type = field(default=(DatasplitType.SAMPLE), converter=(lambda x: DatasplitType(x.lower()) if isinstance(x, str) else x), validator=(validators.instance_of(DatasplitType)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Type of datasplit. Allowed are <code>sample</code>, <code>group_features</code> and <code>group_sample_and_features</code>.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.feature_columns","title":"<code>feature_columns = field(validator=[validators.instance_of(list)])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List of all feature columns in the dataset.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.ignore_data_health_warning","title":"<code>ignore_data_health_warning = field(default=(Factory(lambda: False)), validator=[validators.instance_of(bool)])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Ignore data health checks warning and run machine learning workflow.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.log_dir","title":"<code>log_dir</code>  <code>property</code>","text":"<p>Directory where logs are stored.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.metrics","title":"<code>metrics = field(default=(Factory(lambda self: [self.target_metric], takes_self=True)), validator=[validators.instance_of(list), validate_metrics_list])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A list of metrics to be calculated. Defaults to target_metric value.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.ml_type","title":"<code>ml_type = field(converter=(lambda x: MLType(x.lower()) if isinstance(x, str) else x), validator=(validators.instance_of(MLType)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The type of machine learning model.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.n_folds_outer","title":"<code>n_folds_outer = field(default=(5 if not _RUNNING_IN_TESTSUITE else 2), validator=[validators.instance_of(int)])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The number of outer folds for cross-validation. Defaults to 5.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.name","title":"<code>name = field(validator=[validators.instance_of(str)])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The name of the study.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.outer_parallelization","title":"<code>outer_parallelization = field(default=(Factory(lambda: True)), validator=[validators.instance_of(bool)])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Indicates whether outer parallelization is enabled. Defaults to True.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.output_path","title":"<code>output_path</code>  <code>property</code>","text":"<p>Full output path for this study (path/name).</p>"},{"location":"reference/study/#octopus.study.OctoStudy.path","title":"<code>path = field(default=(UPath('./studies/')), converter=(lambda x: UPath(x)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The path where study outputs are saved. Defaults to \"./studies/\".</p>"},{"location":"reference/study/#octopus.study.OctoStudy.positive_class","title":"<code>positive_class = field(default=1, validator=(validators.instance_of(int)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The positive class label for binary classification. Defaults to 1. Not relevant for other ml_types.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.prepared","title":"<code>prepared = field(init=False)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Container for prepared study data and metadata after data preparation.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.relevant_columns","title":"<code>relevant_columns</code>  <code>property</code>","text":"<p>Relevant columns for the dataset (computed from prepared data).</p>"},{"location":"reference/study/#octopus.study.OctoStudy.row_id","title":"<code>row_id = field(default=(Factory(lambda: None)), validator=(validators.optional(validators.instance_of(str))))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Unique row identifier.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.run_single_experiment_num","title":"<code>run_single_experiment_num = field(default=(Factory(lambda: -1)), validator=[validators.instance_of(int)])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Select a single experiment to execute. Defaults to -1 to run all experiments</p>"},{"location":"reference/study/#octopus.study.OctoStudy.sample_id","title":"<code>sample_id = field(validator=(validators.instance_of(str)))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Identifier for sample instances.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.silently_overwrite_study","title":"<code>silently_overwrite_study = field(default=(Factory(lambda: False)), validator=[validators.instance_of(bool)])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If False, prompts user for confirmation when overwriting existing study. Defaults to False.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.start_with_empty_study","title":"<code>start_with_empty_study = field(default=True, validator=[validators.instance_of(bool), validate_start_with_empty_study])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If True, starts the study with an empty output directory. Defaults to True.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.stratification_column","title":"<code>stratification_column = field(default=(Factory(lambda: None)), validator=(validators.optional(validators.instance_of(str))))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List of columns used for stratification.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.target_assignments","title":"<code>target_assignments = field(default=(Factory(dict)), validator=[validators.instance_of(dict)])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Mapping of target assignments.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.target_columns","title":"<code>target_columns = field(validator=[validators.instance_of(list)])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List of target columns in the dataset. For regression and classification, only one target is allowed. For time-to-event, two targets need to be provided.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.target_metric","title":"<code>target_metric = field(validator=[validate_metric])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The primary metric used for model evaluation.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.workflow","title":"<code>workflow = field(default=(Factory(lambda: [Octo(task_id=0)])), validator=[validators.instance_of(list), validate_workflow])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A list of tasks that defines the processing workflow. Each item in the list is an instance of <code>Task</code>.</p>"},{"location":"reference/study/#octopus.study.OctoStudy.fit","title":"<code>fit(data, health_check_config=None)</code>","text":"<p>Fit study to data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>DataFrame containing the dataset.</p> required <code>health_check_config</code> <code>HealthCheckConfig | None</code> <p>Optional configuration for health check thresholds.</p> <code>None</code> Source code in <code>octopus/study/core.py</code> <pre><code>def fit(\n    self,\n    data: pd.DataFrame,\n    health_check_config: HealthCheckConfig | None = None,\n) -&gt; None:\n    \"\"\"Fit study to data.\n\n    Args:\n        data: DataFrame containing the dataset.\n        health_check_config: Optional configuration for health check thresholds.\n    \"\"\"\n    self._initialize_study_directory()\n    self._validate_data(data)\n    prepared_data = self._prepare_data(data)\n    self._initialize_study_outputs(data)\n    self._run_health_check(prepared_data, health_check_config)\n\n    datasplits = self._create_datasplits(prepared_data)\n    experiments = self._create_experiments(datasplits)\n    manager = OctoManager(\n        base_experiments=experiments,\n        workflow=self.workflow,\n        outer_parallelization=self.outer_parallelization,\n        run_single_experiment_num=self.run_single_experiment_num,\n        log_dir=self.log_dir,\n    )\n    manager.run_outer_experiments()\n\n    self._flush_logger()\n</code></pre>"},{"location":"reference/study/#octopus.study.PreparedData","title":"<code>PreparedData</code>","text":"<p>Container for prepared study data and metadata after data preparation.</p> Source code in <code>octopus/study/prepared_data.py</code> <pre><code>@define\nclass PreparedData:\n    \"\"\"Container for prepared study data and metadata after data preparation.\"\"\"\n\n    data: pd.DataFrame\n    \"\"\"Prepared DataFrame after all transformations.\"\"\"\n\n    feature_columns: list[str]\n    \"\"\"Feature columns actually used after preparation (sorted, single-value features removed).\"\"\"\n\n    row_id: str\n    \"\"\"Row ID column used (auto-generated if not provided by user).\"\"\"\n\n    target_assignments: dict[str, str]\n    \"\"\"Target assignments with defaults applied.\"\"\"\n\n    @property\n    def num_features(self) -&gt; list[str]:\n        \"\"\"Get numerical feature columns from effective features.\"\"\"\n        return [\n            col\n            for col in self.feature_columns\n            if col in self.data.columns\n            and pd.api.types.is_numeric_dtype(self.data[col])\n            and not isinstance(self.data[col].dtype, pd.CategoricalDtype)\n        ]\n\n    @property\n    def cat_nominal_features(self) -&gt; list[str]:\n        \"\"\"Get categorical nominal feature columns from effective features.\"\"\"\n        cat_nominal_features = []\n        for col in self.feature_columns:\n            if col in self.data.columns:\n                dtype = self.data[col].dtype\n                if isinstance(dtype, pd.CategoricalDtype) and not dtype.ordered:\n                    cat_nominal_features.append(col)\n        return cat_nominal_features\n\n    @property\n    def cat_ordinal_features(self) -&gt; list[str]:\n        \"\"\"Get categorical ordinal feature columns from effective features.\"\"\"\n        cat_ordinal_features = []\n        for col in self.feature_columns:\n            if col in self.data.columns:\n                dtype = self.data[col].dtype\n                if isinstance(dtype, pd.CategoricalDtype) and dtype.ordered:\n                    cat_ordinal_features.append(col)\n        return cat_ordinal_features\n</code></pre>"},{"location":"reference/study/#octopus.study.PreparedData.cat_nominal_features","title":"<code>cat_nominal_features</code>  <code>property</code>","text":"<p>Get categorical nominal feature columns from effective features.</p>"},{"location":"reference/study/#octopus.study.PreparedData.cat_ordinal_features","title":"<code>cat_ordinal_features</code>  <code>property</code>","text":"<p>Get categorical ordinal feature columns from effective features.</p>"},{"location":"reference/study/#octopus.study.PreparedData.data","title":"<code>data</code>  <code>instance-attribute</code>","text":"<p>Prepared DataFrame after all transformations.</p>"},{"location":"reference/study/#octopus.study.PreparedData.feature_columns","title":"<code>feature_columns</code>  <code>instance-attribute</code>","text":"<p>Feature columns actually used after preparation (sorted, single-value features removed).</p>"},{"location":"reference/study/#octopus.study.PreparedData.num_features","title":"<code>num_features</code>  <code>property</code>","text":"<p>Get numerical feature columns from effective features.</p>"},{"location":"reference/study/#octopus.study.PreparedData.row_id","title":"<code>row_id</code>  <code>instance-attribute</code>","text":"<p>Row ID column used (auto-generated if not provided by user).</p>"},{"location":"reference/study/#octopus.study.PreparedData.target_assignments","title":"<code>target_assignments</code>  <code>instance-attribute</code>","text":"<p>Target assignments with defaults applied.</p>"},{"location":"reference/task/","title":"octopus.task","text":"<p>Task module.</p>"},{"location":"reference/task/#octopus.task.Task","title":"<code>Task</code>","text":"<p>Base class for all workflow tasks.</p> <p>Contains all common parameters for all workflow tasks.</p> Source code in <code>octopus/task/core.py</code> <pre><code>@define\nclass Task:\n    \"\"\"Base class for all workflow tasks.\n\n    Contains all common parameters for all workflow tasks.\n    \"\"\"\n\n    task_id: int = field(validator=[validators.instance_of(int), validators.ge(0)])\n    \"\"\"Task ID, greater or equal than 0.\"\"\"\n\n    depends_on_task: int = field(default=-1, validator=[validators.instance_of(int), validators.ge(-1)])\n    \"\"\"Specify ID of input task. Input ID of start task: -1.\"\"\"\n\n    load_task: bool = field(default=False, validator=[validators.instance_of(bool)])\n    \"\"\"Whether to load the task item.\"\"\"\n\n    description: str = field(default=\"\", validator=[validators.instance_of(str)])\n    \"\"\"Description for the workflow task.\"\"\"\n\n    categorical_encoding: bool = field(default=False, validator=[validators.instance_of(bool)])\n    \"\"\"Enforce categorical encoding on module level (and not model) to stay compatible with feature importance\"\"\"\n</code></pre>"},{"location":"reference/task/#octopus.task.Task.categorical_encoding","title":"<code>categorical_encoding = field(default=False, validator=[validators.instance_of(bool)])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Enforce categorical encoding on module level (and not model) to stay compatible with feature importance</p>"},{"location":"reference/task/#octopus.task.Task.depends_on_task","title":"<code>depends_on_task = field(default=(-1), validator=[validators.instance_of(int), validators.ge(-1)])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Specify ID of input task. Input ID of start task: -1.</p>"},{"location":"reference/task/#octopus.task.Task.description","title":"<code>description = field(default='', validator=[validators.instance_of(str)])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Description for the workflow task.</p>"},{"location":"reference/task/#octopus.task.Task.load_task","title":"<code>load_task = field(default=False, validator=[validators.instance_of(bool)])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether to load the task item.</p>"},{"location":"reference/task/#octopus.task.Task.task_id","title":"<code>task_id = field(validator=[validators.instance_of(int), validators.ge(0)])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Task ID, greater or equal than 0.</p>"},{"location":"userguide/classification/","title":"Classification","text":""},{"location":"userguide/cli/","title":"Command Line Interface","text":"<p>Current functionality:</p> <ul> <li><code>octopus examples --list</code> lists available examples.</li> <li><code>octopus examples &lt;number|filename&gt;</code> opens that example in Jupyter.</li> <li><code>octopus examples</code> opens Jupyter on the examples directory.</li> </ul> <p>Falls back to help output for other commands.</p>"},{"location":"userguide/regression/","title":"Regression","text":""},{"location":"userguide/time_to_event/","title":"Time to Event","text":""},{"location":"userguide/userguide/","title":"User Guide","text":"<p>Backwards Compatibility and Deprecations</p> <p>Octopus is in a constant state of development. As part of this, interfaces and objects might change in ways breaking existing code. We aspire to provide backwards support for deprecated code of the last three minor versions. After this time, old code will generally be removed. Both the moment of deprecation and full removal (deprecation expiration) will be noted in the changelog.</p> <p>The most commonly used interface Octopus provides is the central <code>OctoStudy</code> object.</p> <p>Detailed examples of how to use individual API components can be found via the links below:</p> <ul> <li>Classification</li> <li>Regression</li> <li>Time to Event</li> </ul>"}]}